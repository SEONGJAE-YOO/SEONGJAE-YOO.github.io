<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Search Result</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!-- custom.css -->
    <link rel="stylesheet" type="text/css" href="/assets/built/custom.css" />
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- 웹폰트 추가 -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothic.css">

    <!-- syntax.css 추가 -->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />



    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="SeongJae Yu 블로그" />
    <link rel="shortcut icon" href="https://SEONGJAE-YOO.github.io/assets/built/images/favicon.jpg" type="image/png" />
    <link rel="canonical" href="https://SEONGJAE-YOO.github.io/search" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Big Data" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Search Result" />
    <meta property="og:description" content="SeongJae Yu 블로그" />
    <meta property="og:url" content="https://SEONGJAE-YOO.github.io/search" />
    <meta property="og:image" content="https://SEONGJAE-YOO.github.io/assets/built/images/author-logo.png" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Search Result" />
    <meta name="twitter:description" content="SeongJae Yu 블로그" />
    <meta name="twitter:url" content="https://SEONGJAE-YOO.github.io/" />
    <meta name="twitter:image" content="https://SEONGJAE-YOO.github.io/assets/built/images/author-logo.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Big Data" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="666" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Big Data",
        "logo": "https://SEONGJAE-YOO.github.io/"
    },
    "url": "https://SEONGJAE-YOO.github.io/search",
    "image": {
        "@type": "ImageObject",
        "url": "https://SEONGJAE-YOO.github.io/assets/built/images/author-logo.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://SEONGJAE-YOO.github.io/search"
    },
    "description": "SeongJae Yu 블로그"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Search Result" href="/feed.xml" />




</head>
<body class="page-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- < default -->
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<!-- The big featured header, it uses blog cover image as a BG if available -->
<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://SEONGJAE-YOO.github.io/">Big Data</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-jekyll" role="menuitem"><a href="/tag/Big Data/">Big Data</a></li>
    <li class="nav-python" role="menuitem"><a href="/tag/python/">Python</a></li>
    <li class="nav-ProcessMining" role="menuitem"><a href="/tag/ProcessMining/">ProcessMining</a></li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
    <li class="nav-archive" role="menuitem">
        <a href="/author_archive.html">Tag별 Posts</a>
    </li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  post page no-image">

            <header class="post-full-header">
                <h1 class="post-full-title">Search Result</h1>
            </header>

            

            <section class="post-full-content">
                <form action="/search" method="get" hidden="hidden">
    <label for="search-box"></label>
    <input type="text" id="search-box" name="query">
</form>

<ul class="mylist" id="search-results"></ul>

<script>
    window.store = {
    
    "transform-function": {
        "title": "transform 함수의 이해 및 활용하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  transform 함수 이해하기import numpy as npimport pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datadf = pd.read_csv('./train.csv')df.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      transform 함수  groupby 후 transform 함수를 사용하면 원래의 index를 유지한 상태로 통계함수를 적용  전체 데이터의 집계가 아닌 각 그룹에서의 집계를 계산  따라서 새로 생성된 데이터를 원본 dataframe과 합치기 쉬움df.groupby('Pclass').mean()                  PassengerId      Survived      Age      SibSp      Parch      Fare              Pclass                                                      1      461.597222      0.629630      38.233441      0.416667      0.356481      84.154687              2      445.956522      0.472826      29.877630      0.402174      0.380435      20.662183              3      439.154786      0.242363      25.140620      0.615071      0.393075      13.675550      df.groupby('Pclass').transform(np.mean)                  PassengerId      Survived      Age      SibSp      Parch      Fare                  0      439.154786      0.242363      25.140620      0.615071      0.393075      13.675550              1      461.597222      0.629630      38.233441      0.416667      0.356481      84.154687              2      439.154786      0.242363      25.140620      0.615071      0.393075      13.675550              3      461.597222      0.629630      38.233441      0.416667      0.356481      84.154687              4      439.154786      0.242363      25.140620      0.615071      0.393075      13.675550              ...      ...      ...      ...      ...      ...      ...              886      445.956522      0.472826      29.877630      0.402174      0.380435      20.662183              887      461.597222      0.629630      38.233441      0.416667      0.356481      84.154687              888      439.154786      0.242363      25.140620      0.615071      0.393075      13.675550              889      461.597222      0.629630      38.233441      0.416667      0.356481      84.154687              890      439.154786      0.242363      25.140620      0.615071      0.393075      13.675550      891 rows × 6 columnsdf['Age2'] = df.groupby('Pclass').transform(np.mean)['Age']df                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age2                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      25.140620              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      38.233441              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      25.140620              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      38.233441              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      25.140620              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.0000      NaN      S      29.877630              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S      38.233441              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.4500      NaN      S      25.140620              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C      38.233441              890      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.7500      NaN      Q      25.140620      891 rows × 13 columnsdf.groupby(['Pclass', 'Sex']).mean()                        PassengerId      Survived      Age      SibSp      Parch      Fare      Age2              Pclass      Sex                                                            1      female      469.212766      0.968085      34.611765      0.553191      0.457447      106.125798      38.233441              male      455.729508      0.368852      41.281386      0.311475      0.278689      67.226127      38.233441              2      female      443.105263      0.921053      28.722973      0.486842      0.605263      21.970121      29.877630              male      447.962963      0.157407      30.740707      0.342593      0.222222      19.741782      29.877630              3      female      399.729167      0.500000      21.750000      0.895833      0.798611      16.118810      25.140620              male      455.515850      0.135447      26.507589      0.498559      0.224784      12.661633      25.140620      df.groupby(['Pclass','Sex']).transform(np.mean)                  PassengerId      Survived      Age      SibSp      Parch      Fare      Age2                  0      455.515850      0.135447      26.507589      0.498559      0.224784      12.661633      25.140620              1      469.212766      0.968085      34.611765      0.553191      0.457447      106.125798      38.233441              2      399.729167      0.500000      21.750000      0.895833      0.798611      16.118810      25.140620              3      469.212766      0.968085      34.611765      0.553191      0.457447      106.125798      38.233441              4      455.515850      0.135447      26.507589      0.498559      0.224784      12.661633      25.140620              ...      ...      ...      ...      ...      ...      ...      ...              886      447.962963      0.157407      30.740707      0.342593      0.222222      19.741782      29.877630              887      469.212766      0.968085      34.611765      0.553191      0.457447      106.125798      38.233441              888      399.729167      0.500000      21.750000      0.895833      0.798611      16.118810      25.140620              889      455.729508      0.368852      41.281386      0.311475      0.278689      67.226127      38.233441              890      455.515850      0.135447      26.507589      0.498559      0.224784      12.661633      25.140620      891 rows × 7 columnsdf['Age3'] = df.groupby(['Pclass', 'Sex']).transform(np.mean)['Age']df                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age2      Age3                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      25.140620      26.507589              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      38.233441      34.611765              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      25.140620      21.750000              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      38.233441      34.611765              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      25.140620      26.507589              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.0000      NaN      S      29.877630      30.740707              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S      38.233441      34.611765              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.4500      NaN      S      25.140620      21.750000              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C      38.233441      41.281386              890      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.7500      NaN      Q      25.140620      26.507589      891 rows × 14 columns",
        "url": "/transform-function"
    }
    ,
    
    "stack-function": {
        "title": "stack, unstack 함수의 이해 및 활용하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  stack, unstack 함수 이해하기import numpy as npimport pandas as pddf = pd.DataFrame({    '지역': ['서울', '서울', '서울', '경기', '경기', '부산', '서울', '서울', '부산', '경기', '경기', '경기'],    '요일': ['월요일', '화요일', '수요일', '월요일', '화요일', '월요일', '목요일', '금요일', '화요일', '수요일', '목요일', '금요일'],    '강수량': [100, 80, 1000, 200, 200, 100, 50, 100, 200, 100, 50, 100],    '강수확률': [80, 70, 90, 10, 20, 30, 50, 90, 20, 80, 50, 10]                  })df                  지역      요일      강수량      강수확률                  0      서울      월요일      100      80              1      서울      화요일      80      70              2      서울      수요일      1000      90              3      경기      월요일      200      10              4      경기      화요일      200      20              5      부산      월요일      100      30              6      서울      목요일      50      50              7      서울      금요일      100      90              8      부산      화요일      200      20              9      경기      수요일      100      80              10      경기      목요일      50      50              11      경기      금요일      100      10      stack &amp; unstack  stack : 컬럼 레벨에서 인덱스 레벨로 dataframe 변경  즉, 데이터를 쌓아올리는 개념으로 이해하면 쉬움  unstack : 인덱스 레벨에서 컬럼 레벨로 dataframe 변경      stack의 반대 operation    둘은 역의 관계에 있음new_df = df.set_index(['지역', '요일'])new_df                        강수량      강수확률              지역      요일                              서울      월요일      100      80              화요일      80      70              수요일      1000      90              경기      월요일      200      10              화요일      200      20              부산      월요일      100      30              서울      목요일      50      50              금요일      100      90              부산      화요일      200      20              경기      수요일      100      80              목요일      50      50              금요일      100      10      new_df.indexMultiIndex([('서울', '월요일'),            ('서울', '화요일'),            ('서울', '수요일'),            ('경기', '월요일'),            ('경기', '화요일'),            ('부산', '월요일'),            ('서울', '목요일'),            ('서울', '금요일'),            ('부산', '화요일'),            ('경기', '수요일'),            ('경기', '목요일'),            ('경기', '금요일')],           names=['지역', '요일'])# 첫번째 레벨의 인덱스를 컬럼으로 이동new_df.unstack(0)                   강수량      강수확률              지역      경기      부산      서울      경기      부산      서울              요일                                                      금요일      100.0      NaN      100.0      10.0      NaN      90.0              목요일      50.0      NaN      50.0      50.0      NaN      50.0              수요일      100.0      NaN      1000.0      80.0      NaN      90.0              월요일      200.0      100.0      100.0      10.0      30.0      80.0              화요일      200.0      200.0      80.0      20.0      20.0      70.0      # 두번째 레벨의 인덱스를 컬럼으로 이동new_df.unstack(1)                  강수량      강수확률              요일      금요일      목요일      수요일      월요일      화요일      금요일      목요일      수요일      월요일      화요일              지역                                                                              경기      100.0      50.0      100.0      200.0      200.0      10.0      50.0      80.0      10.0      20.0              부산      NaN      NaN      NaN      100.0      200.0      NaN      NaN      NaN      30.0      20.0              서울      100.0      50.0      1000.0      100.0      80.0      90.0      50.0      90.0      80.0      70.0      from IPython.display import ImageImage(\"stack.png\")# 첫번째 레벨의 컬럼을 인덱스로 이동new_df.unstack(0).stack(0)                  지역      경기      부산      서울              요일                                          금요일      강수량      100.0      NaN      100.0              강수확률      10.0      NaN      90.0              목요일      강수량      50.0      NaN      50.0              강수확률      50.0      NaN      50.0              수요일      강수량      100.0      NaN      1000.0              강수확률      80.0      NaN      90.0              월요일      강수량      200.0      100.0      100.0              강수확률      10.0      30.0      80.0              화요일      강수량      200.0      200.0      80.0              강수확률      20.0      20.0      70.0      new_df.unstack(0).stack(1)                        강수량      강수확률              요일      지역                              금요일      경기      100.0      10.0              서울      100.0      90.0              목요일      경기      50.0      50.0              서울      50.0      50.0              수요일      경기      100.0      80.0              서울      1000.0      90.0              월요일      경기      200.0      10.0              부산      100.0      30.0              서울      100.0      80.0              화요일      경기      200.0      20.0              부산      200.0      20.0              서울      80.0      70.0      new_df.stack&lt;bound method DataFrame.stack of          강수량  강수확률지역 요일             서울 월요일   100    80   화요일    80    70   수요일  1000    90경기 월요일   200    10   화요일   200    20부산 월요일   100    30서울 목요일    50    50   금요일   100    90부산 화요일   200    20경기 수요일   100    80   목요일    50    50   금요일   100    10&gt;",
        "url": "/stack-function"
    }
    ,
    
    "pivot-function": {
        "title": "pivot, pivot_table 함수의 이해 및 활용하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  pivot, pivot_table 함수의 이해import numpy as npimport pandas as pddf = pd.DataFrame({    '지역': ['서울', '서울', '경기', '경기', '부산', '서울', '서울', '부산', '경기', '경기', '경기'],    '요일': ['월요일', '수요일', '월요일', '화요일', '월요일', '목요일', '금요일', '화요일', '수요일', '목요일', '금요일'],    '강수량': [80, 1000, 200, 200, 100, 50, 100, 200, 100, 50, 100],    '강수확률': [70, 90, 10, 20, 30, 50, 90, 20, 80, 50, 10]                  })df                  지역      요일      강수량      강수확률                  0      서울      월요일      80      70              1      서울      수요일      1000      90              2      경기      월요일      200      10              3      경기      화요일      200      20              4      부산      월요일      100      30              5      서울      목요일      50      50              6      서울      금요일      100      90              7      부산      화요일      200      20              8      경기      수요일      100      80              9      경기      목요일      50      50              10      경기      금요일      100      10      pivot  dataframe의 형태를 변경  인덱스, 컬럼, 데이터로 사용할 컬럼을 명시df.pivot('지역', '요일') #index, column                  강수량      강수확률              요일      금요일      목요일      수요일      월요일      화요일      금요일      목요일      수요일      월요일      화요일              지역                                                                              경기      100.0      50.0      100.0      200.0      200.0      10.0      50.0      80.0      10.0      20.0              부산      NaN      NaN      NaN      100.0      200.0      NaN      NaN      NaN      30.0      20.0              서울      100.0      50.0      1000.0      80.0      NaN      90.0      50.0      90.0      70.0      NaN      df.pivot('요일', '지역')                  강수량      강수확률              지역      경기      부산      서울      경기      부산      서울              요일                                                      금요일      100.0      NaN      100.0      10.0      NaN      90.0              목요일      50.0      NaN      50.0      50.0      NaN      50.0              수요일      100.0      NaN      1000.0      80.0      NaN      90.0              월요일      200.0      100.0      80.0      10.0      30.0      70.0              화요일      200.0      200.0      NaN      20.0      20.0      NaN      df.pivot('요일','지역','강수량')            지역      경기      부산      서울              요일                                    금요일      100.0      NaN      100.0              목요일      50.0      NaN      50.0              수요일      100.0      NaN      1000.0              월요일      200.0      100.0      80.0              화요일      200.0      200.0      NaN      pivot_table  기능적으로 pivot과 동일  pivot과의 차이점          중복되는 모호한 값이 있을 경우, aggregation 함수 사용하여 값을 채움      기능은 groupby랑 거의 똑같고 , 연산을 하는것이 pivot_table이다.      pd.pivot_table(df, index='요일', columns='지역', aggfunc=np.mean)                  강수량      강수확률              지역      경기      부산      서울      경기      부산      서울              요일                                                      금요일      100.0      NaN      100.0      10.0      NaN      90.0              목요일      50.0      NaN      50.0      50.0      NaN      50.0              수요일      100.0      NaN      1000.0      80.0      NaN      90.0              월요일      200.0      100.0      80.0      10.0      30.0      70.0              화요일      200.0      200.0      NaN      20.0      20.0      NaN      pd.pivot_table(df, index='요일', columns='지역', aggfunc=np.mean, fill_value=0)#fill_value=0으로 NaN값을 0으로 대체                  강수량      강수확률              지역      경기      부산      서울      경기      부산      서울              요일                                                      금요일      100      0      100      10      0      90              목요일      50      0      50      50      0      50              수요일      100      0      1000      80      0      90              월요일      200      100      80      10      30      70              화요일      200      200      0      20      20      0      ",
        "url": "/pivot-function"
    }
    ,
    
    "merge-join": {
        "title": "Merge_join 함수로 데이터 프레임 병합하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  merge &amp; join 함수 활용하기import numpy as npimport pandas as pddataframe merge  SQL의 join처럼 특정한 column을 기준으로 병합          join 방식: how 파라미터를 통해 명시                  inner: 기본값, 일치하는 값이 있는 경우          left: left outer join          right: right outer join          outer: full outer join                      pandas.merge 함수가 사용됨customer = pd.DataFrame({'customer_id' : np.arange(6),                     'name' : ['철수'\"\", '영희', '길동', '영수', '수민', '동건'],                     '나이' : [40, 20, 21, 30, 31, 18]})customer                  customer_id      name      나이                  0      0      철수      40              1      1      영희      20              2      2      길동      21              3      3      영수      30              4      4      수민      31              5      5      동건      18      orders = pd.DataFrame({'customer_id' : [1, 1, 2, 2, 2, 3, 3, 1, 4, 9],                     'item' : ['치약', '칫솔', '이어폰', '헤드셋', '수건', '생수', '수건', '치약', '생수', '케이스'],                     'quantity' : [1, 2, 1, 1, 3, 2, 2, 3, 2, 1]})orders.head()                  customer_id      item      quantity                  0      1      치약      1              1      1      칫솔      2              2      2      이어폰      1              3      2      헤드셋      1              4      2      수건      3        on  join 대상이 되는 column 명시pd.merge(customer, orders, on='customer_id', how='inner') #(테이블명1, 테이블명2)                  customer_id      name      나이      item      quantity                  0      1      영희      20      치약      1              1      1      영희      20      칫솔      2              2      1      영희      20      치약      3              3      2      길동      21      이어폰      1              4      2      길동      21      헤드셋      1              5      2      길동      21      수건      3              6      3      영수      30      생수      2              7      3      영수      30      수건      2              8      4      수민      31      생수      2      pd.merge(customer, orders, on='customer_id', how='left')                  customer_id      name      나이      item      quantity                  0      0      철수      40      NaN      NaN              1      1      영희      20      치약      1.0              2      1      영희      20      칫솔      2.0              3      1      영희      20      치약      3.0              4      2      길동      21      이어폰      1.0              5      2      길동      21      헤드셋      1.0              6      2      길동      21      수건      3.0              7      3      영수      30      생수      2.0              8      3      영수      30      수건      2.0              9      4      수민      31      생수      2.0              10      5      동건      18      NaN      NaN      pd.merge(customer, orders, on='customer_id', how='right')                  customer_id      name      나이      item      quantity                  0      1      영희      20.0      치약      1              1      1      영희      20.0      칫솔      2              2      2      길동      21.0      이어폰      1              3      2      길동      21.0      헤드셋      1              4      2      길동      21.0      수건      3              5      3      영수      30.0      생수      2              6      3      영수      30.0      수건      2              7      1      영희      20.0      치약      3              8      4      수민      31.0      생수      2              9      9      NaN      NaN      케이스      1      pd.merge(customer, orders, on='customer_id', how='outer') #left + right 값 합친것                   customer_id      name      나이      item      quantity                  0      0      철수      40.0      NaN      NaN              1      1      영희      20.0      치약      1.0              2      1      영희      20.0      칫솔      2.0              3      1      영희      20.0      치약      3.0              4      2      길동      21.0      이어폰      1.0              5      2      길동      21.0      헤드셋      1.0              6      2      길동      21.0      수건      3.0              7      3      영수      30.0      생수      2.0              8      3      영수      30.0      수건      2.0              9      4      수민      31.0      생수      2.0              10      5      동건      18.0      NaN      NaN              11      9      NaN      NaN      케이스      1.0        index 기준으로 join하기cust1 = customer.set_index('customer_id')order1 = orders.set_index('customer_id')cust1                  name      나이              customer_id                              0      철수      40              1      영희      20              2      길동      21              3      영수      30              4      수민      31              5      동건      18      order1                  item      quantity              customer_id                              1      치약      1              1      칫솔      2              2      이어폰      1              2      헤드셋      1              2      수건      3              3      생수      2              3      수건      2              1      치약      3              4      생수      2              9      케이스      1      pd.merge(cust1, order1, left_index=True, right_index=True) #on='customer_id' 대신 사용가능                  name      나이      item      quantity              customer_id                                          1      영희      20      치약      1              1      영희      20      칫솔      2              1      영희      20      치약      3              2      길동      21      이어폰      1              2      길동      21      헤드셋      1              2      길동      21      수건      3              3      영수      30      생수      2              3      영수      30      수건      2              4      수민      31      생수      2      연습문제  가장 많이 팔린 아이템은?  영희가 가장 많이 구매한 아이템은?pd.merge(customer, orders, on='customer_id').groupby('item').sum().sort_values(by='quantity', ascending=False)                  customer_id      나이      quantity              item                                    수건      5      51      5              생수      7      61      4              치약      2      40      4              칫솔      1      20      2              이어폰      2      21      1              헤드셋      2      21      1      pd.merge(customer, orders, on='customer_id').groupby(['name', 'item']).sum()                        customer_id      나이      quantity              name      item                                    길동      수건      2      21      3              이어폰      2      21      1              헤드셋      2      21      1              수민      생수      4      31      2              영수      생수      3      30      2              수건      3      30      2              영희      치약      2      40      4              칫솔      1      20      2      pd.merge(customer, orders, on='customer_id').groupby(['name', 'item']).sum().loc['영희']                  customer_id      나이      quantity              item                                    치약      2      40      4              칫솔      1      20      2      pd.merge(customer, orders, on='customer_id').groupby(['name', 'item']).sum().loc['영희', 'quantity']item치약    4칫솔    2Name: quantity, dtype: int64join 함수  내부적으로 pandas.merge 함수 사용  기본적으로 index를 사용하여 left joincust1.join(order1)                  name      나이      item      quantity              customer_id                                          0      철수      40      NaN      NaN              1      영희      20      치약      1.0              1      영희      20      칫솔      2.0              1      영희      20      치약      3.0              2      길동      21      이어폰      1.0              2      길동      21      헤드셋      1.0              2      길동      21      수건      3.0              3      영수      30      생수      2.0              3      영수      30      수건      2.0              4      수민      31      생수      2.0              5      동건      18      NaN      NaN      cust1.join(order1, how='inner')                  name      나이      item      quantity              customer_id                                          1      영희      20      치약      1              1      영희      20      칫솔      2              1      영희      20      치약      3              2      길동      21      이어폰      1              2      길동      21      헤드셋      1              2      길동      21      수건      3              3      영수      30      생수      2              3      영수      30      수건      2              4      수민      31      생수      2      ",
        "url": "/merge-join"
    }
    ,
    
    "dataframe-groupby": {
        "title": "DataFrame group by 이해하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  DataFrame groupby 이해하기import pandas as pdimport numpy as npgroup by  아래의 세 단계를 적용하여 데이터를 그룹화(groupping) (SQL의 group by 와 개념적으로는 동일, 사용법은 유사)          데이터 분할      operation 적용      데이터 병합      # data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datadf = pd.read_csv('./train.csv')df.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      GroupBy groups 속성  각 그룹과 그룹에 속한 index를 dict 형태로 표현class_group = df.groupby('Pclass')class_group&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000018605571DC0&gt;class_group.groups{1: [1, 3, 6, 11, 23, 27, 30, 31, 34, 35, 52, 54, 55, 61, 62, 64, 83, 88, 92, 96, 97, 102, 110, 118, 124, 136, 137, 139, 151, 155, 166, 168, 170, 174, 177, 185, 187, 194, 195, 209, 215, 218, 224, 230, 245, 248, 252, 256, 257, 258, 262, 263, 268, 269, 270, 273, 275, 284, 290, 291, 295, 297, 298, 299, 305, 306, 307, 309, 310, 311, 318, 319, 325, 329, 331, 332, 334, 336, 337, 339, 341, 351, 356, 366, 369, 370, 373, 375, 377, 380, 383, 390, 393, 412, 430, 434, 435, 438, 445, 447, ...], 2: [9, 15, 17, 20, 21, 33, 41, 43, 53, 56, 58, 66, 70, 72, 78, 84, 98, 99, 117, 120, 122, 123, 133, 134, 135, 144, 145, 148, 149, 150, 161, 178, 181, 183, 190, 191, 193, 199, 211, 213, 217, 219, 221, 226, 228, 232, 234, 236, 237, 238, 239, 242, 247, 249, 259, 265, 272, 277, 288, 292, 303, 308, 312, 314, 316, 317, 322, 323, 327, 340, 342, 343, 344, 345, 346, 357, 361, 385, 387, 389, 397, 398, 399, 405, 407, 413, 416, 417, 418, 426, 427, 432, 437, 439, 440, 443, 446, 450, 458, 463, ...], 3: [0, 2, 4, 5, 7, 8, 10, 12, 13, 14, 16, 18, 19, 22, 24, 25, 26, 28, 29, 32, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 57, 59, 60, 63, 65, 67, 68, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 89, 90, 91, 93, 94, 95, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 119, 121, 125, 126, 127, 128, 129, 130, 131, 132, 138, 140, 141, 142, 143, 146, 147, 152, 153, 154, 156, 157, 158, 159, ...]}gender_group = df.groupby('Sex')gender_group.groups{'female': [1, 2, 3, 8, 9, 10, 11, 14, 15, 18, 19, 22, 24, 25, 28, 31, 32, 38, 39, 40, 41, 43, 44, 47, 49, 52, 53, 56, 58, 61, 66, 68, 71, 79, 82, 84, 85, 88, 98, 100, 106, 109, 111, 113, 114, 119, 123, 128, 132, 133, 136, 140, 141, 142, 147, 151, 156, 161, 166, 167, 172, 177, 180, 184, 186, 190, 192, 194, 195, 198, 199, 205, 208, 211, 215, 216, 218, 229, 230, 233, 235, 237, 240, 241, 246, 247, 251, 254, 255, 256, 257, 258, 259, 264, 268, 269, 272, 274, 275, 276, ...], 'male': [0, 4, 5, 6, 7, 12, 13, 16, 17, 20, 21, 23, 26, 27, 29, 30, 33, 34, 35, 36, 37, 42, 45, 46, 48, 50, 51, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131, 134, 135, 137, 138, 139, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, ...]}groupping 함수  그룹 데이터에 적용 가능한 통계 함수(NaN은 제외하여 연산)  count - 데이터 개수  sum   - 데이터의 합  mean, std, var - 평균, 표준편차, 분산  min, max - 최소, 최대값class_group.count()                  PassengerId      Survived      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked              Pclass                                                                                    1      216      216      216      216      186      216      216      216      216      176      214              2      184      184      184      184      173      184      184      184      184      16      184              3      491      491      491      491      355      491      491      491      491      12      491      class_group.mean()['Survived']Pclass1    0.6296302    0.4728263    0.242363Name: Survived, dtype: float64  성별에 따른 생존율 구해보기df.groupby('Sex').mean()['Survived']Sexfemale    0.742038male      0.188908Name: Survived, dtype: float64복수 columns로 groupping 하기  groupby에 column 리스트를 전달      통계함수를 적용한 결과는 multiindex를 갖는 dataframe    클래스와 성별에 따른 생존률 구해보기df.groupby(['Pclass', 'Sex']).mean()['Survived']Pclass  Sex   1       female    0.968085        male      0.3688522       female    0.921053        male      0.1574073       female    0.500000        male      0.135447Name: Survived, dtype: float64df.groupby(['Pclass', 'Sex']).mean()                        PassengerId      Survived      Age      SibSp      Parch      Fare              Pclass      Sex                                                      1      female      469.212766      0.968085      34.611765      0.553191      0.457447      106.125798              male      455.729508      0.368852      41.281386      0.311475      0.278689      67.226127              2      female      443.105263      0.921053      28.722973      0.486842      0.605263      21.970121              male      447.962963      0.157407      30.740707      0.342593      0.222222      19.741782              3      female      399.729167      0.500000      21.750000      0.895833      0.798611      16.118810              male      455.515850      0.135447      26.507589      0.498559      0.224784      12.661633      df.groupby(['Pclass', 'Sex']).mean().loc[(2, 'female')] #Pclass 가 2인 평균값PassengerId    443.105263Survived         0.921053Age             28.722973SibSp            0.486842Parch            0.605263Fare            21.970121Name: (2, female), dtype: float64df.groupby(['Pclass', 'Sex']).mean().indexMultiIndex([(1, 'female'),            (1,   'male'),            (2, 'female'),            (2,   'male'),            (3, 'female'),            (3,   'male')],           names=['Pclass', 'Sex'])index를 이용한 group by  index가 있는 경우, groupby 함수에 level 사용 가능          level은 index의 depth를 의미하며, 가장 왼쪽부터 0부터 증가        set_index 함수  column 데이터를 index 레벨로 변경  reset_index 함수  인덱스 초기화df.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      df.set_index(['Pclass', 'Sex'])                        PassengerId      Survived      Name      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked              Pclass      Sex                                                                              3      male      1      0      Braund, Mr. Owen Harris      22.0      1      0      A/5 21171      7.2500      NaN      S              1      female      2      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      38.0      1      0      PC 17599      71.2833      C85      C              3      female      3      1      Heikkinen, Miss. Laina      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              1      female      4      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      35.0      1      0      113803      53.1000      C123      S              3      male      5      0      Allen, Mr. William Henry      35.0      0      0      373450      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              2      male      887      0      Montvila, Rev. Juozas      27.0      0      0      211536      13.0000      NaN      S              1      female      888      1      Graham, Miss. Margaret Edith      19.0      0      0      112053      30.0000      B42      S              3      female      889      0      Johnston, Miss. Catherine Helen \"Carrie\"      NaN      1      2      W./C. 6607      23.4500      NaN      S              1      male      890      1      Behr, Mr. Karl Howell      26.0      0      0      111369      30.0000      C148      C              3      male      891      0      Dooley, Mr. Patrick      32.0      0      0      370376      7.7500      NaN      Q      891 rows × 10 columnsdf.set_index(['Pclass', 'Sex']).reset_index()                  Pclass      Sex      PassengerId      Survived      Name      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      3      male      1      0      Braund, Mr. Owen Harris      22.0      1      0      A/5 21171      7.2500      NaN      S              1      1      female      2      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      38.0      1      0      PC 17599      71.2833      C85      C              2      3      female      3      1      Heikkinen, Miss. Laina      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      1      female      4      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      35.0      1      0      113803      53.1000      C123      S              4      3      male      5      0      Allen, Mr. William Henry      35.0      0      0      373450      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      2      male      887      0      Montvila, Rev. Juozas      27.0      0      0      211536      13.0000      NaN      S              887      1      female      888      1      Graham, Miss. Margaret Edith      19.0      0      0      112053      30.0000      B42      S              888      3      female      889      0      Johnston, Miss. Catherine Helen \"Carrie\"      NaN      1      2      W./C. 6607      23.4500      NaN      S              889      1      male      890      1      Behr, Mr. Karl Howell      26.0      0      0      111369      30.0000      C148      C              890      3      male      891      0      Dooley, Mr. Patrick      32.0      0      0      370376      7.7500      NaN      Q      891 rows × 12 columnsdf.set_index('Age').groupby(level=0).mean()                  PassengerId      Survived      Pclass      SibSp      Parch      Fare              Age                                                      0.42      804.0      1.0      3.0      0.0      1.0      8.5167              0.67      756.0      1.0      2.0      1.0      1.0      14.5000              0.75      557.5      1.0      3.0      2.0      1.0      19.2583              0.83      455.5      1.0      2.0      0.5      1.5      23.8750              0.92      306.0      1.0      1.0      1.0      2.0      151.5500              ...      ...      ...      ...      ...      ...      ...              70.00      709.5      0.0      1.5      0.5      0.5      40.7500              70.50      117.0      0.0      3.0      0.0      0.0      7.7500              71.00      295.5      0.0      1.0      0.0      0.0      42.0792              74.00      852.0      0.0      3.0      0.0      0.0      7.7750              80.00      631.0      1.0      1.0      0.0      0.0      30.0000      88 rows × 6 columns나이대별로 생존율 구하기import mathdef age_categorize(age):    if math.isnan(age):        return -1    return math.floor(age / 10) * 10df.set_index('Age').groupby(age_categorize).mean()['Survived']-1     0.293785 0     0.612903 10    0.401961 20    0.350000 30    0.437126 40    0.382022 50    0.416667 60    0.315789 70    0.000000 80    1.000000Name: Survived, dtype: float64MultiIndex를 이용한 grouppingdf.set_index(['Pclass', 'Sex']).groupby(level=[0, 1]).mean()['Age']Pclass  Sex   1       female    34.611765        male      41.2813862       female    28.722973        male      30.7407073       female    21.750000        male      26.507589Name: Age, dtype: float64aggregate(집계) 함수 사용하기  groupby 결과에 집계함수를 적용하여 그룹별 데이터 확인 가능df.set_index(['Pclass', 'Sex']).groupby(level=[0, 1]).aggregate([np.mean, np.sum, np.max])                        PassengerId      Survived      Age      SibSp      Parch      Fare                          mean      sum      amax      mean      sum      amax      mean      sum      amax      mean      sum      amax      mean      sum      amax      mean      sum      amax              Pclass      Sex                                                                                                                              1      female      469.212766      44106      888      0.968085      91      1      34.611765      2942.00      63.0      0.553191      52      3      0.457447      43      2      106.125798      9975.8250      512.3292              male      455.729508      55599      890      0.368852      45      1      41.281386      4169.42      80.0      0.311475      38      3      0.278689      34      4      67.226127      8201.5875      512.3292              2      female      443.105263      33676      881      0.921053      70      1      28.722973      2125.50      57.0      0.486842      37      3      0.605263      46      3      21.970121      1669.7292      65.0000              male      447.962963      48380      887      0.157407      17      1      30.740707      3043.33      70.0      0.342593      37      2      0.222222      24      2      19.741782      2132.1125      73.5000              3      female      399.729167      57561      889      0.500000      72      1      21.750000      2218.50      63.0      0.895833      129      8      0.798611      115      6      16.118810      2321.1086      69.5500              male      455.515850      158064      891      0.135447      47      1      26.507589      6706.42      74.0      0.498559      173      8      0.224784      78      5      12.661633      4393.5865      69.5500      ",
        "url": "/dataframe-groupby"
    }
    ,
    
    "concat-function": {
        "title": "Concat 함수로 데이터 프레임 병합하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  concat 함수를 활용하여 dataframe 병합시키기import pandas as pdimport numpy as npconcat 함수 사용하여 dataframe 병합하기  pandas.concat 함수  축을 따라 dataframe을 병합 가능          기본 axis = 0 -&gt; 행단위 병합        column명이 같은 경우df1 = pd.DataFrame({'key1' : np.arange(10), 'value1' : np.random.randn(10)})df2 = pd.DataFrame({'key1' : np.arange(10), 'value1' : np.random.randn(10)})df2                  key1      value1                  0      0      -0.338849              1      1      0.688248              2      2      0.863890              3      3      0.431818              4      4      -0.345499              5      5      0.626425              6      6      0.639522              7      7      -0.677354              8      8      -0.778642              9      9      -0.600007      pd.concat([df1, df2], ignore_index=True)                  key1      value1                  0      0      0.157695              1      1      0.815835              2      2      0.512740              3      3      -0.575658              4      4      -0.713351              5      5      1.701762              6      6      0.296171              7      7      -0.018002              8      8      -1.302774              9      9      -2.626175              10      0      -0.338849              11      1      0.688248              12      2      0.863890              13      3      0.431818              14      4      -0.345499              15      5      0.626425              16      6      0.639522              17      7      -0.677354              18      8      -0.778642              19      9      -0.600007      pd.concat([df1, df2], axis=0) #기본값                  key1      value1                  0      0      0.157695              1      1      0.815835              2      2      0.512740              3      3      -0.575658              4      4      -0.713351              5      5      1.701762              6      6      0.296171              7      7      -0.018002              8      8      -1.302774              9      9      -2.626175              0      0      -0.338849              1      1      0.688248              2      2      0.863890              3      3      0.431818              4      4      -0.345499              5      5      0.626425              6      6      0.639522              7      7      -0.677354              8      8      -0.778642              9      9      -0.600007      pd.concat([df1, df2], axis=1)                   key1      value1      key1      value1                  0      0      0.157695      0      -0.338849              1      1      0.815835      1      0.688248              2      2      0.512740      2      0.863890              3      3      -0.575658      3      0.431818              4      4      -0.713351      4      -0.345499              5      5      1.701762      5      0.626425              6      6      0.296171      6      0.639522              7      7      -0.018002      7      -0.677354              8      8      -1.302774      8      -0.778642              9      9      -2.626175      9      -0.600007        column 명이 다른 경우df3 = pd.DataFrame({'key2' : np.arange(10), 'value2' : np.random.randn(10)})pd.concat([df1, df3], axis=1)                  key1      value1      key2      value2                  0      0      0.157695      0      2.096654              1      1      0.815835      1      1.434691              2      2      0.512740      2      -0.211020              3      3      -0.575658      3      1.498715              4      4      -0.713351      4      -1.106296              5      5      1.701762      5      -0.678457              6      6      0.296171      6      -0.420552              7      7      -0.018002      7      -0.091809              8      8      -1.302774      8      0.603147              9      9      -2.626175      9      -0.918178      ",
        "url": "/concat-function"
    }
    ,
    
    "num-categoricaldata": {
        "title": "숫자 데이터의 범주형 데이터화",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  숫자 데이터의 범주형 데이터 화import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      Pclass 변수 변환하기  astype 사용하여 간단히 타입만 변환train_data.info()&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns): #   Column       Non-Null Count  Dtype  ---  ------       --------------  -----   0   PassengerId  891 non-null    int64   1   Survived     891 non-null    int64   2   Pclass       891 non-null    int64   3   Name         891 non-null    object  4   Sex          891 non-null    object  5   Age          714 non-null    float64 6   SibSp        891 non-null    int64   7   Parch        891 non-null    int64   8   Ticket       891 non-null    object  9   Fare         891 non-null    float64 10  Cabin        204 non-null    object  11  Embarked     889 non-null    object dtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KBtrain_data['Pclass'] = train_data['Pclass'].astype(str)train_data.info() # Pclass  object 로 변경됨&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns): #   Column       Non-Null Count  Dtype  ---  ------       --------------  -----   0   PassengerId  891 non-null    int64   1   Survived     891 non-null    int64   2   Pclass       891 non-null    object  3   Name         891 non-null    object  4   Sex          891 non-null    object  5   Age          714 non-null    float64 6   SibSp        891 non-null    int64   7   Parch        891 non-null    int64   8   Ticket       891 non-null    object  9   Fare         891 non-null    float64 10  Cabin        204 non-null    object  11  Embarked     889 non-null    object dtypes: float64(2), int64(4), object(6)memory usage: 83.7+ KBAge 변수 변환하기  변환 로직을 함수로 만든 후, apply 함수로 적용import math  # 소수점 버리려고 math 사용함def age_categorize(age):   #예를 들어 23 -&gt; 20, 38 -&gt; 30 으로 바뀜    if math.isnan(age):   #age 가 NaN이면 -1 반환        return -1    return math.floor(age / 10) * 10train_data                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.0000      NaN      S              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.4500      NaN      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C              890      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.7500      NaN      Q      891 rows × 12 columnstrain_data['Age'].apply(age_categorize) # 바뀐 데이터 확인 가능0      201      302      203      304      30       ..886    20887    10888    -1889    20890    30Name: Age, Length: 891, dtype: int64",
        "url": "/num-categoricaldata"
    }
    ,
    
    "num-categorical": {
        "title": "숫자 데이터와 범주형 데이터의 이해",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  숫자 &amp; 범주형 데이터의 이해import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      info함수로 각 변수의 데이터 타입 확인  타입 변경은 astype함수를 사용train_data.info()&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns): #   Column       Non-Null Count  Dtype  ---  ------       --------------  -----   0   PassengerId  891 non-null    int64   1   Survived     891 non-null    int64   2   Pclass       891 non-null    int64   3   Name         891 non-null    object  4   Sex          891 non-null    object  5   Age          714 non-null    float64 6   SibSp        891 non-null    int64   7   Parch        891 non-null    int64   8   Ticket       891 non-null    object  9   Fare         891 non-null    float64 10  Cabin        204 non-null    object  11  Embarked     889 non-null    object dtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KB숫자형(Numerical Type) 데이터  연속성을 띄는 숫자로 이루어진 데이터          예) Age, Fare 등      범주형(Categorical Type) 데이터  연속적이지 않은 값(대부분의 경우 숫자를 제외한 나머지 값)을 갖는 데이터를 의미          예) Name, Sex, Ticket, Cabin, Embarked        어떤 경우, 숫자형 타입이라 할지라도 개념적으로 범주형으로 처리해야할 경우가 있음          예) Pclass      ",
        "url": "/num-categorical"
    }
    ,
    
    "dataframe-structure": {
        "title": "DataFrame 구조 이해하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  인덱스와 컬럼의 이해import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      인덱스(index)  index 속성  각 아이템을 특정할 수 있는 고유의 값을 저장  복잡한 데이터의 경우, 멀티 인덱스로 표현 가능train_data.indexRangeIndex(start=0, stop=891, step=1)컬럼(column)  columns 속성  각각의 특성(feature)을 나타냄  복잡한 데이터의 경우, 멀티 컬럼으로 표현 가능train_data.columnsIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],      dtype='object')",
        "url": "/dataframe-structure"
    }
    ,
    
    "dataframe-row": {
        "title": "DataFrame 원하는 row(데이터)만 선택하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  dataframe row 선택하기import numpy as npimport pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      dataframe slicing  dataframe의 경우 기본적으로 [] 연산자가 column 선택에 사용  하지만, slicing은 row 레벨로 지원train_data[7:10]                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  7      8      0      3      Palsson, Master. Gosta Leonard      male      2.0      3      1      349909      21.0750      NaN      S              8      9      1      3      Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      female      27.0      0      2      347742      11.1333      NaN      S              9      10      1      2      Nasser, Mrs. Nicholas (Adele Achem)      female      14.0      1      0      237736      30.0708      NaN      C      row 선택하기  Seires의 경우 []로 row 선택이 가능하나, DataFrame의 경우는 기본적으로 column을 선택하도록 설계  .loc, .iloc로 row 선택 가능          loc - 인덱스 자체를 사용      iloc - 0 based index로 사용      이 두 함수는 ,를 사용하여 column 선택도 가능      train_data.info()&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns): #   Column       Non-Null Count  Dtype  ---  ------       --------------  -----   0   PassengerId  891 non-null    int64   1   Survived     891 non-null    int64   2   Pclass       891 non-null    int64   3   Name         891 non-null    object  4   Sex          891 non-null    object  5   Age          714 non-null    float64 6   SibSp        891 non-null    int64   7   Parch        891 non-null    int64   8   Ticket       891 non-null    object  9   Fare         891 non-null    float64 10  Cabin        204 non-null    object  11  Embarked     889 non-null    object dtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KBtrain_data.index = np.arange(100, 991)train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  100      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              101      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              102      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              103      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              104      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      train_data.tail()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  986      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.00      NaN      S              987      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.00      B42      S              988      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.45      NaN      S              989      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.00      C148      C              990      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.75      NaN      Q      train_data.loc[986] #index 명시해줌PassengerId                      887Survived                           0Pclass                             2Name           Montvila, Rev. JuozasSex                             maleAge                             27.0SibSp                              0Parch                              0Ticket                        211536Fare                            13.0Cabin                            NaNEmbarked                           SName: 986, dtype: objecttrain_data.loc[[986, 100, 110, 990]] #복수 loc 조회하려면 리스트 형태로 준다                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  986      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.00      NaN      S              100      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.25      NaN      S              110      11      1      3      Sandstrom, Miss. Marguerite Rut      female      4.0      1      1      PP 9549      16.70      G6      S              990      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.75      NaN      Q      train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  100      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              101      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              102      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              103      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              104      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      train_data.iloc[0] # 100이 0번째 주소이다PassengerId                          1Survived                             0Pclass                               3Name           Braund, Mr. Owen HarrisSex                               maleAge                               22.0SibSp                                1Parch                                0Ticket                       A/5 21171Fare                              7.25Cabin                              NaNEmbarked                             SName: 100, dtype: objecttrain_data.iloc[[0, 100, 200, 2]] # loc 는 정확한 주소를 이용하고 iloc 는 순서를 이용할 때 사용한다. /0 based index로 사용 /                   PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  100      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              200      101      0      3      Petranec, Miss. Matilda      female      28.0      0      0      349245      7.8958      NaN      S              300      201      0      3      Vande Walle, Mr. Nestor Cyriel      male      28.0      0      0      345770      9.5000      NaN      S              102      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      row, column 동시에 선택하기  loc, iloc 속성을 이용할 때, 콤마를 이용하여 둘 다 명시 가능train_data.loc[[986, 100, 110, 990], ['Survived', 'Name', 'Sex', 'Age']]                  Survived      Name      Sex      Age                  986      0      Montvila, Rev. Juozas      male      27.0              100      0      Braund, Mr. Owen Harris      male      22.0              110      1      Sandstrom, Miss. Marguerite Rut      female      4.0              990      0      Dooley, Mr. Patrick      male      32.0      train_data.iloc[[101, 100, 200, 102], [1, 4, 5]] # 맨뒤 컬럼값도 0 based index로 사용 ,  0 번째 주소는 PassengerId이다                   Survived      Sex      Age                  201      0      male      NaN              200      0      female      28.0              300      0      male      28.0              202      0      male      21.0      ",
        "url": "/dataframe-row"
    }
    ,
    
    "dataframe-nan": {
        "title": "DataFrame NaN 데이터 처리",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  NaN 처리 방법 이해하기import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      NaN 값 확인  info함수를 통하여 개수 확인  isna함수를 통해 boolean 타입으로 확인train_data.info() #Cabin 204, Age 714 을 보아 데이터 손실이 있다는 것을 알수 있다&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns): #   Column       Non-Null Count  Dtype  ---  ------       --------------  -----   0   PassengerId  891 non-null    int64   1   Survived     891 non-null    int64   2   Pclass       891 non-null    int64   3   Name         891 non-null    object  4   Sex          891 non-null    object  5   Age          714 non-null    float64 6   SibSp        891 non-null    int64   7   Parch        891 non-null    int64   8   Ticket       891 non-null    object  9   Fare         891 non-null    float64 10  Cabin        204 non-null    object  11  Embarked     889 non-null    object dtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KBtrain_data.isna() # true 인 경우에 NaN , 즉 데이터가 없다는 의미                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      False      False      False      False      False      False      False      False      False      False      True      False              1      False      False      False      False      False      False      False      False      False      False      False      False              2      False      False      False      False      False      False      False      False      False      False      True      False              3      False      False      False      False      False      False      False      False      False      False      False      False              4      False      False      False      False      False      False      False      False      False      False      True      False              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      False      False      False      False      False      False      False      False      False      False      True      False              887      False      False      False      False      False      False      False      False      False      False      False      False              888      False      False      False      False      False      True      False      False      False      False      True      False              889      False      False      False      False      False      False      False      False      False      False      False      False              890      False      False      False      False      False      False      False      False      False      False      True      False      891 rows × 12 columnstrain_data['Age'].isna()0      False1      False2      False3      False4      False       ...  886    False887    False888     True889    False890    FalseName: Age, Length: 891, dtype: boolNaN 처리 방법  데이터에서 삭제          dropna 함수        다른 값으로 치환          fillna 함수        NaN 데이터 삭제하기train_data.dropna()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              6      7      0      1      McCarthy, Mr. Timothy J      male      54.0      0      0      17463      51.8625      E46      S              10      11      1      3      Sandstrom, Miss. Marguerite Rut      female      4.0      1      1      PP 9549      16.7000      G6      S              11      12      1      1      Bonnell, Miss. Elizabeth      female      58.0      0      0      113783      26.5500      C103      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              871      872      1      1      Beckwith, Mrs. Richard Leonard (Sallie Monypeny)      female      47.0      1      1      11751      52.5542      D35      S              872      873      0      1      Carlsson, Mr. Frans Olof      male      33.0      0      0      695      5.0000      B51 B53 B55      S              879      880      1      1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)      female      56.0      0      1      11767      83.1583      C50      C              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C      183 rows × 12 columnstrain_data.dropna(subset=['Age', 'Cabin']) #Age , Cabin 컬럼 에서 True 값이 있는 인덱스 행열 제거 한다                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              6      7      0      1      McCarthy, Mr. Timothy J      male      54.0      0      0      17463      51.8625      E46      S              10      11      1      3      Sandstrom, Miss. Marguerite Rut      female      4.0      1      1      PP 9549      16.7000      G6      S              11      12      1      1      Bonnell, Miss. Elizabeth      female      58.0      0      0      113783      26.5500      C103      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              871      872      1      1      Beckwith, Mrs. Richard Leonard (Sallie Monypeny)      female      47.0      1      1      11751      52.5542      D35      S              872      873      0      1      Carlsson, Mr. Frans Olof      male      33.0      0      0      695      5.0000      B51 B53 B55      S              879      880      1      1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)      female      56.0      0      1      11767      83.1583      C50      C              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C      185 rows × 12 columnstrain_data.dropna(axis=1) # axis = 0 은 row 제거 , axis =1 은 columns 제거                  PassengerId      Survived      Pclass      Name      Sex      SibSp      Parch      Ticket      Fare                  0      1      0      3      Braund, Mr. Owen Harris      male      1      0      A/5 21171      7.2500              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      1      0      PC 17599      71.2833              2      3      1      3      Heikkinen, Miss. Laina      female      0      0      STON/O2. 3101282      7.9250              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      1      0      113803      53.1000              4      5      0      3      Allen, Mr. William Henry      male      0      0      373450      8.0500              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      Montvila, Rev. Juozas      male      0      0      211536      13.0000              887      888      1      1      Graham, Miss. Margaret Edith      female      0      0      112053      30.0000              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      1      2      W./C. 6607      23.4500              889      890      1      1      Behr, Mr. Karl Howell      male      0      0      111369      30.0000              890      891      0      3      Dooley, Mr. Patrick      male      0      0      370376      7.7500      891 rows × 9 columns  NaN 값 대체하기  평균으로 대체하기  생존자/사망자 별 평균으로 대체하기train_data['Age'].mean()29.69911764705882train_data['Age'].fillna(train_data['Age'].mean()) # Age 컬럼 888번째 NaN 값을 전체 평균 값으로 대체한다(29.69911764705882)0      22.0000001      38.0000002      26.0000003      35.0000004      35.000000         ...    886    27.000000887    19.000000888    29.699118889    26.000000890    32.000000Name: Age, Length: 891, dtype: float64train_data['Survived'] == 1 # 생존자 확인 0      False1       True2       True3       True4      False       ...  886    False887     True888    False889     True890    FalseName: Survived, Length: 891, dtype: booltrain_data[train_data['Survived'] == 1]['Age'] # 생존자 나이 추출1      38.02      26.03      35.08      27.09      14.0       ... 875    15.0879    56.0880    25.0887    19.0889    26.0Name: Age, Length: 342, dtype: float64# 생존자 나이 평균mean1 = train_data[train_data['Survived'] == 1]['Age'].mean()# 사망자 나이 평균mean0 = train_data[train_data['Survived'] == 0]['Age'].mean()print(mean1, mean0)28.343689655172415 30.62617924528302train_data[train_data['Survived'] == 1]['Age'].fillna(mean1) # 생존자 나이 중에 NaN 값이 28.343689655172415으로 대체됨 train_data[train_data['Survived'] == 0]['Age'].fillna(mean0) # 사망자 나이 중에 NaN 값이 30.62617924528302 으로 대체됨0      22.0000004      35.0000005      30.6261796      54.0000007       2.000000         ...    884    25.000000885    39.000000886    27.000000888    30.626179890    32.000000Name: Age, Length: 549, dtype: float64#실제 데이터에 채우고 싶다면 loc 이용하기train_data.loc[train_data['Survived'] == 1, 'Age'] = train_data[train_data['Survived'] == 1]['Age'].fillna(mean1)train_data.loc[train_data['Survived'] == 0, 'Age'] = train_data[train_data['Survived'] == 0]['Age'].fillna(mean0)train_data                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.000000      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.000000      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.000000      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.000000      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.000000      0      0      373450      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      Montvila, Rev. Juozas      male      27.000000      0      0      211536      13.0000      NaN      S              887      888      1      1      Graham, Miss. Margaret Edith      female      19.000000      0      0      112053      30.0000      B42      S              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      30.626179      1      2      W./C. 6607      23.4500      NaN      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.000000      0      0      111369      30.0000      C148      C              890      891      0      3      Dooley, Mr. Patrick      male      32.000000      0      0      370376      7.7500      NaN      Q      891 rows × 12 columnstrain_data[train_data['Age'] == 28.343689655172415] #생존자만 보기 / NaN 값이 바뀐 것을 확인 할수 있다                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  17      18      1      2      Williams, Mr. Charles Eugene      male      28.34369      0      0      244373      13.0000      NaN      S              19      20      1      3      Masselmani, Mrs. Fatima      female      28.34369      0      0      2649      7.2250      NaN      C              28      29      1      3      O'Dwyer, Miss. Ellen \"Nellie\"      female      28.34369      0      0      330959      7.8792      NaN      Q              31      32      1      1      Spencer, Mrs. William Augustus (Marie Eugenie)      female      28.34369      1      0      PC 17569      146.5208      B78      C              32      33      1      3      Glynn, Miss. Mary Agatha      female      28.34369      0      0      335677      7.7500      NaN      Q              36      37      1      3      Mamee, Mr. Hanna      male      28.34369      0      0      2677      7.2292      NaN      C              47      48      1      3      O'Driscoll, Miss. Bridget      female      28.34369      0      0      14311      7.7500      NaN      Q              55      56      1      1      Woolner, Mr. Hugh      male      28.34369      0      0      19947      35.5000      C52      S              65      66      1      3      Moubarek, Master. Gerios      male      28.34369      1      1      2661      15.2458      NaN      C              82      83      1      3      McDermott, Miss. Brigdet Delia      female      28.34369      0      0      330932      7.7875      NaN      Q              107      108      1      3      Moss, Mr. Albert Johan      male      28.34369      0      0      312991      7.7750      NaN      S              109      110      1      3      Moran, Miss. Bertha      female      28.34369      1      0      371110      24.1500      NaN      Q              128      129      1      3      Peter, Miss. Anna      female      28.34369      1      1      2668      22.3583      F E69      C              166      167      1      1      Chibnall, Mrs. (Edith Martha Bowerman)      female      28.34369      0      1      113505      55.0000      E33      S              186      187      1      3      O'Brien, Mrs. Thomas (Johanna \"Hannah\" Godfrey)      female      28.34369      1      0      370365      15.5000      NaN      Q              198      199      1      3      Madigan, Miss. Margaret \"Maggie\"      female      28.34369      0      0      370370      7.7500      NaN      Q              241      242      1      3      Murphy, Miss. Katherine \"Kate\"      female      28.34369      1      0      367230      15.5000      NaN      Q              256      257      1      1      Thorne, Mrs. Gertrude Maybelle      female      28.34369      0      0      PC 17585      79.2000      NaN      C              274      275      1      3      Healy, Miss. Hanora \"Nora\"      female      28.34369      0      0      370375      7.7500      NaN      Q              298      299      1      1      Saalfeld, Mr. Adolphe      male      28.34369      0      0      19988      30.5000      C106      S              300      301      1      3      Kelly, Miss. Anna Katherine \"Annie Kate\"      female      28.34369      0      0      9234      7.7500      NaN      Q              301      302      1      3      McCoy, Mr. Bernard      male      28.34369      2      0      367226      23.2500      NaN      Q              303      304      1      2      Keane, Miss. Nora A      female      28.34369      0      0      226593      12.3500      E101      Q              306      307      1      1      Fleming, Miss. Margaret      female      28.34369      0      0      17421      110.8833      NaN      C              330      331      1      3      McCoy, Miss. Agnes      female      28.34369      2      0      367226      23.2500      NaN      Q              334      335      1      1      Frauenthal, Mrs. Henry William (Clara Heinshei...      female      28.34369      1      0      PC 17611      133.6500      NaN      S              347      348      1      3      Davison, Mrs. Thomas Henry (Mary E Finck)      female      28.34369      1      0      386525      16.1000      NaN      S              358      359      1      3      McGovern, Miss. Mary      female      28.34369      0      0      330931      7.8792      NaN      Q              359      360      1      3      Mockler, Miss. Helen Mary \"Ellie\"      female      28.34369      0      0      330980      7.8792      NaN      Q              367      368      1      3      Moussa, Mrs. (Mantoura Boulos)      female      28.34369      0      0      2626      7.2292      NaN      C              368      369      1      3      Jermyn, Miss. Annie      female      28.34369      0      0      14313      7.7500      NaN      Q              375      376      1      1      Meyer, Mrs. Edgar Joseph (Leila Saks)      female      28.34369      1      0      PC 17604      82.1708      NaN      C              431      432      1      3      Thorneycroft, Mrs. Percival (Florence Kate White)      female      28.34369      1      0      376564      16.1000      NaN      S              444      445      1      3      Johannesen-Bratthammer, Mr. Bernt      male      28.34369      0      0      65306      8.1125      NaN      S              457      458      1      1      Kenyon, Mrs. Frederick R (Marion)      female      28.34369      1      0      17464      51.8625      D21      S              507      508      1      1      Bradley, Mr. George (\"George Arthur Brayton\")      male      28.34369      0      0      111427      26.5500      NaN      S              533      534      1      3      Peter, Mrs. Catherine (Catherine Rizk)      female      28.34369      0      2      2668      22.3583      NaN      C              547      548      1      2      Padro y Manent, Mr. Julian      male      28.34369      0      0      SC/PARIS 2146      13.8625      NaN      C              573      574      1      3      Kelly, Miss. Mary      female      28.34369      0      0      14312      7.7500      NaN      Q              596      597      1      2      Leitch, Miss. Jessie Wills      female      28.34369      0      0      248727      33.0000      NaN      S              612      613      1      3      Murphy, Miss. Margaret Jane      female      28.34369      1      0      367230      15.5000      NaN      Q              643      644      1      3      Foo, Mr. Choong      male      28.34369      0      0      1601      56.4958      NaN      S              653      654      1      3      O'Leary, Miss. Hanora \"Norah\"      female      28.34369      0      0      330919      7.8292      NaN      Q              669      670      1      1      Taylor, Mrs. Elmer Zebley (Juliet Cummins Wright)      female      28.34369      1      0      19996      52.0000      C126      S              692      693      1      3      Lam, Mr. Ali      male      28.34369      0      0      1601      56.4958      NaN      S              697      698      1      3      Mullens, Miss. Katherine \"Katie\"      female      28.34369      0      0      35852      7.7333      NaN      Q              709      710      1      3      Moubarek, Master. Halim Gonios (\"William George\")      male      28.34369      1      1      2661      15.2458      NaN      C              727      728      1      3      Mannion, Miss. Margareth      female      28.34369      0      0      36866      7.7375      NaN      Q              740      741      1      1      Hawksford, Mr. Walter James      male      28.34369      0      0      16988      30.0000      D45      S              828      829      1      3      McCormack, Mr. Thomas Joseph      male      28.34369      0      0      367228      7.7500      NaN      Q              839      840      1      1      Marechal, Mr. Pierre      male      28.34369      0      0      11774      29.7000      C47      C              849      850      1      1      Goldenberg, Mrs. Samuel L (Edwiga Grabowska)      female      28.34369      1      0      17453      89.1042      C92      C      train_data[train_data['Age'] == 30.62617924528302] #사망자만 보기 / NaN 값이 바뀐 것을 확인 할수 있다                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  5      6      0      3      Moran, Mr. James      male      30.626179      0      0      330877      8.4583      NaN      Q              26      27      0      3      Emir, Mr. Farred Chehab      male      30.626179      0      0      2631      7.2250      NaN      C              29      30      0      3      Todoroff, Mr. Lalio      male      30.626179      0      0      349216      7.8958      NaN      S              42      43      0      3      Kraeff, Mr. Theodor      male      30.626179      0      0      349253      7.8958      NaN      C              45      46      0      3      Rogers, Mr. William John      male      30.626179      0      0      S.C./A.4. 23567      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              859      860      0      3      Razi, Mr. Raihed      male      30.626179      0      0      2629      7.2292      NaN      C              863      864      0      3      Sage, Miss. Dorothy Edith \"Dolly\"      female      30.626179      8      2      CA. 2343      69.5500      NaN      S              868      869      0      3      van Melkebeke, Mr. Philemon      male      30.626179      0      0      345777      9.5000      NaN      S              878      879      0      3      Laleff, Mr. Kristo      male      30.626179      0      0      349217      7.8958      NaN      S              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      30.626179      1      2      W./C. 6607      23.4500      NaN      S      125 rows × 12 columns",
        "url": "/dataframe-nan"
    }
    ,
    
    "dataframe-datacreate": {
        "title": "DataFrame 데이터 생성하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  수치해석 라이브러리인 numpy의 이해 및 사용  데이터 분석 라이브러이인 pandas의 이해 및 사용DataFrame 생성하기  일반적으로 분석을 위한 데이터는 다른 데이터 소스(database, 외부 파일)을 통해 dataframe을 생성  여기서는 실습을 통해, dummy 데이터를 생성하는 방법을 다룰 예정import pandas as pddictionary로 부터 생성하기  dict의 key -&gt; columndata = {'a' : 100, 'b' : 200, 'c' : 300}pd.DataFrame(data, index=['x', 'y', 'z'])                  a      b      c                  x      100      200      300              y      100      200      300              z      100      200      300      data = {'a' : [1, 2, 3], 'b' : [4, 5, 6], 'c' : [10, 11, 12]}pd.DataFrame(data, index=[0, 1, 2])                  a      b      c                  0      1      4      10              1      2      5      11              2      3      6      12      Series로 부터 생성하기  각 Series의 인덱스 -&gt; columna = pd.Series([100, 200, 300], ['a', 'b', 'c'])b = pd.Series([101, 201, 301], ['a', 'b', 'c'])c = pd.Series([110, 210, 310], ['a', 'b', 'c'])pd.DataFrame([a, b, c], index=[100, 101, 102])                  a      b      c                  100      100      200      300              101      101      201      301              102      110      210      310      a = pd.Series([100, 200, 300], ['a', 'b', 'd'])b = pd.Series([101, 201, 301], ['a', 'b', 'k'])c = pd.Series([110, 210, 310], ['a', 'b', 'c'])pd.DataFrame([a, b, c], index=[100, 101, 102])                  a      b      d      k      c                  100      100.0      200.0      300.0      NaN      NaN              101      101.0      201.0      NaN      301.0      NaN              102      110.0      210.0      NaN      NaN      310.0      ",
        "url": "/dataframe-datacreate"
    }
    ,
    
    "dataframe-data": {
        "title": "DataFrame 데이터 살펴보기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  Dataframe data 살펴보기DataFrame  Series가 1차원이라면 DataFrame은 2차원으로 확대된 버젼  Excel spreadsheet이라고 생각하면 이해하기 쉬움  2차원이기 때문에 인덱스가 row, column로 구성됨  row는 각 개별 데이터를, column은 개별 속성을 의미  Data Analysis, Machine Learning에서 data 변형을 위해 가장 많이 사용import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')head, tail 함수  데이터 전체가 아닌, 일부(처음부터, 혹은 마지막부터)를 간단히 보기 위한 함수train_data.head(n=6)                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S              5      6      0      3      Moran, Mr. James      male      NaN      0      0      330877      8.4583      NaN      Q      train_data.tail(n=10)                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  881      882      0      3      Markun, Mr. Johann      male      33.0      0      0      349257      7.8958      NaN      S              882      883      0      3      Dahlberg, Miss. Gerda Ulrika      female      22.0      0      0      7552      10.5167      NaN      S              883      884      0      2      Banfield, Mr. Frederick James      male      28.0      0      0      C.A./SOTON 34068      10.5000      NaN      S              884      885      0      3      Sutehall, Mr. Henry Jr      male      25.0      0      0      SOTON/OQ 392076      7.0500      NaN      S              885      886      0      3      Rice, Mrs. William (Margaret Norton)      female      39.0      0      5      382652      29.1250      NaN      Q              886      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.0000      NaN      S              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.4500      NaN      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C              890      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.7500      NaN      Q      dataframe 데이터 파악하기  shape 속성 (row, column)  describe 함수 - 숫자형 데이터의 통계치 계산  info 함수 - 데이터 타입, 각 아이템의 개수 등 출력train_data.shape(891, 12)train_data.describe()                  PassengerId      Survived      Pclass      Age      SibSp      Parch      Fare                  count      891.000000      891.000000      891.000000      714.000000      891.000000      891.000000      891.000000              mean      446.000000      0.383838      2.308642      29.699118      0.523008      0.381594      32.204208              std      257.353842      0.486592      0.836071      14.526497      1.102743      0.806057      49.693429              min      1.000000      0.000000      1.000000      0.420000      0.000000      0.000000      0.000000              25%      223.500000      0.000000      2.000000      20.125000      0.000000      0.000000      7.910400              50%      446.000000      0.000000      3.000000      28.000000      0.000000      0.000000      14.454200              75%      668.500000      1.000000      3.000000      38.000000      1.000000      0.000000      31.000000              max      891.000000      1.000000      3.000000      80.000000      8.000000      6.000000      512.329200      train_data.info()&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns): #   Column       Non-Null Count  Dtype  ---  ------       --------------  -----   0   PassengerId  891 non-null    int64   1   Survived     891 non-null    int64   2   Pclass       891 non-null    int64   3   Name         891 non-null    object  4   Sex          891 non-null    object  5   Age          714 non-null    float64 6   SibSp        891 non-null    int64   7   Parch        891 non-null    int64   8   Ticket       891 non-null    object  9   Fare         891 non-null    float64 10  Cabin        204 non-null    object  11  Embarked     889 non-null    object dtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KB",
        "url": "/dataframe-data"
    }
    ,
    
    "dataframe-column": {
        "title": "DataFrame 원하는 column(컬럼)만 선택하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  dataframe column 선택하기column 선택하기  기본적으로 [ ]는 column을 추출  컬럼 인덱스일 경우 인덱스의 리스트 사용 가능          리스트를 전달할 경우 결과는 Dataframe      하나의 컬럼명을 전달할 경우 결과는 Series      import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      하나의 컬럼 선택하기train_data['Survived'] #컬럼명 꼭 써주자!0      01      12      13      14      0      ..886    0887    1888    0889    1890    0Name: Survived, Length: 891, dtype: int64복수의 컬럼 선택하기train_data[['Survived', 'Name', 'Age', 'Embarked']]                  Survived      Name      Age      Embarked                  0      0      Braund, Mr. Owen Harris      22.0      S              1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      38.0      C              2      1      Heikkinen, Miss. Laina      26.0      S              3      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      35.0      S              4      0      Allen, Mr. William Henry      35.0      S              ...      ...      ...      ...      ...              886      0      Montvila, Rev. Juozas      27.0      S              887      1      Graham, Miss. Margaret Edith      19.0      S              888      0      Johnston, Miss. Catherine Helen \"Carrie\"      NaN      S              889      1      Behr, Mr. Karl Howell      26.0      C              890      0      Dooley, Mr. Patrick      32.0      Q      891 rows × 4 columns",
        "url": "/dataframe-column"
    }
    ,
    
    "dataframe-colcorrelation": {
        "title": "DataFrame column(컬럼)간 상관관계 계산하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  corr 함수 이용하기import pandas as pdimport matplotlib.pyplot as plt%matplotlib inline # data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      변수(column) 사이의 상관계수(correlation)  corr함수를 통해 상관계수 연산 (-1, 1 사이의 결과)          연속성(숫자형)데이터에 대해서만 연산      인과관계를 의미하진 않음      train_data.corr() #1에 가까울 수록 인과관계가 크다는 의미                  PassengerId      Survived      Pclass      Age      SibSp      Parch      Fare                  PassengerId      1.000000      -0.005007      -0.035144      0.036847      -0.057527      -0.001652      0.012658              Survived      -0.005007      1.000000      -0.338481      -0.077221      -0.035322      0.081629      0.257307              Pclass      -0.035144      -0.338481      1.000000      -0.369226      0.083081      0.018443      -0.549500              Age      0.036847      -0.077221      -0.369226      1.000000      -0.308247      -0.189119      0.096067              SibSp      -0.057527      -0.035322      0.083081      -0.308247      1.000000      0.414838      0.159651              Parch      -0.001652      0.081629      0.018443      -0.189119      0.414838      1.000000      0.216225              Fare      0.012658      0.257307      -0.549500      0.096067      0.159651      0.216225      1.000000      plt.matshow(train_data.corr()) # 색깔이 밝을 수록 관계가 깊다&lt;matplotlib.image.AxesImage at 0x7fe2108b8860&gt;",
        "url": "/dataframe-colcorrelation"
    }
    ,
    
    "dataframe-coladd": {
        "title": "DataFrame에 column(컬럼) 추가,삭제하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  Dataframe에 새로운 colum을 추가하기  Dataframe에 column 삭제하기import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      새 column 추가하기  [] 사용하여 추가하기  insert 함수 사용하여 원하는 위치에 추가하기train_data['Age_double'] = train_data['Age'] * 2 #Age_double 칼럼 생성시킴train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age_double                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      44.0              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      76.0              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      52.0              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      70.0              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      70.0      train_data['Age_tripple'] = train_data['Age_double'] + train_data['Age']train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age_double      Age_tripple                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      44.0      66.0              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      76.0      114.0              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      52.0      78.0              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      70.0      105.0              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      70.0      105.0      train_data.insert(3, 'Fare10', train_data['Fare'] / 10) #insert으로 3 index 에 Fare10 컬럼 만들어짐 train_data.head()                  PassengerId      Survived      Pclass      Fare10      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age_double      Age_tripple                  0      1      0      3      0.72500      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      44.0      66.0              1      2      1      1      7.12833      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      76.0      114.0              2      3      1      3      0.79250      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      52.0      78.0              3      4      1      1      5.31000      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      70.0      105.0              4      5      0      3      0.80500      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      70.0      105.0      column 삭제하기  drop 함수 사용하여 삭제          리스트를 사용하여 멀티플 삭제 가능      train_data.drop('Age_tripple', axis=1) #원본데이터는 남아있음train_data.head()                  PassengerId      Survived      Pclass      Fare10      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age_double      Age_tripple                  0      1      0      3      0.72500      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      44.0      66.0              1      2      1      1      7.12833      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      76.0      114.0              2      3      1      3      0.79250      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      52.0      78.0              3      4      1      1      5.31000      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      70.0      105.0              4      5      0      3      0.80500      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      70.0      105.0      train_data.drop(['Age_double', 'Age_tripple'], axis=1) #axis: index와 column 중에서 어디에서 삭제를 할지 결정합니다.axis =0 이면 index에서 삭제를 하고 1이면 column에서 삭제를 합니다 .train_data.head()                  PassengerId      Survived      Pclass      Fare10      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked      Age_double      Age_tripple                  0      1      0      3      0.72500      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S      44.0      66.0              1      2      1      1      7.12833      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C      76.0      114.0              2      3      1      3      0.79250      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S      52.0      78.0              3      4      1      1      5.31000      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S      70.0      105.0              4      5      0      3      0.80500      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      70.0      105.0      train_data.drop(['Age_double', 'Age_tripple'], axis=1, inplace=True)train_data                  PassengerId      Survived      Pclass      Fare10      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      0.72500      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      7.12833      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      0.79250      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      5.31000      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      0.80500      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      1.30000      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.0000      NaN      S              887      888      1      1      3.00000      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S              888      889      0      3      2.34500      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.4500      NaN      S              889      890      1      1      3.00000      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C              890      891      0      3      0.77500      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.7500      NaN      Q      891 rows × 13 columns",
        "url": "/dataframe-coladd"
    }
    ,
    
    "dataframe-booleansele": {
        "title": "DataFrame Boolean Selection으로 데이터 선택하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  Dataframe boolean selection 이해하기import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      boolean selection으로 row 선택하기  numpy에서와 동일한 방식으로 해당 조건에 맞는 row만 선택30대이면서 1등석에 탄 사람 선택하기class_ = train_data['Pclass'] == 1age_ = (train_data['Age'] &gt;= 30) &amp; (train_data['Age'] &lt; 40)train_data[class_ &amp; age_]                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              61      62      1      1      Icard, Miss. Amelie      female      38.0      0      0      113572      80.0000      B28      NaN              137      138      0      1      Futrelle, Mr. Jacques Heath      male      37.0      1      0      113803      53.1000      C123      S              215      216      1      1      Newell, Miss. Madeleine      female      31.0      1      0      35273      113.2750      D36      C              218      219      1      1      Bazzani, Miss. Albina      female      32.0      0      0      11813      76.2917      D15      C              224      225      1      1      Hoyt, Mr. Frederick Maxfield      male      38.0      1      0      19943      90.0000      C93      S              230      231      1      1      Harris, Mrs. Henry Birkhardt (Irene Wallach)      female      35.0      1      0      36973      83.4750      C83      S              248      249      1      1      Beckwith, Mr. Richard Leonard      male      37.0      1      1      11751      52.5542      D35      S              257      258      1      1      Cherry, Miss. Gladys      female      30.0      0      0      110152      86.5000      B77      S              258      259      1      1      Ward, Miss. Anna      female      35.0      0      0      PC 17755      512.3292      NaN      C              269      270      1      1      Bissette, Miss. Amelia      female      35.0      0      0      PC 17760      135.6333      C99      S              273      274      0      1      Natsch, Mr. Charles H      male      37.0      0      1      PC 17596      29.7000      C118      C              309      310      1      1      Francatelli, Miss. Laura Mabel      female      30.0      0      0      PC 17485      56.9292      E36      C              318      319      1      1      Wick, Miss. Mary Natalie      female      31.0      0      2      36928      164.8667      C7      S              325      326      1      1      Young, Miss. Marie Grice      female      36.0      0      0      PC 17760      135.6333      C32      C              332      333      0      1      Graham, Mr. George Edward      male      38.0      0      1      PC 17582      153.4625      C91      S              383      384      1      1      Holverson, Mrs. Alexander Oskar (Mary Aline To...      female      35.0      1      0      113789      52.0000      NaN      S              390      391      1      1      Carter, Mr. William Ernest      male      36.0      1      2      113760      120.0000      B96 B98      S              412      413      1      1      Minahan, Miss. Daisy E      female      33.0      1      0      19928      90.0000      C78      Q              447      448      1      1      Seward, Mr. Frederic Kimber      male      34.0      0      0      113794      26.5500      NaN      S              452      453      0      1      Foreman, Mr. Benjamin Laventall      male      30.0      0      0      113051      27.7500      C111      C              486      487      1      1      Hoyt, Mrs. Frederick Maxfield (Jane Anne Forby)      female      35.0      1      0      19943      90.0000      C93      S              512      513      1      1      McGough, Mr. James Robert      male      36.0      0      0      PC 17473      26.2875      E25      S              520      521      1      1      Perreault, Miss. Anne      female      30.0      0      0      12749      93.5000      B73      S              537      538      1      1      LeRoy, Miss. Bertha      female      30.0      0      0      PC 17761      106.4250      NaN      C              540      541      1      1      Crosby, Miss. Harriet R      female      36.0      0      2      WE/P 5735      71.0000      B22      S              558      559      1      1      Taussig, Mrs. Emil (Tillie Mandelbaum)      female      39.0      1      1      110413      79.6500      E67      S              572      573      1      1      Flynn, Mr. John Irwin (\"Irving\")      male      36.0      0      0      PC 17474      26.3875      E25      S              577      578      1      1      Silvey, Mrs. William Baird (Alice Munger)      female      39.0      1      0      13507      55.9000      E44      S              581      582      1      1      Thayer, Mrs. John Borland (Marian Longstreth M...      female      39.0      1      1      17421      110.8833      C68      C              583      584      0      1      Ross, Mr. John Hugo      male      36.0      0      0      13049      40.1250      A10      C              604      605      1      1      Homer, Mr. Harry (\"Mr E Haven\")      male      35.0      0      0      111426      26.5500      NaN      C              632      633      1      1      Stahelin-Maeglin, Dr. Max      male      32.0      0      0      13214      30.5000      B50      C              671      672      0      1      Davidson, Mr. Thornton      male      31.0      1      0      F.C. 12750      52.0000      B71      S              679      680      1      1      Cardeza, Mr. Thomas Drake Martinez      male      36.0      0      1      PC 17755      512.3292      B51 B53 B55      C              690      691      1      1      Dick, Mr. Albert Adrian      male      31.0      1      0      17474      57.0000      B20      S              701      702      1      1      Silverthorne, Mr. Spencer Victor      male      35.0      0      0      PC 17475      26.2875      E24      S              716      717      1      1      Endres, Miss. Caroline Louise      female      38.0      0      0      PC 17757      227.5250      C45      C              737      738      1      1      Lesurer, Mr. Gustave J      male      35.0      0      0      PC 17755      512.3292      B101      C              741      742      0      1      Cavendish, Mr. Tyrell William      male      36.0      1      0      19877      78.8500      C46      S              759      760      1      1      Rothes, the Countess. of (Lucy Noel Martha Dye...      female      33.0      0      0      110152      86.5000      B77      S              763      764      1      1      Carter, Mrs. William Ernest (Lucile Polk)      female      36.0      1      2      113760      120.0000      B96 B98      S              806      807      0      1      Andrews, Mr. Thomas Jr      male      39.0      0      0      112050      0.0000      A36      S              809      810      1      1      Chambers, Mrs. Norman Campbell (Bertha Griggs)      female      33.0      1      0      113806      53.1000      E8      S              822      823      0      1      Reuchlin, Jonkheer. John George      male      38.0      0      0      19972      0.0000      NaN      S              835      836      1      1      Compton, Miss. Sara Rebecca      female      39.0      1      1      PC 17756      83.1583      E49      C              842      843      1      1      Serepeca, Miss. Augusta      female      30.0      0      0      113798      31.0000      NaN      C              867      868      0      1      Roebling, Mr. Washington Augustus II      male      31.0      0      0      PC 17590      50.4958      A24      S              872      873      0      1      Carlsson, Mr. Frans Olof      male      33.0      0      0      695      5.0000      B51 B53 B55      S      남자이면서 1등석에 탄 사람 선택하기class_ = train_data['Pclass'] == 1age_ = train_data['Sex'] == 'male'train_data[class_ &amp; age_]                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  6      7      0      1      McCarthy, Mr. Timothy J      male      54.0      0      0      17463      51.8625      E46      S              23      24      1      1      Sloper, Mr. William Thompson      male      28.0      0      0      113788      35.5000      A6      S              27      28      0      1      Fortune, Mr. Charles Alexander      male      19.0      3      2      19950      263.0000      C23 C25 C27      S              30      31      0      1      Uruchurtu, Don. Manuel E      male      40.0      0      0      PC 17601      27.7208      NaN      C              34      35      0      1      Meyer, Mr. Edgar Joseph      male      28.0      1      0      PC 17604      82.1708      NaN      C              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              839      840      1      1      Marechal, Mr. Pierre      male      NaN      0      0      11774      29.7000      C47      C              857      858      1      1      Daly, Mr. Peter Denis      male      51.0      0      0      113055      26.5500      E17      S              867      868      0      1      Roebling, Mr. Washington Augustus II      male      31.0      0      0      PC 17590      50.4958      A24      S              872      873      0      1      Carlsson, Mr. Frans Olof      male      33.0      0      0      695      5.0000      B51 B53 B55      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C      122 rows × 12 columns",
        "url": "/dataframe-booleansele"
    }
    ,
    
    "csv-dataframe": {
        "title": "샘플 csv 데이터로 DataFrame 데이터 생성하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  수치해석 라이브러리인 numpy의 이해 및 사용  데이터 분석 라이브러이인 pandas의 이해 및 사용csv 데이터로 부터 Dataframe 생성  데이터 분석을 위해, dataframe을 생성하는 가장 일반적인 방법  데이터 소스로부터 추출된 csv(comma separated values) 파일로부터 생성  pandas.read_csv 함수 사용import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      read_csv 함수 파라미터  sep - 각 데이터 값을 구별하기 위한 구분자(separator) 설정  header - header를 무시할 경우, None 설정  index_col - index로 사용할 column 설정  usecols - 실제로 dataframe에 로딩할 columns만 설정train_data = pd.read_csv('./train.csv', sep=',')train_data                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      Montvila, Rev. Juozas      male      27.0      0      0      211536      13.0000      NaN      S              887      888      1      1      Graham, Miss. Margaret Edith      female      19.0      0      0      112053      30.0000      B42      S              888      889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN      1      2      W./C. 6607      23.4500      NaN      S              889      890      1      1      Behr, Mr. Karl Howell      male      26.0      0      0      111369      30.0000      C148      C              890      891      0      3      Dooley, Mr. Patrick      male      32.0      0      0      370376      7.7500      NaN      Q      891 rows × 12 columnstrain_data = pd.read_csv('./train.csv', index_col='PassengerId', usecols=['PassengerId', 'Survived', 'Pclass', 'Name'])train_data                  Survived      Pclass      Name              PassengerId                                    1      0      3      Braund, Mr. Owen Harris              2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...              3      1      3      Heikkinen, Miss. Laina              4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)              5      0      3      Allen, Mr. William Henry              ...      ...      ...      ...              887      0      2      Montvila, Rev. Juozas              888      1      1      Graham, Miss. Margaret Edith              889      0      3      Johnston, Miss. Catherine Helen \"Carrie\"              890      1      1      Behr, Mr. Karl Howell              891      0      3      Dooley, Mr. Patrick      891 rows × 3 columnstrain_data.columnsIndex(['Survived', 'Pclass', 'Name'], dtype='object')train_data = pd.read_csv('./train.csv', index_col='PassengerId', usecols=['PassengerId','Name','Sex','Age'])train_data                  Name      Sex      Age              PassengerId                                    1      Braund, Mr. Owen Harris      male      22.0              2      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0              3      Heikkinen, Miss. Laina      female      26.0              4      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0              5      Allen, Mr. William Henry      male      35.0              ...      ...      ...      ...              887      Montvila, Rev. Juozas      male      27.0              888      Graham, Miss. Margaret Edith      female      19.0              889      Johnston, Miss. Catherine Helen \"Carrie\"      female      NaN              890      Behr, Mr. Karl Howell      male      26.0              891      Dooley, Mr. Patrick      male      32.0      891 rows × 3 columnstrain_data.columnsIndex(['Name', 'Sex', 'Age'], dtype='object')",
        "url": "/csv-dataframe"
    }
    ,
    
    "catagoricaldata-onehot": {
        "title": "범주형 데이터 전처리 하기(one-hot encoding)",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  범주형 데이터 전처리 하기(one-hot encoding)import pandas as pd# data 출처: https://www.kaggle.com/hesh97/titanicdataset-traincsv/datatrain_data = pd.read_csv('./train.csv')train_data.head()                  PassengerId      Survived      Pclass      Name      Sex      Age      SibSp      Parch      Ticket      Fare      Cabin      Embarked                  0      1      0      3      Braund, Mr. Owen Harris      male      22.0      1      0      A/5 21171      7.2500      NaN      S              1      2      1      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      female      38.0      1      0      PC 17599      71.2833      C85      C              2      3      1      3      Heikkinen, Miss. Laina      female      26.0      0      0      STON/O2. 3101282      7.9250      NaN      S              3      4      1      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      female      35.0      1      0      113803      53.1000      C123      S              4      5      0      3      Allen, Mr. William Henry      male      35.0      0      0      373450      8.0500      NaN      S      One-hot encoding  범주형 데이터는 분석단계에서 계산이 어렵기 때문에 숫자형으로 변경이 필요함  범주형 데이터의 각 범주(category)를 column레벨로 변경  해당 범주에 해당하면 1, 아니면 0으로 채우는 인코딩 기법  pandas.get_dummies 함수 사용          drop_first : 첫번째 카테고리 값은 사용하지 않음      pd.get_dummies(train_data)                  PassengerId      Survived      Pclass      Age      SibSp      Parch      Fare      Name_Abbing, Mr. Anthony      Name_Abbott, Mr. Rossmore Edward      Name_Abbott, Mrs. Stanton (Rosa Hunt)      ...      Cabin_F G73      Cabin_F2      Cabin_F33      Cabin_F38      Cabin_F4      Cabin_G6      Cabin_T      Embarked_C      Embarked_Q      Embarked_S                  0      1      0      3      22.0      1      0      7.2500      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              1      2      1      1      38.0      1      0      71.2833      0      0      0      ...      0      0      0      0      0      0      0      1      0      0              2      3      1      3      26.0      0      0      7.9250      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              3      4      1      1      35.0      1      0      53.1000      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              4      5      0      3      35.0      0      0      8.0500      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      2      27.0      0      0      13.0000      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              887      888      1      1      19.0      0      0      30.0000      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              888      889      0      3      NaN      1      2      23.4500      0      0      0      ...      0      0      0      0      0      0      0      0      0      1              889      890      1      1      26.0      0      0      30.0000      0      0      0      ...      0      0      0      0      0      0      0      1      0      0              890      891      0      3      32.0      0      0      7.7500      0      0      0      ...      0      0      0      0      0      0      0      0      1      0      891 rows × 1731 columnspd.get_dummies(train_data, columns=['Pclass', 'Sex', 'Embarked'], drop_first=False)                  PassengerId      Survived      Name      Age      SibSp      Parch      Ticket      Fare      Cabin      Pclass_1      Pclass_2      Pclass_3      Sex_female      Sex_male      Embarked_C      Embarked_Q      Embarked_S                  0      1      0      Braund, Mr. Owen Harris      22.0      1      0      A/5 21171      7.2500      NaN      0      0      1      0      1      0      0      1              1      2      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      38.0      1      0      PC 17599      71.2833      C85      1      0      0      1      0      1      0      0              2      3      1      Heikkinen, Miss. Laina      26.0      0      0      STON/O2. 3101282      7.9250      NaN      0      0      1      1      0      0      0      1              3      4      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      35.0      1      0      113803      53.1000      C123      1      0      0      1      0      0      0      1              4      5      0      Allen, Mr. William Henry      35.0      0      0      373450      8.0500      NaN      0      0      1      0      1      0      0      1              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      Montvila, Rev. Juozas      27.0      0      0      211536      13.0000      NaN      0      1      0      0      1      0      0      1              887      888      1      Graham, Miss. Margaret Edith      19.0      0      0      112053      30.0000      B42      1      0      0      1      0      0      0      1              888      889      0      Johnston, Miss. Catherine Helen \"Carrie\"      NaN      1      2      W./C. 6607      23.4500      NaN      0      0      1      1      0      0      0      1              889      890      1      Behr, Mr. Karl Howell      26.0      0      0      111369      30.0000      C148      1      0      0      0      1      1      0      0              890      891      0      Dooley, Mr. Patrick      32.0      0      0      370376      7.7500      NaN      0      0      1      0      1      0      1      0      891 rows × 17 columnspd.get_dummies(train_data, columns=['Pclass', 'Sex', 'Embarked'], drop_first=True)                  PassengerId      Survived      Name      Age      SibSp      Parch      Ticket      Fare      Cabin      Pclass_2      Pclass_3      Sex_male      Embarked_Q      Embarked_S                  0      1      0      Braund, Mr. Owen Harris      22.0      1      0      A/5 21171      7.2500      NaN      0      1      1      0      1              1      2      1      Cumings, Mrs. John Bradley (Florence Briggs Th...      38.0      1      0      PC 17599      71.2833      C85      0      0      0      0      0              2      3      1      Heikkinen, Miss. Laina      26.0      0      0      STON/O2. 3101282      7.9250      NaN      0      1      0      0      1              3      4      1      Futrelle, Mrs. Jacques Heath (Lily May Peel)      35.0      1      0      113803      53.1000      C123      0      0      0      0      1              4      5      0      Allen, Mr. William Henry      35.0      0      0      373450      8.0500      NaN      0      1      1      0      1              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              886      887      0      Montvila, Rev. Juozas      27.0      0      0      211536      13.0000      NaN      1      0      1      0      1              887      888      1      Graham, Miss. Margaret Edith      19.0      0      0      112053      30.0000      B42      0      0      0      0      1              888      889      0      Johnston, Miss. Catherine Helen \"Carrie\"      NaN      1      2      W./C. 6607      23.4500      NaN      0      1      0      0      1              889      890      1      Behr, Mr. Karl Howell      26.0      0      0      111369      30.0000      C148      0      0      1      0      0              890      891      0      Dooley, Mr. Patrick      32.0      0      0      370376      7.7500      NaN      0      1      1      1      0      891 rows × 14 columns",
        "url": "/catagoricaldata-onehot"
    }
    ,
    
    "process-miningtype": {
        "title": "프로세스 마이닝의 종류(유형)",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)프로세스 마이닝의 종류 (유형)프로세스 마이닝에는 크게 네 가지 종류가 있다. 프로세스 도출(Process Discovery), 적합도 검사(Conformance Checking), 프로세스 향상(Enhancement)이 바로 그것이다. 이번 포스팅에서는, 이 세 가지 종류에 프로세스 분석 (Process Analysis)를 더하여 네 가지 종류의 프로세스 마이닝에 대해 알아볼 것이다.Process Discovery (프로세스 도출)Process Discovery는 event log로부터 model을 도출하는 것이다.Process Discovery는 프로세스 마이닝에서 가장 중요한 분야로서, 아무런 사전 정보 없이 이벤트 로그로부터 모델을 도출하는 것을 의미한다. 여기서 가장 중요한 것은 아무런 사전 정보 없이이다. 그저 어떤 시스템으로부터 도출되어 저장된 데이터를 이벤트 로그 형태로 가공만 하면, 이로부터 바로 프로세스가 어떻게 흘러갔는지를 이해할 수 있는 것이다. 한 눈에 쉽게 이해할 수 없는 표 혹은 로그 형태로 저장된 데이터를 아래 그림처럼 흐름을 한 눈에 볼 수 있는 형태로 한 번에 바꾸어 준다는 것은 굉장히 놀라운 일이다.Process Discovery를 통해 도출된 프로세스 모델의 예시Process Discovery 방법으로는 Alpha Miner, Heuristic Miner, ILP Miner, Inductive Miner 등이 있다. 이에 대해서는 이후 포스팅에서 다룰 것이다.Conformance Checking (적합도 검사)Conformance Checking은 event log와 model을 비교하여 이들의 적합성을 진단하는 것이다.Conformance Checking이란 도출된 모델이 실제 이벤트 로그와 잘 맞는지를 확인하는 것을 말한다. 앞서 말한 Process Discovery를 통해 어떤 이벤트 로그를 바탕으로 하여 하나의 모델이 도출되었을 것이다. 이 모델이 추후에 발생된 다른 데이터 또한 잘 설명할 수 있는지를 확인하는 과정이라고 할 수 있다. 쉽게 말하면, 도출된 모델의 성능을 데이터를 이용해 검사해보는 것이다. 여기에서 모델은 앞서 말한 프로세스 모델이 될 수도 있고, 조직의 구성을 나타내는 Orgnaizational Model, 조직 내부의 관계를 나타내는 Social Network Model 등 모든 종류의 모델이 될 수 있다. Conformance Checking 방법으로는 Causual footprint, Token-Based Replay, Synchronous Product Net 등이 있다. 이 또한 추후 포스팅에서 다루도록 하겠다.Enhancement (향상)enhancement는 model을 event log의 정보를 이용하여 더 나은 모델로 만드는 것을 말한다.Enhancement는 기존에 존재하는 모델을 새로운 이벤트 로그의 정보를 토대로 하여 더 나은 모델 혹은 확장된 모델로 발전시키는 것을 말한다. 여기에서 더 나은 모델은 성능이 발전된 모델 (Conformance가 더 좋은 것 등)을 말하고 확장된 모델은 병목, 빈도, 소요 시간 등 추가적인 정보를 제공하는 모델을 말한다. Conformance checking은 기존 모델의 문제점을 파악하는 것이었다면, enhancement는 기존 모델을 새로운 모델로 발전시키는 것이라고 할 수 있다.Process Analysis (프로세스 분석)앞서 말한 세 가지 방법을 통해 모델을 도출하고, 이 모델을 진단하여 더 나은 확장된 모델을 만들었다면 이를 분석하여 어떤 방법으로 프로세스를 발전시킬 수 있는지를 알아 보아야 할 것이다. 모델에는 필요 없는 반복되는 activity가 있을 수도 있고, 특정 activity에서 병목 현상이 일어날 수도 있다. 프로세스를 분석하여 문제점을 발견하고, 이를 개선할 수 있는 방법을 제시하는 모든 과정을 Process Analysis라고 한다.",
        "url": "/process-miningtype"
    }
    ,
    
    "process-mining": {
        "title": "프로세스 마이닝(Process Mining)이란?",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)프로세스 마이닝 (Process Mining)이란?“프로세스 마이닝 (Process Mining)이 뭐야? 데이터 마이닝 같은거야?”내가 프로세스 마이닝을 공부한다고 하면 항상 듣는 질문이다. 이 질문을 항상 들었다는 것이 이 블로그를 시작하게 된 이유이기도 하다. 이 질문을 너무 많이 들었기 때문에 요즘은 아예 대답을 준비해 놓는 편이다.“데이터 마이닝의 방법 중 하나라고 생각하면 편해. 하지만 다른 점은 프로세스 그 자체에 좀 더 집중한다는 점이야. 예를 들어서, 공장에서 쇳물이 하나의 철판이 되기까지 굳히기, 펴지기, 자르기 이런 다양한 과정을 거치잖아. 데이터 마이닝이 이런 공정에서 결과적으로 무엇이 일어났는가, 무엇이 일어날 것인가, 왜 일어났는가에 집중한다면, 프로세스 마이닝은 공정 과정(Process) 전체를 분석하고 시각화해서 어떻게 이 공정을 더 효율적으로 개선하고, 발전시킬 수 있는지에 집중하는 학문이야.”프로세스 마이닝은 Data Science 중에서도 Process의 분석과 개선에 집중하는 학문이다.이렇게 대답하면, 대부분의 사람들이 “아, 공장에서 공정 분석을 할 때 이용할 수 있구나.” 하고 좁은 분야에만 적용할 수 있다고 생각하고 만다. 하지만 프로세스는 어디에나 존재한다. 생산, 제조, 물류 등의 당연히 프로세스가 존재할 것이라고 생각되는 분야 뿐만 아니라, 웹 페이지 안에서 사용자가 물건을 구매하기까지의 과정, 병원에서 환자가 접수할 때부터 퇴원할 때까지의 과정, 회사에서 직원들이 일을 받고 처리하기까지의 과정 모두가 시작 단계와 끝 단계를 가지고 있는 프로세스라고 할 수 있다. 모든 프로세스에 대해서 프로세스 마이닝은 힘을 발휘할 수 있다. 달리 말하면, 앞서 말한 모든 과정들이 프로세스 마이닝으로 사용자가 더 효율적으로 물건을 구매하도록, 짧은 시간 내에 더 많은 환자들을 치료할 수 있도록, 직원들이 더 효율적으로 일을 분배할 수 있도록 개선될 수 있다는 것이다.그렇다면 프로세스 마이닝이 해결할 수 있는 문제에는 구체적으로 어떤 것이 있을까? 이는 크게 현재 프로세스에 대한 분석, 문제점 도출 및 개선, 미래 예측으로 나눌 수 있다.첫 번째로 프로세스 마이닝을 통해 현재 프로세스에 대한 분석을 할 수 있다. 프로세스 마이닝은 현재의 IT System에 쌓인 real event data를 기반으로 하기 때문에 현재 프로세스가 실제로 어떻게 진행되고 있는지를 정확하게 파악할 수 있게 해 준다. 또한 이를 보기 좋게 시각화해주어 한 눈에 이를 분석할 수 있도록 도와 준다.프로세스 마이닝은 event data로부터 프로세스를 도출하여 이를 시각화하고 insight를 얻는 과정이다.두 번째로 현재 프로세스의 문제점 도출 및 개선을 할 수 있다. 프로세스 내에서 시간을 오래 차지하는 병목 활동 (Bottleneck)이 무엇인지, 반복 작업 (Rework)은 없는지, 원래 원하던 프로세스에서 벗어난 프로세스 (Deviation)은 없는지 등의 문제점을 쉽게 분석할 수 있고, 이를 토대로 하여 이들을 개선할 수 있게 해 준다. 뿐만 아니라, 프로세스 마이닝과 데이터 마이닝을 결합하여 이런 문제점이 일어난 원인은 무엇이고, 어떤 factor가 이를 일어나게 했는지까지 분석하여 개선안을 도출할 수 있다.세 번째로 프로세스를 기반으로 하여 미래를 예측할 수 있다. 이전의 프로세스 마이닝 결과를 바탕으로 특정 상황에서 어떤 결과가 일어날 것인지, 앞서 언급했던 문제 상황이 일어나지 않게 하려면 어떤 프로세스를 거쳐야하는지 등을 분석할 수 있다.",
        "url": "/process-mining"
    }
    ,
    
    "event-log": {
        "title": "이벤트 로그(event log)란?",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)이벤트 로그(event log)란?이벤트 로그란, 프로세스 마이닝의 가장 기본이 되는 데이터 형태이다. 프로세스 마이닝을 하기 위해서는 이벤트 로그가 반드시 있어야 하기 때문에, 현재 있는 데이터를 프로세스 마이닝에 활용하고 싶다면 이를 이벤트 로그 형태로 바꾸어 주는 것이 필수적이다. 그렇다면, 이벤트 로그란 무엇일까?이벤트 로그의 필수적인 요소이벤트 로그에는 필수적인 요소가 세 가지 있다. 케이스 아이디 (Case ID), 액티비티 (Activity), 타임스탬프 (Timestamp)가 바로 그것이다.예를 들어서, 위의 표처럼 병원에서 환자들의 프로세스가 있다고 하자. 여기에서 환자 5781은 X-ray를 찍고 (make X-ray), CT 촬영을 하고 (CT scan), 병원비를 지불하였고 (handle payment), 환자 5833은 피검사를 한 후 (blood test) 수술을 한다 (surgery). 이렇게 병원 안에서도 수많은 환자들이 각자 다른 일을 하고 병원에서 나갈 것이다. 이러한 각각의 환자 하나하나를 케이스(Case)라고 한다. 각 케이스들은 여러 줄의 데이터를 가질 수 있는데, 이 데이터 한 줄 한 줄, 그러니까 각 프로세스의 과정 하나하나를 이벤트(event)라고 한다. 즉, 이벤트가 모여 하나의 케이스가 되고, 이 케이스들이 모여 이벤트 로그가 되는 것이다.각각의 케이스, 위 표의 경우에는 환자 하나하나를 구별해주는 고유한 값 (이 경우에는 5781, 5833 등)을 케이스 아이디 (Case ID)라고 한다. 다음으로, 이 환자들이 하는 X-ray 찍기, CT 촬영 하기, 병원비 지불 등의 행동들을 액티비티(activity)라고 한다. 그리고 환자들이 행동을 한 시각을 기록한 것을 타임스탬프(timestamp)라고 한다. 즉, 위 예시 로그에서는 patient 컬럼이 Case ID, activity 컬럼이 activity, timestamp 컬럼이 timestamp인 것이다. 이벤트 로그에는 이  Case ID, activity, timestamp가 필수적으로 포함되어야 한다.이벤트 로그의 추가적인 요소위 세 가지의 필수적인 요소 외에도 이벤트 로그에 포함될 수 있는 요소들이 몇 가지 있다. 첫 번째 요소는 리소스(resource)다. 리소스는 보통 해당 작업을 처리한 사람 (위 표의 경우에는 해당 일을 담당한 의사, 직원. doctor 컬럼)이나 부서, 기계 등을 의미한다. 두 번째 요소로는 Transactional information이 있다. 이는 액티비티가 시작되었는지, 종료되었는지, 계획되었는지 등의 정보를 표시하는 것이다. 예를 들어, 하나의 blood test 액티비티가 있더라도 이를 계획한 시각, 시작한 시각, 종료한 시각은 모두 다를 것이다. 이들을 각각 schedule, start, complete 등으로 표시한 컬럼을 transactional information이라고 한다. 나머지 요소는 other data이다. 이들은 각 케이스나 이벤트의 정보를 뜻하는 것으로, 위 표의 경우에는 age, cost 등의 컬럼들이 포함될 수 있다.이벤트 로그의 표시이벤트 로그는 주로 이러한 형태로 표시된다.여기에서 &lt;&gt;는 케이스 내에서 발생한 액티비티의 패턴을 말한다. 즉, &lt;a,b,c,d&gt;는 케이스 내에서 액티비티 a,b,c,d 순서대로 액티비티가 발생했다는 것이다. 이 하나의 패턴을 트레이스(trace)라고 한다. &lt;&gt; 위에 있는 숫자는 해당 패턴을 보이는 케이스가 일어난 횟수를 의미한다. 즉, 전체 이벤트 로그에서 &lt;a,b,c,d&gt; 패턴을 보인 케이스가 3개, &lt;a,c,b,d&gt; 패턴을 보인 케이스가 2개, &lt;a,e,d&gt; 패턴을 보인 케이스가 1개라는 뜻이다.이러한 이벤트 로그 형태의 데이터만 있으면 ProM, PM4Py, Disco 등의 툴을 활용하여 쉽게 프로세스 마이닝을 할 수 있다!!References  Data Sceicne in Action. Coursera. Prof. Wil van der Aalst.",
        "url": "/event-log"
    }
    ,
    
    "nsmc-wordcloud": {
        "title": "NSMC 정제 - wordcloud 와 histogram으로 단어 분포 파악하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)NSMC 정제하기      Naver Sentiment Movie Corpus 영화 리뷰 학습을 통한 감정 예측 구현        감정분석을 위해, Naver Movie Corpus(https://github.com/e9t/nsmc/) 를 사용합니다.  def read_documents(filename):    with open(filename, encoding='utf-8') as f:        documents = [line.split('\\t') for line in f.read().splitlines()]        documents = documents[1:]            return documents    train_docs = read_documents(\"ratings_train.txt\")test_docs = read_documents(\"ratings_test.txt\")print(len(train_docs))print(len(test_docs))15000050000함수 정의.def text_cleaning(doc):    # 한국어를 제외한 글자를 제거하는 함수.    doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)    return docdef define_stopwords(path):        SW = set()    # 불용어를 추가하는 방법 1.    # SW.add(\"있다\")        # 불용어를 추가하는 방법 2.    # stopwords-ko.txt에 직접 추가        with open(path) as f:        for word in f:            SW.add(word)                return SWdef text_tokenizing(doc):    return [word for word in mecab.morphs(doc) if word not in SW and len(word) &gt; 1]        # wordcloud를 위해 명사만 추출하는 경우.    #return [word for word in mecab.nouns(doc) if word not in SW and len(word) &gt; 1]불러온 데이터를 품사 태그를 붙여서 토크나이징합니다.from konlpy.tag import Mecabfrom konlpy.tag import Oktimport jsonimport osimport refrom pprint import pprintokt = Okt()mecab = Mecab(dicpath='C:\\mecab\\mecab-ko-dic')SW = define_stopwords(\"stopwords-ko.txt\")if os.path.exists('train_docs.json'):    with open(\"train_docs.json\", encoding='utf-8') as f:        train_data = json.load(f)else:    train_data = [(text_tokenizing(line[1]), line[2]) for line in train_docs if text_tokenizing(line[1])]#     train_data = []#     for line in train_docs:#         if text_tokenizing(line[1]):#             train_data.append((text_tokenzing(line[1]), line[2]))            with open(\"train_docs.json\", 'w', encoding='utf-8') as f:        json.dump(train_data, f, ensure_ascii=False, indent='\\t')        if os.path.exists('test_docs.json'):    with open(\"test_docs.json\", encoding='utf-8') as f:        test_data = json.load(f)else:    test_data = [(text_tokenizing(line[1]), line[2]) for line in test_docs if text_tokenizing(line[1])]        with open(\"test_docs.json\", 'w', encoding='utf-8') as f:        json.dump(test_data, f, ensure_ascii=False, indent='\\t')pprint(train_data[0])pprint(test_data[0])(['진짜', '짜증', '네요', '목소리'], '0')(['GDNTOPCLASSINTHECLUB'], '0')NLTK를 이용한 histogram 분석.      데이터 분석을 하기 위해 기본적인 정보들을 확인합니다.        nltk 라이브러리를 이용하여 전처리를 합니다.  import nltktotal_tokens = [token for doc in train_data for token in doc[0]]print(len(total_tokens))1206841  examplev = [list(range(10)),[10,11,12]]print(v)[[0,1,2,3,4,5,6,7,8,9],[10,11,12]]for i in v:  for j in i:          print(j)[j for i in v for j in i][0,1,2,3,4,5,6,7,8,9,10,11,12]      example 2    for doc in train_data     for token in doc[0]            print(token)        [token for doc in train_data for token in doc[0]]    *모든 데이터가 모두 출력된다  text = nltk.Text(total_tokens, name='NMSC')print(len(set(text.tokens)))pprint(text.vocab().most_common(10))51722[('영화', 57614), ('..', 22813), ('는데', 11543), ('너무', 11002), ('정말', 9783), ('으로', 9322), ('네요', 9053), ('재밌', 9022), ('지만', 8366), ('진짜', 8326)]Histogram 그리기.import matplotlib.pyplot as pltimport platformfrom matplotlib import font_manager, rc%matplotlib inlinepath = \"c:/Windows/Fonts/malgun.ttf\"if platform.system() == 'Darwin':    rc('font', family='AppleGothic')elif platform.system() == 'Windows':    font_name = font_manager.FontProperties(fname=path).get_name()    rc('font', family=font_name)else:    print('Unknown system... sorry~~~~')plt.figure(figsize=(16, 10))text.plot(50)WordCloud 그리기.from wordcloud import WordClouddata = text.vocab().most_common(100)# for win : font_path='c:/Windows/Fonts/malgun.ttf'wordcloud = WordCloud(font_path='c:/Windows/Fonts/malgun.ttf',                      relative_scaling = 0.2,                      #stopwords=STOPWORDS,                      background_color='white',                      ).generate_from_frequencies(dict(data))plt.figure(figsize=(16,8))plt.imshow(wordcloud)plt.axis(\"off\")plt.show()",
        "url": "/nsmc-wordcloud"
    }
    ,
    
    "nsmc-sentiment": {
        "title": "NSMC 감성분석 - 감정분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)NSMC로 감정 분석(텍스트 분류) 하기  Reference : https://www.kdnuggets.com/2018/03/5-things-sentiment-analysis-classification.html1. 감정분석이란?      Natural Language Processing, Text Analysis, Computational Lingustics, biometrics 같은 방법을 이용하여 텍스트에 숨겨져있는 저자의 의도나 정보를 찾아내는 모든 방법들을 말한다.        Opinion Mining, Sentiment Mining, Subjectivity Analysis 라고도 불리기도 한다.        초반의 방법들은 텍스트의 극성(Polarity)를 찾기 위해 많이 시도되었다. 대표적인 예로 긍정/부정으로 나누는 케이스가 있다.        감정 분석은 크게 Knowledge-based approach, Machine Learning-based approach가 있다.    Knowledge-based는 알려진 어구, 어미, 관용 표현등을 활용하여 이미 문서들을 human expert가 평가한 데이터를 가져와 평가하는 방법이다.  ML-based approach는 supervised, unsupervised 방법이 있다. 최근 pretrained Language Model이 비약적으로 발달함에 따라 unsupervised 방법의 성능도 많이 높아졌지만, 아직까지는 성능면에선 supervised가 월등히 높다.  따라서, 가장 많이 쓰이는 방법인 text classification으로서의 sentiment analysis를 공부해보고, 추가적으로 생각해볼 여러 가지 이슈에 대해 고민해보는 시간을 가진다.2. 텍스트 분류란?      벡터 형태로 표현된 텍스트를 말그대로 분류하는 방법이다.        DNN이 비약적으로 성능 향상을 가져오기 전까지는 SVM이 가장 많이 사용되었다.        현재는 CNN, LSTM을 분류 모델로 가장 많이 사용한다.        실제로 텍스트 분류 작업은 큰 범위에서 대부분의 NLP downstream task를 포함한다.        하나의 예로, Siamese Network라는 걸 통해서 Question-Answering pair를 학습하게 되면, 분류의 기준이 “특정 질문에 맞는 정답을 잘 골랐는가 아닌가(0 / 1)”를 해결하는 문제로 바뀌게 된다.  3. scikit-learn으로 NSMC 감정분석 하기  저번 시간에 했던 코드를 그대로 가져와, nsmc를 불러옵니다.def read_documents(filename):    with open(filename, encoding='utf-8') as f:        documents = [line.split('\\t') for line in f.read().splitlines()]        documents = documents[1:]            return documents    train_docs = read_documents(\"ratings_train.txt\")test_docs = read_documents(\"ratings_test.txt\")print(len(train_docs))print(len(test_docs))15000050000def text_cleaning(doc):    # 한국어를 제외한 글자를 제거하는 함수.        doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)            return docdef define_stopwords(path):        SW = set()    # 불용어를 추가하는 방법 1.    # SW.add(\"있다\")        # 불용어를 추가하는 방법 2.    # stopwords-ko.txt에 직접 추가        with open(path) as f:        for word in f:            SW.add(word)                return SWdef text_tokenizing(doc):    return [word for word in mecab.morphs(doc) if word not in SW and len(word) &gt; 1]        # wordcloud를 위해 명사만 추출하는 경우.    #return [word for word in mecab.nouns(doc) if word not in SW and len(word) &gt; 1]  불러온 데이터를 품사 태그를 붙여서 토크나이징합니다.from konlpy.tag import Mecabfrom konlpy.tag import Oktimport jsonimport osimport refrom pprint import pprintokt = Okt()mecab = Mecab(dicpath='C:\\mecab\\mecab-ko-dic')SW = define_stopwords(\"stopwords-ko.txt\")if os.path.exists('train_docs.json'):    with open(\"train_docs.json\", encoding='utf-8') as f:        train_data = json.load(f)else:    train_data = [(text_tokenizing(text_cleaning(line[1])), line[2]) for line in train_docs if text_tokenizing(line[1])]    #train_data = [(text_tokenizing(line[1]), line[2]) for line in train_docs if text_tokenizing(line[1])]        with open(\"train_docs.json\", 'w', encoding='utf-8') as f:        json.dump(train_data, f, ensure_ascii=False, indent='\\t')        if os.path.exists('test_docs.json'):    with open(\"test_docs.json\", encoding='utf-8') as f:        test_data = json.load(f)else:    test_data = [(text_tokenizing(text_cleaning(line[1])), line[2]) for line in test_docs if text_tokenizing(line[1])]    #test_data = [(text_tokenizing(line[1]), line[2]) for line in test_docs if text_tokenizing(line[1])]    with open(\"test_docs.json\", 'w', encoding='utf-8') as f:        json.dump(test_data, f, ensure_ascii=False, indent='\\t')pprint(train_data[0])pprint(test_data[0])[['진짜', '짜증', '네요', '목소리'], '0'][['GDNTOPCLASSINTHECLUB'], '0']print(train_data[:3])[[['진짜', '짜증', '네요', '목소리'], '0'], [['..', '포스터', '보고', '초딩', '영화', '...', '오버', '연기', '조차', '가볍', '구나'], '1'], [['너무', '밓었다그래서보는것을추천한다'], '0']]      데이터 분석을 하기 위해 기본적인 정보들을 확인합니다.        nltk 라이브러리를 이용하여 전처리를 합니다.  import nltktotal_tokens = [token for doc in train_data for token in doc[0]]print(len(total_tokens))1206841text = nltk.Text(total_tokens, name='NMSC')print(len(set(text.tokens)))pprint(text.vocab().most_common(10))51722[('영화', 57614), ('..', 22813), ('는데', 11543), ('너무', 11002), ('정말', 9783), ('으로', 9322), ('네요', 9053), ('재밌', 9022), ('지만', 8366), ('진짜', 8326)]import matplotlib.pyplot as pltimport platformfrom matplotlib import font_manager, rc%matplotlib inlinepath = \"c:/Windows/Fonts/malgun.ttf\"if platform.system() == 'Darwin':    rc('font', family='AppleGothic')elif platform.system() == 'Windows':    font_name = font_manager.FontProperties(fname=path).get_name()    rc('font', family=font_name)else:    print('Unknown system... sorry~~~~')plt.figure(figsize=(16, 10))text.plot(50)# 여러 리스트들을 하나로 묶어 주는 함수입니다.def list_to_str(List):     return \" \".join(List)4. Linear Classifier와 Support Vector Machine으로 nsmc 분류하기from sklearn.pipeline import Pipeline#파이프라인 개념 =&gt; 데이터 수집부터 전처리,학습 모델 배포,예측까지 전과정을 순차적으로 처리하도록 설계된 머신러닝 아키텍처from sklearn.feature_extraction.text import CountVectorizer# 단어 카운트 (countvectorizer)는 오직 띄어쓰기만을 기준으로 단어를 자른 후에 Bow를 만든다는 점from sklearn.linear_model import SGDClassifier # SGD (Stochastic Gradient descent, 확률적 경사 하강법)from sklearn.svm import SVC#Support Vector Machine(svm)은 데이터 분석 중 분류에 이용되며 지도학습 방식의 모델# SVM은 선형 분류와 비선형 분류를 지원한다.그 중 선형 모델을 위해 kernel을 linear로 지정함# 비선형에 대한 kernel로는 rbf와 poly가 있다#clf = svm.SVC(kernel='linear')from sklearn.naive_bayes import MultinomialNB# 나이브 베이즈 분류는 지도학습의 일종, Feature와 Label이 필요하다#Feature에 따라 Label을 분류하는데 베이즈 정리를 사용하는 것이 특징입니다. 또한 모든 Feature가 서로 독립(independent)이어야 한다는 가정이 필요합니다.# 참고 -https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-1%EB%82%98%EC%9D%B4%EB%B8%8C-%EB%B2%A0%EC%9D%B4%EC%A6%88-%EB%B6%84%EB%A5%98-Naive-Bayes-Classificationimport numpy as nptrain_x = [list_to_str(doc) for doc, _ in train_data]test_x = [list_to_str(doc) for doc, _ in test_data]train_y = [label for _, label in train_data]test_y = [label for _, label in test_data]#print(len(train_x), len(train_y))print(\"For %d train data\" % len(train_x))#print(len(test_x), len(test_y))learner = Pipeline([    ('vect', CountVectorizer()),    ('clf', SGDClassifier(loss='perceptron', penalty='l2',                         alpha=1e-4, random_state=42,                         max_iter=100))])learner2 = Pipeline([    ('vect', CountVectorizer()),    ('clf', SVC(kernel='linear'))    ])learner3 = Pipeline([    ('vect', CountVectorizer()),    ('clf', SVC(kernel='poly', degree=8))])learner4 = Pipeline([    ('vect', CountVectorizer()),    ('clf', SVC(kernel='rbf'))])learner5 = Pipeline([    ('vect', CountVectorizer()),    ('clf', SVC(kernel='sigmoid'))])learner6 = Pipeline([    ('vect', CountVectorizer()),    ('mb', MultinomialNB())])classifier = learner2classifier.fit(train_x, train_y)train_predict = classifier.predict(train_x)train_accuracy = np.mean(train_predict == train_y)test_predict = classifier.predict(test_x)test_accuracy = np.mean(test_predict == test_y)print(\"For %d test data\" % len(test_x))print(\"Training Accuracy : %.2f\" % train_accuracy)print(\"Test Accuracy : %.2f\" % test_accuracy)For 148051 train data&lt; 실험결과 &gt;Linear Classifier 학습하여, test accuracy를 측정. (learner)  명사만 추출 : 0.51  전처리 하지 않고 형태소 분석 : 0.67  전처리 하고 형태소 분석 : 0.71—–여기까진 top 500 features만 사용——–  3 + 모든 feature : 0.76&lt; 실험결과 &gt;SVM Classifier 학습하여, test accuracy를 측정. (learner2)  명사만 추출 : 0.53  전처리 하지 않고 형태소 분석 : 0.72  전처리 하고 형태소 분석 : 0.77—–여기까진 top 500 features만 사용——–  3 + 모든 feature : 0.81",
        "url": "/nsmc-sentiment"
    }
    ,
    
    "gensim-news": {
        "title": "기사 텍스트 정제 - gensim을 이용한 토픽모델링 분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)gensim으로 네이버 기사 토픽 모델링 해보기  토픽 모델링을 적용하기 위해 텍스트를 처리합니다.  토픽 모델링 라이브러리인 gensim을 사용해봅니다.토픽 모델링*토픽(Topic)은 한국어로는 주제라고 합니다. 토픽 모델링(Topic Modeling)이란 기계 학습 및 자연어 처리 분야에서 토픽이라는 문서 집합의 추상적인 주제를 발견하기 위한 통계적 모델 중 하나로, 텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이닝 기법입니다.  문서에서 토픽(키워드)을 찾는 과정  문장을 구성하는 단어 조합으로부터 k개의 단어 묶음을 찾는 과정  베이지안 확률 모델이며 , 토픽 모델링의 결과로 각 단어가 각 토픽에속할 확률이 나옴  잠재 디리클레 할당 (LDA)          각 문서에 여러 개의 토픽이 포함될 수있다      각 토픽에는 여러개의 단어가 포함 될 수 있다      문서에 존재하는 모든 단어는 반드시 어떤 토픽에 포함된다      사람이 글을 쓰는 과정을 생성 모델로 정의한다.*토픽 모델링은 문서의 집합에서 토픽을 찾아내는 프로세스를 말합니다. 이는 검색 엔진, 고객 민원 시스템 등과 같이 문서의 주제를 알아내는 일이 중요한 곳에서 사용됩니다. 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)은 토픽 모델링의 대표적인 알고리즘입니다. 줄여서 LDA라고 합니다.        ** LDA 모델 과정          문서들에 사용할 토픽을 고른다 (K개의 토픽)      토픽 중 하나의 토픽을 고른다      그 토픽에 포함된 단어 중에 하나를 고른다      단어를 문서에 추가한다 (글을 쓴다)      B번 과정부터 반복한다.      # !pip install gensim# !pip install pickle-mixin  gensim 설치자연어를 벡터로 변환하는데 필요한 대부분의 편의기능을 제공하고 있는 라이브러리Word2vec도 포함(Word2vec : word를 vector로 바꿔주는 테크닉)1. 토픽 모델링을 위한 라이브러리 불러오기from tqdm import tqdm_notebook # 진행상황을 progress bar 형태로 한눈에 확인할 수 있다from konlpy.tag import Mecab #Mecab, Okt 등 형태소 분석기 불러오기import numpy as npimport string # 특수문자import reimport warnings # 경고 알림 제거import pickle ## 리스트나 클래스 같은 텍스트가 아닌 자료형을 파일로 저장하기 위해 pickle 모듈 사용함 import pandas as pd#gensim 라이브러리 불러오기 from gensim import corporafrom gensim import modelsimport matplotlib.pyplot as plt%matplotlib inlinewarnings.filterwarnings(\"ignore\", category=DeprecationWarning) # 경고 알림이 뜨면 모두 무시합니다.C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package &lt;https://pypi.org/project/python-Levenshtein/&gt; is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.  warnings.warn(msg)# pickle 파일 읽기%time new_df = pd.read_pickle(\"naver_news_content.pk\") #pickle 파일 읽기 new_dfWall time: 4 ms[['   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t[스포츠경향]  안양대학교 대학일자리센터가 디지털 기초 이해도 확보 및 최신 트렌드에 맞는  IT 역량 강화를 위한 ‘코딩학개론’ 프로그램을 진행한다고  16 일 밝혔다.  10 월  11 일까지 3개월간 진행되는 이번 프로그램은 ‘코드잇’과 연계한 것으로,   IT  실무에서 많이 쓰이는 파이썬 기초, 머신 러닝, 웹퍼블리싱 등으로 교육과정을 구성하고, 학생들이 원하는 과목을 신청하여 자유롭게 수강하도록 개설된 것이 특징이다. 코드잇은 국내에서 유일하게 외주 제작 없이 대기업·아이비리그 출신 개발자들이 콘텐츠를 직접 기획, 제작해 유기적으로 연결된 강의를 제작하는 기업. 최근 글로벌 서비스를 개시해 국내뿐만 아니라 해외에도 높은 수준의 코딩 강의를 제공하고 있으며 높은 고객만족도와 향후 성장 가능성을 인정받아  2021 년 중소벤처기업부의 ‘아기 유니콘 기업’으로 선정되기도 했다.  이번 프로그램은 전공자, 비전공자 관계없이 코딩에 관심 있는 재학생 누구나 신청할 수 있으며 수강률  80 %이상, 기말평가  60 점 이상 달성 시 수료증이 발급된다. 김현태 대학일자리센터 팀장은 “4차 산업시대에 빠르게 변하는 트렌드에 맞춰 전공자들의 실질적인  IT 역량 강화와 비전공자들의 디지털 기초 이해도 확보가 기대된다”고 말했다. 앞서 안양대는 지난해 ‘대학일자리센터’ 개소식을 갖고 폭넓은 진로탐색지원, 맞춤형 진로 선택 지원, 구직활동 지원, 취업경쟁력 강화를 목표로 재학생 뿐만 아니라 지역 청년들의 진로와 취·창업을 위해 다양한 프로그램 운영에 박차를 가하고 있다.    // 본문 내용   ',  '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t안양대학교 대학일자리센터는 최근 디지털 기초 이해도 확보와 최신 트렌드에 맞는  IT 역량 강화를 위해 \\'코딩학개론\\' 프로그램을 실시한다고  16 일 밝혔다.  이번 교육은 \\'코드잇\\'과 연계해 오는  10 월  11 일까지 3개월간  IT  실무에서 많이 쓰이는 파이썬 기초, 머신 러닝, 웹퍼블리싱 등으로 교육과정을 구성하고 학생들이 원하는 과목을 신청해 자유롭게 수강하도록 개설됐다. \\'코드잇\\'은 국내에서 유일하게 외주 제작 없이 대기업·아이비리그 출신 개발자들이 콘텐츠를 직접 기획·제작해 유기적으로 연결된 강의를 제작하는 기업이다.  최근 글로벌 서비스를 개시해 국내뿐만 아니라 해외에도 높은 수준의 코딩 강의를 제공하고 있다. 높은 고객만족도와 향후 성장 가능성을 인정받아 올해 중소벤처기업부의 \\'아기 유니콘 기업\\'으로도 선정됐다. 이번 프로그램은 (비)전공자 관계없이 코딩에 관심 있는 재학생 누구나 신청할 수 있다. 수강률  80 %이상, 기말평가  60 점 이상 달성 시 수료증이 발급된다. 김현태 대학일자리센터 팀장은 \"이번 교육을 통해 4차 산업시대에 빠르게 변하는 트렌드에 맞춰 전공자들의 실질적인  IT 역량 강화와 비전공자들의 디지털 기초 이해도 확보가 기대된다\"고 말했다. 한편 안양대는 지난해 \\'대학일자리센터\\' 개소식을 갖고 폭넓은 진로탐색지원, 맞춤형 진로 선택 지원, 구직활동 지원, 취업경쟁력 강화를 목표로 재학생 뿐만 아니라 지역 청년의 진로와 취·창업을 위한 다양한 프로그램을 운영하고 있다. article_split    // 본문 내용   ',  '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    [디지털데일리 이종현기자] 안랩은 지난  15 일 디지털 직무 교육 사회공헌 프로그램 ‘안랩샘’의  12 기 수료식을 온라인으로 실시한다고  16 일 밝혔다.     안랩샘  12 기에서는 ▲파이썬·인공지능( AI ) 교육 강사 ▲아두이노 ·AI  교육 강사 ▲증강현실/가상현실( AR / VR ) 실감 콘텐츠 기획자 과정 ▲프로젝트 매니저 과정 ▲소셜벤처 창업 과정 ▲소셜미디어 마케터 과정 ▲웹퍼블리셔 과정 ▲ PBL ( Problem / Project   Based   Learning ) 퍼실리테이터 과정 ▲ PR/ 커뮤니케이터 과정 등 9개 교육과정에서  110 명의 수료생을 배출했다.      안랩은 안랩샘  12 기 수료생 중 희망자를 선발해 온라인 러닝코스 개설 지원, 자체 교육 프로그램(안랩샘, 맘잡고 등) 강사/보조강사 우대 채용, 공부방 창업자 교육용품 지원 등 수료 이후 경력개발을 위한 후속 지원 프로그램을 이어 나갈 예정이다.     안랩샘  12 기 파이썬 ·AI  교육 강사 과정을 수료한 김미영 수료생은 “오랜 경력단절로 사회 재진출을 주저하다가 안랩샘을 알게 돼 교육에 성실히 참여했다”며 “안랩샘의 직무 교육으로 이번에 소프트웨어( SW ) 교육강사로 채용돼 경력을 이어갈 수 있게 됐다”고 말했다.     강석균 안랩 대표는 인사말에서 ”일상 생활이 디지털로 재편되고 있는 만큼 안랩샘 교육과정에서 배운 디지털 역량으로 안랩샘 수료생 모두가 ‘디지털 트랜스포메이션’ 시대에 활약하길 기대한다”고 말했다. \\t  // 본문 내용   ']]2. 텍스트 전처리 함수 만들기     -stopwords-ko.txt 텍스트파일 ANSI 형식으로 인코딩 해주기     - 참고 자료 : https://m.blog.naver.com/tipsware/221727268968def read_documents(input_file_name):    \"\"\"문서들을 주어진 이름의 파일로부터 읽어들여 돌려준다.\"\"\"        corpus = []        with open(input_file_name, 'rb') as f:        temp_corpus = pickle.load(f)            for page in temp_corpus:        corpus += page        return corpusdef text_cleaning(docs):    # 한국어를 제외한 글자를 제거하는 함수.    for doc in docs:        doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)    return docsdef define_stopwords(path):        SW = set()    # 불용어를 추가하는 방법 1.    for i in string.punctuation:        SW.add(i)    # 불용어를 추가하는 방법 2.    # stopwords-ko.txt에 직접 추가        with open(path) as f:        for word in f:            SW.add(word)    return SWdef text_tokenizing(corpus, tokenizer):        mecab = Mecab(dicpath='C:\\mecab\\mecab-ko-dic')    token_corpus = []        if tokenizer == \"noun\":        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):            token_text = mecab.nouns(corpus[n])            token_text = [word for word in token_text if word not in SW and len(word) &gt; 1]                            token_corpus.append(token_text)                elif tokenized == \"morph\":        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):            token_text = mecab.morphs(corpus[n])            token_text = [word for word in token_text if word not in SW and len(word) &gt; 1]            token_corpus.append(token_text)    elif tokenizer == \"word\":        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):            token_text = corpus[n].split()            token_text = [word for word in token_text if word not in SW and len(word) &gt; 1]            token_corpus.append(token_text)            return token_corpusinput_file_name = \"naver_news_content.pk\"documents = read_documents(input_file_name)SW = define_stopwords(\"stopwords-ko.txt\")cleaned_text = text_cleaning(documents)tokenized_text = text_tokenizing(cleaned_text, tokenizer=\"noun\") #tokenizer= \"noun\" or \"word\"Preprocessing:   0%|          | 0/3 [00:00&lt;?, ?it/s]문서 읽기의 과정은 앞서 단어 임베딩의 경우와 다르지 않다. 다음 과정은 문서-단어 행렬을 만드는 과정이다.print(tokenized_text[0])['본문', '내용', '플레이어', '플레이어', '오류', '우회', '함수', '추가', '스포츠', '경향', '안양', '대학교', '대학', '일자리', '센터', '디지털', '기초', '이해', '확보', '최신', '트렌드', '역량', '강화', '코딩', '학개', '프로그램', '진행', '개월', '진행', '이번', '프로그램', '코드', '연계', '실무', '파이썬', '기초', '머신', '러닝', '퍼블리싱', '교육', '과정', '구성', '학생', '과목', '신청', '자유', '수강', '개설', '특징', '코드', '국내', '유일', '외주', '제작', '기업', '아이비리그', '출신', '개발자', '콘텐츠', '기획', '제작', '유기', '연결', '강의', '제작', '기업', '최근', '글로벌', '서비스', '개시', '국내', '해외', '수준', '코딩', '강의', '제공', '고객', '만족도', '향후', '성장', '가능', '중소', '벤처', '기업', '아기', '유니콘', '기업', '선정', '이번', '프로그램', '전공', '전공', '코딩', '관심', '재학', '누구', '신청', '수강', '이상', '기말', '평가', '이상', '달성', '수료증', '발급', '김현태', '대학', '일자리', '센터', '팀장', '산업', '시대', '트렌드', '전공', '실질', '역량', '강화', '전공', '디지털', '기초', '이해', '확보', '기대', '양대', '지난해', '대학', '일자리', '센터', '개소식', '진로', '탐색', '지원', '맞춤', '진로', '선택', '지원', '구직', '활동', '지원', '취업', '경쟁력', '강화', '목표', '재학', '지역', '청년', '진로', '창업', '프로그램', '운영', '박차', '본문', '내용']3. 토픽 모델링에 사용할 함수들 확인하기# 문서-단어 행렬 만들기# 어휘(vocabulary) 학습#from gensim import corporadictionary = corpora.Dictionary(tokenized_text)# 문서-단어 행렬(document-term matrix) 생성corpus = [dictionary.doc2bow(text) for text in tokenized_text]print(dictionary)Dictionary(171 unique tokens: ['가능', '강의', '강화', '개발자', '개설']...)corpus[0][:5][(0, 1), (1, 2), (2, 3), (3, 1), (4, 1)]4.TF-IDF(단어 빈도-역 문서 빈도, Term Frequency-Inverse Document Frequency)TF-IDF(Term Frequency-Inverse Document Frequency)는 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정 식을 취함)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법입니다. 사용 방법은 우선 DTM을 만든 후, TF-IDF 가중치를 부여합니다.TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰일 수 있습니다.TF-IDF는 TF와 IDF를 곱한 값을 의미하는데 이를 식으로 표현해보겠습니다. 문서를 d, 단어를 t, 문서의 총 개수를 n이라고 표현할 때 TF, DF, IDF는 각각 다음과 같이 정의할 수 있습니다.(1) tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.생소한 글자때문에 어려워보일 수 있지만, 잘 생각해보면 TF는 이미 앞에서 구한 적이 있습니다. TF는 앞에서 배운 DTM의 예제에서 각 단어들이 가진 값들입니다. DTM이 각 문서에서의 각 단어의 등장 빈도를 나타내는 값이었기 때문입니다.(2) df(t) : 특정 단어 t가 등장한 문서의 수.여기서 특정 단어가 각 문서, 또는 문서들에서 몇 번 등장했는지는 관심가지지 않으며 오직 특정 단어 t가 등장한 문서의 수에만 관심을 가집니다. 앞서 배운 DTM에서 바나나는 문서2와 문서3에서 등장했습니다. 이 경우, 바나나의 df는 2입니다. 문서3에서 바나나가 두 번 등장했지만, 그것은 중요한 게 아닙니다. 심지어 바나나란 단어가 문서2에서 100번 등장했고, 문서3에서 200번 등장했다고 하더라도 바나나의 df는 2가 됩니다.(3) idf(d, t) : df(t)에 반비례하는 수.# TFIDF 문서-단어 행렬 생성# TF-IDF로 corpus를 변환# corpus(말뭉치) = &gt; nltk 패키지의 서브패키지에서는 다앙한 연구용 말뭉치를 제공한다 tfidf = models.TfidfModel(corpus)corpus_tfidf = tfidf[corpus]corpus_tfidf[0][:5][(0, 0.06084982941388938), (1, 0.12169965882777876), (2, 0.18254948824166817), (3, 0.06084982941388938), (5, 0.06084982941388938)]# LDA모델 생성model = models.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary)model.show_topic(3, 10)[('과정', 0.036929026), ('안랩', 0.03349875), ('교육', 0.032891143), ('강사', 0.019402198), ('지원', 0.018727802), ('디지털', 0.018118385), ('프로그램', 0.015849968), ('경력', 0.012340712), ('수료생', 0.012300622), ('파이썬', 0.0103326235)]4. 토픽 모델링을 추가하여 코드 완성하기  LDA 모델의 주요 입력값은 dictionary와 corpus이다  빈도수 기반으로 BoW의 행렬 또는 TF-IDF 행렬로 corpus를 나타냄# 토픽 개수, 키워드 개수를 정해주는 변수를 추가.NUM_TOPICS = 3NUM_TOPIC_WORDS = 30def build_doc_term_mat(documents):    # 문서-단어 행렬 만들어주는 함수.    print(\"Building document-term matrix.\")    dictionary = corpora.Dictionary(documents) #dictionary를 이용하여  corpus 생성함    corpus = [dictionary.doc2bow(document) for document in documents]            return corpus, dictionarydef print_topic_words(model):    # 토픽 모델링 결과를 출력해 주는 함수.    print(\"\\nPrinting topic words.\\n\")        for topic_id in range(model.num_topics):        topic_word_probs = model.show_topic(topic_id, NUM_TOPIC_WORDS)        print(\"Topic ID: {}\".format(topic_id))                for topic_word, prob in topic_word_probs:            print(\"\\t{}\\t{}\".format(topic_word, prob))                    print(\"\\n\")# document-term matrix를 만들고,corpus, dictionary = build_doc_term_mat(tokenized_text)# LDA를 실행.model = models.ldamodel.LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, alpha=\"auto\", eta=\"auto\")# 결과를 출력.print_topic_words(model)Building document-term matrix.Printing topic words.Topic ID: 0\t교육\t0.020134063437581062\t과정\t0.01933959499001503\t지원\t0.01856546476483345\t프로그램\t0.01719101145863533\t전공\t0.016903992742300034\t강화\t0.015583008527755737\t센터\t0.01377133745700121\t코딩\t0.013474454171955585\t일자리\t0.013459446839988232\t디지털\t0.013236879371106625\t기업\t0.013011089526116848\t대학\t0.012913161888718605\t기초\t0.012707662768661976\t내용\t0.011979364790022373\t진로\t0.011881052516400814\t제작\t0.011384266428649426\t플레이어\t0.011376134119927883\t본문\t0.011355482041835785\t안랩\t0.010759378783404827\t이번\t0.010608116164803505\t코드\t0.010289400815963745\t신청\t0.01004485972225666\t국내\t0.009928843937814236\t역량\t0.009752754122018814\t재학\t0.009469701908528805\t강의\t0.009315531700849533\t확보\t0.009268994443118572\t수강\t0.009232008829712868\t이해\t0.00896440725773573\t이상\t0.008546862751245499Topic ID: 1\t안랩\t0.03611671179533005\t교육\t0.035984765738248825\t과정\t0.028996383771300316\t프로그램\t0.019850241020321846\t디지털\t0.01963992789387703\t강사\t0.01785849593579769\t지원\t0.016276324167847633\t플레이어\t0.012492415495216846\t기업\t0.012299888767302036\t수료생\t0.012250230647623539\t본문\t0.010270711034536362\t제작\t0.01019159983843565\t이번\t0.010007740929722786\t진로\t0.00999428890645504\t내용\t0.009981066919863224\t경력\t0.009714951738715172\t센터\t0.009554658085107803\t역량\t0.00923772994428873\t코딩\t0.008980067446827888\t대학\t0.00897340290248394\t기초\t0.008057481609284878\t파이썬\t0.00794822908937931\t전공\t0.007943570613861084\t강화\t0.007534967735409737\t일자리\t0.007462440058588982\t코드\t0.007358819246292114\t직무\t0.007350211963057518\t개설\t0.0072939093224704266\t시대\t0.007264475338160992\t오류\t0.007243797183036804Topic ID: 2\t교육\t0.019978761672973633\t기업\t0.019293813034892082\t프로그램\t0.016017606481909752\t디지털\t0.015322954393923283\t전공\t0.014733160845935345\t안랩\t0.014050689525902271\t기초\t0.013909869827330112\t이번\t0.013884689658880234\t일자리\t0.013789125718176365\t지원\t0.013388378545641899\t과정\t0.01308402605354786\t제작\t0.012753716669976711\t본문\t0.012687018141150475\t대학\t0.012517648749053478\t진로\t0.01242670789361\t내용\t0.012329492717981339\t코딩\t0.011859092861413956\t강화\t0.011237404309213161\t재학\t0.010989995673298836\t센터\t0.010790950618684292\t역량\t0.010305172763764858\t트렌드\t0.010141834616661072\t강의\t0.009979970753192902\t플레이어\t0.009863385930657387\t이상\t0.008951065130531788\t수강\t0.008901397697627544\t파이썬\t0.008846205659210682\t이해\t0.008645805530250072\t국내\t0.008613510057330132\t확보\t0.0082792770117521295. pyLDAvis를 통한 토픽 모델링 결과 시각화하기 -LDA 시각화를 위해서는 pyLDAvis의 설치가 필요합니다. 윈도우의 명령 프롬프트나 MAC/UNIX의 터미널에서 아래의 명령을 수행하여 pyLDAvis를 설치하시기 바랍니다.!pip install pyLDAvisCollecting pyLDAvis  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)  Installing build dependencies: started  Installing build dependencies: finished with status 'done'  Getting requirements to build wheel: started  Getting requirements to build wheel: finished with status 'done'  Installing backend dependencies: started  Installing backend dependencies: finished with status 'done'    Preparing wheel metadata: started    Preparing wheel metadata: finished with status 'done'Requirement already satisfied: joblib in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.0.1)Requirement already satisfied: future in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (0.18.2)Requirement already satisfied: scipy in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.5.0)Requirement already satisfied: numexpr in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (2.7.3)Collecting funcy  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)Requirement already satisfied: setuptools in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (52.0.0.post20210125)Requirement already satisfied: gensim in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (4.0.1)Collecting pyLDAvis  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)  Installing build dependencies: started  Installing build dependencies: finished with status 'done'  Getting requirements to build wheel: started  Getting requirements to build wheel: finished with status 'done'  Installing backend dependencies: started  Installing backend dependencies: finished with status 'done'    Preparing wheel metadata: started    Preparing wheel metadata: finished with status 'done'  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)Requirement already satisfied: wheel&gt;=0.23.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (0.36.2)Requirement already satisfied: numpy&gt;=1.9.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.17.0)Requirement already satisfied: jinja2&gt;=2.7.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (3.0.1)Requirement already satisfied: pandas&gt;=0.17.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.0.5)Requirement already satisfied: MarkupSafe&gt;=2.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from jinja2&gt;=2.7.2-&gt;pyLDAvis) (2.0.1)Requirement already satisfied: pytz&gt;=2017.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pandas&gt;=0.17.0-&gt;pyLDAvis) (2021.1)Requirement already satisfied: python-dateutil&gt;=2.6.1 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pandas&gt;=0.17.0-&gt;pyLDAvis) (2.8.2)Requirement already satisfied: six&gt;=1.5 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas&gt;=0.17.0-&gt;pyLDAvis) (1.16.0)Building wheels for collected packages: pyLDAvis  Building wheel for pyLDAvis (setup.py): started  Building wheel for pyLDAvis (setup.py): finished with status 'done'  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135593 sha256=262e5ce09089c4b45730aaa1d68d2998f5fc6e1fabfb7326d9e778caa1cb1e74  Stored in directory: c:\\users\\mycom\\appdata\\local\\pip\\cache\\wheels\\eb\\d1\\ac\\e8728b60e7d714da9ff6a52cb8659099c3be9e0dc19f522881Successfully built pyLDAvisInstalling collected packages: funcy, pyLDAvisSuccessfully installed funcy-1.16 pyLDAvis-3.2.2# pyLDAvis 불러오기import pyLDAvisimport pyLDAvis.gensim# pyLDAvis를 jupyter notebook에서 실행할 수 있게 활성화.pyLDAvis.enable_notebook()# pyLDAvis 실행.data = pyLDAvis.gensim.prepare(model, corpus, dictionary)data# pyLDAvis 실행결과 깃허브에서 안보여집니다.# 밑에 링크를 통해 실행결과 확인 가능합니다#https://nbviewer.jupyter.org/github/SEONGJAE-YOO/MachineLearning-dataAnalysis/blob/main/KakaoTalk%20conversation%20analysis%20using%20Text%20Mining/%EA%B8%B0%EC%82%AC%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%A0%95%EC%A0%9C%20-%20gensim%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%86%A0%ED%94%BD%EB%AA%A8%EB%8D%B8%EB%A7%81%20%EB%B6%84%EC%84%9D.ipynb",
        "url": "/gensim-news"
    }
    ,
    
    "series-slicing": {
        "title": "Series 데이터 변경 - 슬라이싱하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  pandas Series 이해하기import numpy as npimport pandas as pdSeries 값 변경  추가 및 업데이트: 인덱스를 이용  삭제: drop함수 이용s = pd.Series(np.arange(100, 105), ['a', 'b', 'c', 'd', 'e'])sa    100b    101c    102d    103e    104dtype: int32s['a'] = 200sa    200b    101c    102d    103e    104dtype: int32s['k'] = 300sa    200b    101c    102d    103e    104k    300dtype: int64s.drop('k', inplace=True) #inplace=True으로 결과 값 고정시킴sa    200b    101c    102d    103e    104dtype: int64s[['a', 'b']] = [300, 900]sa    300b    900c    102d    103e    104dtype: int64Slicing  리스트, ndarray와 동일하게 적용s1 = pd.Series(np.arange(100, 105))s10    1001    1012    1023    1034    104dtype: int32s1[1:3]1    1012    102dtype: int32s2 = pd.Series(np.arange(100, 105), ['a', 'c', 'b', 'd', 'e'])s2a    100c    101b    102d    103e    104dtype: int32s2[1:3]c    101b    102dtype: int32s2['c':'d'] #문자열로 이루어진 경우 마지막 까지 포함시킴c    101b    102d    103dtype: int32",
        "url": "/series-slicing"
    }
    ,
    
    "series-operation": {
        "title": "Series 데이터 연산하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  Series 데이터 연산하기import numpy as npimport pandas as pdindex를 기준으로 연산s1 = pd.Series([1, 2, 3, 4], ['a', 'b', 'c', 'd'])s2 = pd.Series([6, 3, 2, 1], ['d', 'c', 'b', 'a'])s1a    1b    2c    3d    4dtype: int64s2d    6c    3b    2a    1dtype: int64s1 + s2a     2b     4c     6d    10dtype: int64산술연산  Series의 경우에도 스칼라와의 연산은 각 원소별로 스칼라와의 연산이 적용  Series와의 연산은 각 인덱스에 맞는 값끼리 연산이 적용          이때, 인덱스의 pair가 맞지 않으면, 결과는 NaN      s1 ** 2a     1b     4c     9d    16dtype: int64s1 ** s2a       1b       4c      27d    4096dtype: int644 ** 64096index pair가 맞지 않는 경우  해당 index에 대해선 NaN 값 생성s1['k'] = 7s2['e'] = 9s1a    1b    2c    3d    4k    7dtype: int64s2d    6c    3b    2a    1e    9dtype: int64s1 + s2a     2.0b     4.0c     6.0d    10.0e     NaNk     NaNdtype: float64",
        "url": "/series-operation"
    }
    ,
    
    "series-index": {
        "title": "Series 데이터 생성하기(index, value 활용)",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  pandas Series 데이터 생성하기import numpy as npimport pandas as pdSeries  pandas의 기본 객체 중 하나  numpy의 ndarray를 기반으로 인덱싱을 기능을 추가하여 1차원 배열을 나타냄  index를 지정하지 않을 시, 기본적으로 ndarray와 같이 0-based 인덱스 생성, 지정할 경우 명시적으로 지정된 index를 사용      같은 타입의 0개 이상의 데이터를 가질 수 있음    data로만 생성하기  index는 기본적으로 0부터 자동적으로 생성s1 = pd.Series([1, 2, 3])s10    11    22    3dtype: int64s2 = pd.Series(['a', 'b', 'c'])s20    a1    b2    cdtype: objects3 = pd.Series(np.arange(200))s30        01        12        23        34        4      ... 195    195196    196197    197198    198199    199Length: 200, dtype: int32  data, index함께 명시하기s4 = pd.Series([1, 2, 3], [100, 200, 300])s4100    1200    2300    3dtype: int64s5 = pd.Series([1, 2, 3], ['a', 'm', 'k'])s5a    1m    2k    3dtype: int64  data, index, data type 함께 명시하기s6 = pd.Series(np.arange(5), np.arange(100, 105), dtype=np.int16)s6100    0101    1102    2103    3104    4dtype: int16인덱스 활용하기s6.indexInt64Index([100, 101, 102, 103, 104], dtype='int64')s6.valuesarray([0, 1, 2, 3, 4], dtype=int16)  인덱스를 통한 데이터 접근s6[104]4  인덱스를 통한 데이터 업데이트s6[104] = 70s6100     0101     1102     2103     3104    70dtype: int16s6[105] = 90s6[200] = 80 # 인덱스를 통해 값을 넣을 수도 있다.s6100     0101     1102     2103     3104    70105    90200    80dtype: int64  인덱스 재사용하기s7 = pd.Series(np.arange(7), s6.index) #s6 index 그대로 사용한다s7100    0101    1102    2103    3104    4105    5200    6dtype: int32",
        "url": "/series-index"
    }
    ,
    
    "series-count": {
        "title": "Series 데이터 심플 분석(개수, 빈도 등 계산하기)",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  Series 함수 활용하여 데이터 분석하기import numpy as npimport pandas as pdSeries size, shape, unique, count, value_counts 함수  size : 개수 반환  shape : 튜플형태로 shape반환  unique: 유일한 값만 ndarray로 반환  count : NaN을 제외한 개수를 반환  mean: NaN을 제외한 평균  value_counts: NaN을 제외하고 각 값들의 빈도를 반환s = pd.Series([1, 1, 2, 1, 2, 2, 2, 1, 1, 3, 3, 4, 5, 5, 7, np.NaN])s0     1.01     1.02     2.03     1.04     2.05     2.06     2.07     1.08     1.09     3.010    3.011    4.012    5.013    5.014    7.015    NaNdtype: float64len(s)16s.size16s.shape #1차원 이다.(16,)s.unique() #중복된 값 제거!array([ 1.,  2.,  3.,  4.,  5.,  7., nan])s.count() #NaN를 뺀 count 값 15a = np.array([2, 2, 2, 2, np.NaN])a.mean()b = pd.Series(a)b.mean()2.0s.mean()2.6666666666666665s0     1.01     1.02     2.03     1.04     2.05     2.06     2.07     1.08     1.09     3.010    3.011    4.012    5.013    5.014    7.015    NaNdtype: float64s.value_counts()1.0    52.0    43.0    25.0    27.0    14.0    1dtype: int64index를 활용하여 멀티플한 값에 접근s[[5, 7, 8, 10]].value_counts()1.0    23.0    12.0    1dtype: int64head, tail 함수  head : 상위 n개 출력 기본 5개  tail : 하위 n개 출력 기본 5개s.head(n=7)0    1.01    1.02    2.03    1.04    2.05    2.06    2.0dtype: float64s.tail()11    4.012    5.013    5.014    7.015    NaNdtype: float64s0     1.01     1.02     2.03     1.04     2.05     2.06     2.07     1.08     1.09     3.010    3.011    4.012    5.013    5.014    7.015    NaNdtype: float64",
        "url": "/series-count"
    }
    ,
    
    "series-boolean": {
        "title": "Series 데이터 Boolean Selection으로 데이터 선택하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  Series boolean selection 활용하기import numpy as npimport pandas as pdBoolean selection  boolean Series가 []와 함께 사용되면 True 값에 해당하는 값만 새로 반환되는 Series객체에 포함됨                              다중조건의 경우, &amp;(and),          (or)를 사용하여 연결 가능                    s = pd.Series(np.arange(10), np.arange(10)+1) # ( 값,주소 )s1     02     13     24     35     46     57     68     79     810    9dtype: int32s &gt; 51     False2     False3     False4     False5     False6     False7      True8      True9      True10     Truedtype: bools[s&gt;5]7     68     79     810    9dtype: int32s[s % 2 == 0]1    03    25    47    69    8dtype: int32s1     02     13     24     35     46     57     68     79     810    9dtype: int32s.index &gt; 5array([False, False, False, False, False,  True,  True,  True,  True,        True])s[s.index &gt; 5]6     57     68     79     810    9dtype: int32(s &gt; 5) &amp; (s &lt; 8)1     False2     False3     False4     False5     False6     False7      True8      True9     False10    Falsedtype: bools[(s &gt; 5) &amp; (s &lt; 8)]7    68    7dtype: int32(s &gt;= 7).sum()3(s[s&gt;=7]).sum() # 7+8+9 = 2424",
        "url": "/series-boolean"
    }
    ,
    
    "linear-regression": {
        "title": "단순선형회귀분석 실습 - 단순선형회귀 적합 및 해석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)import osimport pandas as pd import numpy as npimport statsmodels.api as sm# 현재경로 확인os.getcwd()'C:\\\\Users\\\\MyCom\\\\jupyter-tutorial\\\\머신러닝과 데이터분석 A-Z 올인원 패키지 Online\\\\Machine learning의 개념과 종류'# 데이터 불러오기boston = pd.read_csv(\"Boston_house.csv\")boston.head()                  AGE      B      RM      CRIM      DIS      INDUS      LSTAT      NOX      PTRATIO      RAD      ZN      TAX      CHAS      Target                  0      65.2      396.90      6.575      0.00632      4.0900      2.31      4.98      0.538      15.3      1      18.0      296      0      24.0              1      78.9      396.90      6.421      0.02731      4.9671      7.07      9.14      0.469      17.8      2      0.0      242      0      21.6              2      61.1      392.83      7.185      0.02729      4.9671      7.07      4.03      0.469      17.8      2      0.0      242      0      34.7              3      45.8      394.63      6.998      0.03237      6.0622      2.18      2.94      0.458      18.7      3      0.0      222      0      33.4              4      54.2      396.90      7.147      0.06905      6.0622      2.18      5.33      0.458      18.7      3      0.0      222      0      36.2      # target 제외한 데이터만 뽑기boston_data = boston.drop(['Target'],axis=1)# boston_databoston_data.describe()# data 통계 뽑아보기                  AGE      B      RM      CRIM      DIS      INDUS      LSTAT      NOX      PTRATIO      RAD      ZN      TAX      CHAS                  count      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000      506.000000              mean      68.574901      356.674032      6.284634      3.613524      3.795043      11.136779      12.653063      0.554695      18.455534      9.549407      11.363636      408.237154      0.069170              std      28.148861      91.294864      0.702617      8.601545      2.105710      6.860353      7.141062      0.115878      2.164946      8.707259      23.322453      168.537116      0.253994              min      2.900000      0.320000      3.561000      0.006320      1.129600      0.460000      1.730000      0.385000      12.600000      1.000000      0.000000      187.000000      0.000000              25%      45.025000      375.377500      5.885500      0.082045      2.100175      5.190000      6.950000      0.449000      17.400000      4.000000      0.000000      279.000000      0.000000              50%      77.500000      391.440000      6.208500      0.256510      3.207450      9.690000      11.360000      0.538000      19.050000      5.000000      0.000000      330.000000      0.000000              75%      94.075000      396.225000      6.623500      3.677083      5.188425      18.100000      16.955000      0.624000      20.200000      24.000000      12.500000      666.000000      0.000000              max      100.000000      396.900000      8.780000      88.976200      12.126500      27.740000      37.970000      0.871000      22.000000      24.000000      100.000000      711.000000      1.000000      '''타겟 데이터1978 보스턴 주택 가격506개 타운의 주택 가격 중앙값 (단위 1,000 달러)특징 데이터CRIM: 범죄율INDUS: 비소매상업지역 면적 비율NOX: 일산화질소 농도RM: 주택당 방 수LSTAT: 인구 중 하위 계층 비율B: 인구 중 흑인 비율PTRATIO: 학생/교사 비율ZN: 25,000 평방피트를 초과 거주지역 비율CHAS: 찰스강의 경계에 위치한 경우는 1, 아니면 0AGE: 1940년 이전에 건축된 주택의 비율RAD: 방사형 고속도로까지의 거리DIS: 직업센터의 거리TAX: 재산세율''''\\n타겟 데이터\\n1978 보스턴 주택 가격\\n506개 타운의 주택 가격 중앙값 (단위 1,000 달러)\\n\\n특징 데이터\\nCRIM: 범죄율\\nINDUS: 비소매상업지역 면적 비율\\nNOX: 일산화질소 농도\\nRM: 주택당 방 수\\nLSTAT: 인구 중 하위 계층 비율\\nB: 인구 중 흑인 비율\\nPTRATIO: 학생/교사 비율\\nZN: 25,000 평방피트를 초과 거주지역 비율\\nCHAS: 찰스강의 경계에 위치한 경우는 1, 아니면 0\\nAGE: 1940년 이전에 건축된 주택의 비율\\nRAD: 방사형 고속도로까지의 거리\\nDIS: 직업센터의 거리\\nTAX: 재산세율'crim/rm/lstat 세게의 변수로 각각 단순 선형 회귀 분석하기target = boston[['Target']]# boston_targetcrim=boston[['CRIM']]rm=boston[['RM']]lstat=boston['LSTAT']target ~ crim 선형회귀분석crim1 = sm.add_constant(crim, has_constant='add')model1 = sm.OLS(target,crim1)fitted_model1=model1.fit()fitted_model1.summary()OLS Regression Results  Dep. Variable:         Target        R-squared:             0.151  Model:                   OLS         Adj. R-squared:        0.149  Method:             Least Squares    F-statistic:           89.49  Date:             Wed, 12 May 2021   Prob (F-statistic): 1.17e-19  Time:                 15:52:25       Log-Likelihood:      -1798.9  No. Observations:         506        AIC:                   3602.  Df Residuals:             504        BIC:                   3610.  Df Model:                   1                                      Covariance Type:      nonrobust                                             coef     std err      t      P&gt;|t|  [0.025    0.975]    const    24.0331     0.409    58.740  0.000    23.229    24.837  CRIM     -0.4152     0.044    -9.460  0.000    -0.501    -0.329  Omnibus:       139.832   Durbin-Watson:         0.713  Prob(Omnibus):  0.000    Jarque-Bera (JB):    295.404  Skew:           1.490    Prob(JB):           7.14e-65  Kurtosis:       5.264    Cond. No.               10.1Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.y_hat=beta0 + beta1 * X 계산해보기(np.dot(crim1,fitted_model1.params))array([ 24.03048217,  24.02176733,  24.02177563,  24.01966646,        24.00443729,  24.02071274,  23.99644902,  23.97309042,        23.94540138,  23.96250722,  23.93973403,  23.98433377,        23.99416963,  23.77163594,  23.76823138,  23.77261995,        23.59552468,  23.70751396,  23.69982879,  23.73176107,        23.51337514,  23.67934745,  23.52139661,  23.62271965,        23.72160552,  23.68412214,  23.75413567,  23.63627976,        23.71216824,  23.61689868,  23.56360486,  23.4706396 ,        23.45682622,  23.55492323,  23.36347899,  24.00646341,        23.99265003,  23.99983283,  23.96042712,  24.02163447,        24.01915993,  23.98019433,  23.97435675,  23.96694145,        23.98216648,  23.96193426,  23.95490093,  23.9379155 ,        23.92770182,  23.94185981,  23.99626634,  24.01509937,        24.01085198,  24.01242555,  24.02745959,  24.02766303,        24.02457401,  24.02716065,  23.96898004,  23.99022532,        23.97110996,  23.96181385,  23.98732314,  23.9805846 ,        24.02500581,  24.01822575,  24.01492499,  24.00907081,        23.97683128,  23.97989539,  23.99646148,  23.96719057,        23.99505814,  23.95198215,  24.00032275,  23.99361327,        23.99095191,  23.99695556,  24.00966453,  23.99828417,        24.0160294 ,  24.01458038,  24.01791436,  24.01836277,        24.0121017 ,  24.00929501,  24.0115661 ,  24.00341592,        24.0096064 ,  24.01109279,  24.01365866,  24.01678089,        24.01565573,  24.02116945,  24.0152779 ,  23.98243635,        23.98534268,  23.98293873,  23.99911455,  24.00462412,        23.97138399,  23.98564162,  23.93812725,  23.94524776,        23.97514561,  23.97804364,  23.9620256 ,  23.97864567,        23.97995351,  23.92364956,  23.98829469,  23.99123839,        23.98191736,  23.94088411,  23.97402045,  23.96196747,        23.97847544,  23.97042075,  23.97889063,  23.97300323,        24.0044622 ,  24.00335779,  23.99449763,  23.97066986,        23.99221408,  23.96293071,  23.87228222,  23.92550961,        23.8979908 ,  23.66721974,  23.89191657,  23.53780908,        23.78812315,  23.89616812,  23.62780988,  23.80152134,        23.89914918,  23.88682218,  23.92939164,  23.80702676,        23.91232732,  23.35691068,  22.6542385 ,  22.33190553,        22.87898515,  23.04522734,  23.13835037,  23.04967818,        23.06530179,  22.89798841,  23.34530196,  23.41184866,        23.56536111,  23.14078753,  23.4460894 ,  22.56540439,        23.01726842,  23.52508765,  23.47557206,  23.44145172,        23.50437796,  23.42553333,  23.2717427 ,  23.40242384,        23.1021001 ,  22.8190898 ,  23.19849483,  23.28564742,        23.07800246,  23.01608513,  23.53179713,  23.07239739,        23.9753366 ,  23.99500001,  23.99803505,  24.00543789,        24.00395151,  24.0105821 ,  24.00552924,  24.00910818,        24.00575344,  24.00450787,  23.9953114 ,  23.99155393,        23.99861217,  24.00799962,  24.00984721,  24.00040994,        23.98087939,  23.99835475,  23.99545672,  24.00441237,        23.99713409,  24.02402596,  24.02713159,  24.0273724 ,        24.01645289,  24.0137334 ,  24.0174618 ,  24.02002768,        24.02572409,  24.01880287,  24.02406748,  24.018533  ,        24.024765  ,  23.97646592,  23.93774112,  23.92848238,        23.97669427,  23.85220362,  23.96067208,  23.87708597,        23.942931  ,  23.97476364,  23.91288783,  23.9508902 ,        24.0141735 ,  24.00398888,  23.98714876,  23.98567068,        23.88443069,  23.86382895,  23.77421012,  23.77788871,        23.90218422,  23.81432996,  23.87444536,  23.86189001,        23.90930059,  23.84968341,  23.81014899,  23.84088968,        23.79425136,  23.89548305,  23.8471383 ,  23.89590655,        23.81696642,  23.82059933,  23.99887789,  23.99469277,        23.98606927,  23.98904618,  23.99038309,  23.98014035,        23.94754376,  23.95366782,  23.89201206,  23.95149222,        23.96485304,  23.95391693,  23.97485498,  23.94421809,        23.99897338,  23.87992587,  24.01309815,  24.01837522,        24.02672055,  23.77920071,  23.75762327,  23.76047148,        23.80885775,  23.81134474,  23.8171491 ,  23.69046625,        23.80472246,  23.71688895,  23.70689117,  23.79298503,        23.80869583,  23.99546918,  23.90889785,  23.96579968,        23.98552537,  23.94098376,  24.00967283,  23.9932313 ,        23.9896399 ,  24.00766747,  23.99998229,  23.94575844,        24.01825067,  24.01772337,  24.00765916,  24.02687417,        24.02934455,  24.02855569,  24.02494769,  24.01703416,        24.01404894,  24.01526545,  24.01856621,  24.00036427,        24.01809705,  23.9987907 ,  23.99906472,  23.97941377,        24.01080215,  23.97455189,  24.00625997,  24.01001744,        24.01476722,  24.01842089,  23.99463464,  23.99158715,        24.01020843,  24.0103579 ,  24.00195445,  24.01262899,        23.82842567,  23.88803869,  22.9388805 ,  23.70493563,        23.92445503,  23.92126222,  23.87981792,  23.92783053,        23.90096356,  23.93129321,  23.86619138,  23.83569565,        23.96352028,  23.95771177,  23.88731626,  23.91522535,        23.89148892,  23.95344777,  23.90710838,  23.93303286,        24.00563303,  24.00518878,  24.01423993,  24.01225117,        24.01871568,  24.01200205,  24.01758636,  24.01666049,        24.0188776 ,  24.02048024,  24.01937998,  24.01028316,        24.00756782,  24.02770455,  24.02273472,  24.02254789,        24.02044702,  24.0201813 ,  24.00752215,  24.02534212,        24.02687417,  24.02106981,  24.00731871,  24.00009855,        24.00302979,  24.02601057,  24.01524884,  23.98885104,        20.30346852,  22.43474816,  21.87338184,  22.26385169,        22.14734515,  22.44008751,  22.50594499,  22.2800109 ,        22.5906189 ,  22.14155324,  22.49816848,  18.4188202 ,        21.99941285,  21.6789856 ,  21.31827659,  20.19994497,        20.60062435,  19.42113105,  16.35283338,  15.8915985 ,        17.68567721,  19.95448863,  14.21460344,  16.61502604,       -12.90894703,  17.44220963,  20.21874479,  20.71470618,        15.69405096,  17.05301026,  13.90503757,  14.65100995,        18.08189329,  20.64858298,  21.14248918,  21.83548327,        19.22607466,  20.44388587,  18.4862471 ,  20.41399632,        21.5950881 ,  20.84775806,   8.10981167,  19.91585102,        13.63420895,  18.12237434,  20.04906067,  13.73568146,         6.79058608,  -4.16694965,  15.43194134,  19.07112564,        20.95908303,  18.03846438,   2.80201916,  18.19939214,        16.22296186,  12.13549661,   5.0397702 ,  16.52455607,        19.53485167,  13.26282125,  -6.49753724,  19.12875405,        19.42972549,  21.11739508,  19.03081067,  21.10584033,        20.38270343,  17.44806381,  18.9481878 ,   8.39625145,        20.97435373,  20.15568984,  20.50725636,  19.85533704,        21.35759926,  21.71590017,  18.25639776,  19.3994166 ,        18.04573021,  17.73168029,  18.35409203,  20.13420789,        14.87770384,  19.99572118,  21.68048444,  19.89509566,        18.71771568,  19.60227857,  21.42236064,  19.91240494,        20.1597587 ,  20.90837999,  21.24397414,  21.77399775,        21.91971708,  20.60857939,  20.08313949,  22.05996835,        22.09465335,  20.62830508,  20.81445565,  21.20932651,        22.03515658,  22.49976281,  21.27004809,  21.61622129,        20.77829672,  22.71961021,  22.46577118,  22.19701851,        17.56622696,  18.60445177,  22.22753085,  22.3563976 ,        22.55142493,  22.10376262,  20.68842049,  21.3787449 ,        22.0105441 ,  17.79553655,  19.78446406,  18.08189329,        21.61503384,  21.66312533,  21.65358426,  22.8629422 ,        23.04554703,  22.50783411,  21.66994691,  22.025383  ,        23.97047057,  23.95697273,  23.9469708 ,  23.98920395,        23.98688719,  23.96114955,  23.91703143,  23.95879127,        23.91286707,  23.92167741,  23.93382587,  23.95927289,        23.93994578,  24.00710281,  24.01431051,  24.00787921,        23.98760547,  24.013422  ])len(np.dot(crim1,fitted_model1.params))506pred1=fitted_model1.predict(crim1)pred1-np.dot(crim1,fitted_model1.params)0      0.01      0.02      0.03      0.04      0.05      0.06      0.07      0.08      0.09      0.010     0.011     0.012     0.013     0.014     0.015     0.016     0.017     0.018     0.019     0.020     0.021     0.022     0.023     0.024     0.025     0.026     0.027     0.028     0.029     0.0      ... 476    0.0477    0.0478    0.0479    0.0480    0.0481    0.0482    0.0483    0.0484    0.0485    0.0486    0.0487    0.0488    0.0489    0.0490    0.0491    0.0492    0.0493    0.0494    0.0495    0.0496    0.0497    0.0498    0.0499    0.0500    0.0501    0.0502    0.0503    0.0504    0.0505    0.0Length: 506, dtype: float64적합시킨 직선 시각화import matplotlib.pyplot as pltplt.yticks(fontname = \"Arial\") #plt.scatter(crim,target,label=\"data\")plt.plot(crim,pred1,label=\"result\")plt.legend()plt.show()plt.scatter(target,pred1)plt.xlabel(\"real_value\")plt.ylabel(\"pred_value\")plt.show()fitted_model1.resid.plot()plt.xlabel(\"residual_number\")plt.show()##잔차의 합계산해보기sum(fitted_model1.resid)-2.717825964282383e-13위와 동일하게 rm변수와 lstat 변수로 각각 단순선형회귀분석 적합시켜보기rm1 = sm.add_constant(rm, has_constant='add')lstat1 = sm.add_constant(lstat, has_constant='add')model2 = sm.OLS(target,rm1)fitted_model2=model2.fit()model3 = sm.OLS(target,lstat1)fitted_model3=model3.fit()fitted_model2.summary()OLS Regression Results  Dep. Variable:         Target        R-squared:             0.484  Model:                   OLS         Adj. R-squared:        0.483  Method:             Least Squares    F-statistic:           471.8  Date:             Mon, 12 Aug 2019   Prob (F-statistic): 2.49e-74  Time:                 16:00:59       Log-Likelihood:      -1673.1  No. Observations:         506        AIC:                   3350.  Df Residuals:             504        BIC:                   3359.  Df Model:                   1                                      Covariance Type:      nonrobust                                             coef     std err      t      P&gt;|t|  [0.025    0.975]    const   -34.6706     2.650   -13.084  0.000   -39.877   -29.465  RM        9.1021     0.419    21.722  0.000     8.279     9.925  Omnibus:       102.585   Durbin-Watson:         0.684   Prob(Omnibus):  0.000    Jarque-Bera (JB):    612.449   Skew:           0.726    Prob(JB):           1.02e-133  Kurtosis:       8.190    Cond. No.               58.4 Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.fitted_model3.summary()OLS Regression Results  Dep. Variable:         Target        R-squared:             0.544  Model:                   OLS         Adj. R-squared:        0.543  Method:             Least Squares    F-statistic:           601.6  Date:             Mon, 12 Aug 2019   Prob (F-statistic): 5.08e-88  Time:                 16:04:22       Log-Likelihood:      -1641.5  No. Observations:         506        AIC:                   3287.  Df Residuals:             504        BIC:                   3295.  Df Model:                   1                                      Covariance Type:      nonrobust                                             coef     std err      t      P&gt;|t|  [0.025    0.975]    const    34.5538     0.563    61.415  0.000    33.448    35.659  LSTAT    -0.9500     0.039   -24.528  0.000    -1.026    -0.874  Omnibus:       137.043   Durbin-Watson:         0.892  Prob(Omnibus):  0.000    Jarque-Bera (JB):    291.373  Skew:           1.453    Prob(JB):           5.36e-64  Kurtosis:       5.319    Cond. No.               29.7Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.pred2=fitted_model2.predict(rm1)pred3=fitted_model3.predict(lstat1)import matplotlib.pyplot as pltplt.scatter(rm,target,label=\"data\")plt.plot(rm,pred2,label=\"result\")plt.legend()plt.show()import matplotlib.pyplot as pltplt.scatter(lstat,target,label=\"data\")plt.plot(lstat,pred3,label=\"result\")plt.legend()plt.show()fitted_model2.resid.plot()plt.xlabel(\"residual_number\")plt.show()fitted_model3.resid.plot()plt.xlabel(\"residual_number\")plt.show()fitted_model1.resid.plot(label=\"crim\")fitted_model2.resid.plot(label=\"rm\")fitted_model3.resid.plot(label=\"lstat\")plt.legend()",
        "url": "/linear-regression"
    }
    ,
    
    "newstext-morp": {
        "title": "기사 텍스트 정제 - 형태소 추출기 만들기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)형태소 분석기 제작하기      사용할 형태소 분석기 불러오기(import)        텍스트 전처리 하기(작업에 따라 다름)        형태소 / POS tagging 하기  import refrom konlpy.tag import Mecabmecab = Mecab(dicpath='mecab\\mecab-ko-dic')  한국어 정규 표현식밑에 사이트 참조!https://gocoding.tistory.com/931.숫자만 가능 : [0~9] :띄어쓰기 불가능/^[0~9]+$/2.한글만 가능 : [ 가나다라 … ] 주의 : ㄱㄴㄷ… 형식으로는 입력 불가능 , 띄어쓰기 불가능/^[가-힣]+$/3.한글,띄어쓰기만 가능 : [ 가나다라 … ] 주의 : ㄱㄴㄷ… 형식으로는 입력 불가능 , 띄어쓰기 가능/^[가-힣\\s]+$/4.영문만 가능 :/^[a-zA-Z]+$/5.영문,띄어쓰기만 가능/^[a-zA-Z\\s]+$/6.전화번호 형태 : 전화번호 형태 000-0000-0000 만 받는다. ]/^[0-9]{2,3}-[0-9]{3,4}-[0-9]{4}$/7.도메인 형태, http:// https:// 포함안해도 되고 해도 되고/^(((http(s?)):\\/\\/)?)([0-9a-zA-Z-]+.)+[a-zA-Z]{2,6}(:[0-9]+)?(\\/\\S*)?$/8.도메인 형태, http:// https:// 꼭 포함/^((http(s?)):\\/\\/)([0-9a-zA-Z-]+.)+[a-zA-Z]{2,6}(:[0-9]+)?(\\/\\S*)?$/9.도메인 형태, http:// https:// 포함하면 안됨/^[^((http(s?)):\\/\\/)]([0-9a-zA-Z-]+.)+[a-zA-Z]{2,6}(:[0-9]+)?(\\/\\S*)?$/10.한글과 영문만 가능/^[가-힣a-zA-Z]+$/;11.숫자,알파벳만 가능/^[a-zA-Z0-9]+$/;12.주민번호, -까지 포함된 문자열로 검색/^(?:[0-9]{2}(?:0[1-9]|1[0-2])(?:0[1-9]|[1,2][0-9]|3[0,1]))-[1-4][0-9]{6}$/def text_cleaning(doc): #텍스트 정제     # 한국어를 제외한 글자를 제거하는 함수.    doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc) #ㄱ ~ ㅎ 까지 , ㅏ ~ ㅣ까지, 가 ~ 힣 까지 , 띄어쓰기 꼭 포함 해주기~     return doc#https://www.ranks.nl/stopwords/korean# 위 사이트 참고 / 한국어 불용어 stopwords-ko.txt 으로 텍스트 파일 만들어 주기 def define_stopwords(path): #불용어 제거        SW = set()  #집합으로 써줌    # 불용어를 추가하는 방법 1.    # SW.add(\"있다\")        # 불용어를 추가하는 방법 2.    # stopwords-ko.txt에 직접 추가        # 'cp949' codec can't decode byte 0xec in position 0: illegal multibyte sequence    # 위에 오류 해결 방안    #https://dev-guardy.tistory.com/34  (이 사이트 참고해서 해결함)    with open(path, 'r', encoding='UTF-8') as f: #파일 열어 주고 자동적으로 닫아준다        for word in f: #단어 라인 하나씩 가져온다             SW.add(word) # list는 .append , 집합은 .add이다                 return SWdef text_tokenizing(doc): #형태소 분석 (토큰화)        # list comprehension을 풀어서 쓴 코드.    #     tokenized_doc = []    #     for word in mecab.morphs(doc):#         if word not in SW and len(word) &gt; 1:#             tokenized_doc.append(word)    #     return tokenized_doc    # 위 코드 한줄로 작성 하는게 효율적임     return [word for word in mecab.morphs(doc) if word not in SW and len(word) &gt; 1] # not in 을 사용 함 으로써 SW 포함되지 않도록 함 text3 = \"\"\"5G 이동통신망을 빌려 사용하는 ‘5G 알뜰폰’이 올해 도입되고, 내년부터는 의무화된다.정부는 알뜰폰 사업자(MNVO)가 통신사(MNO)에 통신망을 빌리는 비용(도매대가)을 지난해보다 큰 폭으로 낮춰, 알뜰폰 요금 인하를 유도하기로 했다. 하지만 줄어드는 알뜰폰 시장을 살릴 수 있을지는 지켜봐야 하는 상황이다.과학기술정보통신부는 알뜰폰 활성화 추진대책을 25일 발표했다. 알뜰폰 가입자는 800만명으로 이동통신 시장의 12%를 차지한다. 2011년 출시 뒤 저렴한 요금제로 통신비 부담을 낮춰왔다. 하지만 지난해 5월 통신 3사가 준보편제 요금을 내놓은 이후 알뜰폰 이탈 현상이 지속되고 있다.우선 올해 안에 3개 이상의 5G 알뜰폰이 시장에 나온다. 통신사가 5G망을 알뜰폰 사업자에게 도매 제공할지 여부는 통신사 자율로 정한다. 앞서 LG유플러스는 오는 10월 알뜰폰 사업을 시작하는 KB국민은행에 5G망을 제공한다고 밝힌 바 있다. SK텔레콤와 KT도 특정 제휴사를 선택해 올해 안에 5G 알뜰폰을 내놓기로 했다.내년부터는 5G 알뜰폰 제공이 의무화된다. 지난 22일자로 종료된 도매제공 의무제도의 유효기간을 2022년 9월22일까지 연장하는 전기통신사업법 개정안이 국회에서 통과되면, 관련 고시를 개정해 SK텔레콤의 5G망 도매제공을 의무화하겠다는 것이다.과기정통부 관계자는 “SK텔레콤이 자사와 계약을 맺은 13개 알뜰폰 사업자에게 5G망을 의무 제공하면, 그 외 31개의 알뜰폰 사업자들이 경쟁에서 밀릴 것을 우려해 KT와 LG유플러스도 5G망을 제공하게 될 것”이라고 내다봤다.알뜰폰 사업자가 상품을 만드는 방식 크게 2가지다. 하나는 통신사로부터 음성·문자·데이터를 도매로 사들인 뒤 이를 바탕으로 통신사보다 저렴한 요금제를 내놓는 방식(종량제 도매제공)이다. 이를 위해 정부는 도매대가 인하율을 음성 17.8%, 데이터 19.2%, 단문메시지 1.15%로, 지난해 음성 15.1%, 데이터 19.1%, 단문메시지 1.13%에 비해 높여 잡았다.또 다른 방식은 일정비용을 통신사에 내고 통신사의 정액 요금제를 그대로 판매하면서, 그 차액의 범위에서 저렴한 요금제를 내놓는 방식(수익배분 도매제공)이다. 정부는 SK텔레콤의 준보편 요금제인 ‘T플랜 요금제’를 알뜰폰 사업자가 재판매할 수 있게 했다. 기존에 SK텔레콤이 도매제공했던 ‘밴드데이터 요금제’의 최고구간의 대가도 1.5%포인트 낮췄다.알뜰폰 업계는 대체로 반기는 분위기지만, 알뜰폰 시장을 살릴 수 있을지에는 의구심을 갖고 있다. 업계 관계자는 “도매대가 인하율이 크고, 5G망을 제공하는 것은 긍정적”이라면서도 “수익배분 도매제공의 의무화, 설비를 가진 업체에 대한 접속료 정산 도입 등의 제도적 개선이 필요하다”고 말했다.\"\"\"SW = define_stopwords(\"stopwords-ko.txt\")cleaned_text = text_cleaning(text3)print(\"전처리 : \", cleaned_text)tokenized_text = text_tokenizing(cleaned_text) #정제한 데이터를 토큰화 시킴 print(\"\\n형태소 분석 : \", tokenized_text)전처리 :   이동통신망을 빌려 사용하는  알뜰폰이 올해 도입되고 내년부터는 의무화된다정부는 알뜰폰 사업자가 통신사에 통신망을 빌리는 비용도매대가을 지난해보다 큰 폭으로 낮춰 알뜰폰 요금 인하를 유도하기로 했다 하지만 줄어드는 알뜰폰 시장을 살릴 수 있을지는 지켜봐야 하는 상황이다과학기술정보통신부는 알뜰폰 활성화 추진대책을 일 발표했다 알뜰폰 가입자는 만명으로 이동통신 시장의 를 차지한다 년 출시 뒤 저렴한 요금제로 통신비 부담을 낮춰왔다 하지만 지난해 월 통신 사가 준보편제 요금을 내놓은 이후 알뜰폰 이탈 현상이 지속되고 있다우선 올해 안에 개 이상의  알뜰폰이 시장에 나온다 통신사가 망을 알뜰폰 사업자에게 도매 제공할지 여부는 통신사 자율로 정한다 앞서 유플러스는 오는 월 알뜰폰 사업을 시작하는 국민은행에 망을 제공한다고 밝힌 바 있다 텔레콤와 도 특정 제휴사를 선택해 올해 안에  알뜰폰을 내놓기로 했다내년부터는  알뜰폰 제공이 의무화된다 지난 일자로 종료된 도매제공 의무제도의 유효기간을 년 월일까지 연장하는 전기통신사업법 개정안이 국회에서 통과되면 관련 고시를 개정해 텔레콤의 망 도매제공을 의무화하겠다는 것이다과기정통부 관계자는 텔레콤이 자사와 계약을 맺은 개 알뜰폰 사업자에게 망을 의무 제공하면 그 외 개의 알뜰폰 사업자들이 경쟁에서 밀릴 것을 우려해 와 유플러스도 망을 제공하게 될 것이라고 내다봤다알뜰폰 사업자가 상품을 만드는 방식 크게 가지다 하나는 통신사로부터 음성문자데이터를 도매로 사들인 뒤 이를 바탕으로 통신사보다 저렴한 요금제를 내놓는 방식종량제 도매제공이다 이를 위해 정부는 도매대가 인하율을 음성  데이터  단문메시지 로 지난해 음성  데이터  단문메시지 에 비해 높여 잡았다또 다른 방식은 일정비용을 통신사에 내고 통신사의 정액 요금제를 그대로 판매하면서 그 차액의 범위에서 저렴한 요금제를 내놓는 방식수익배분 도매제공이다 정부는 텔레콤의 준보편 요금제인 플랜 요금제를 알뜰폰 사업자가 재판매할 수 있게 했다 기존에 텔레콤이 도매제공했던 밴드데이터 요금제의 최고구간의 대가도 포인트 낮췄다알뜰폰 업계는 대체로 반기는 분위기지만 알뜰폰 시장을 살릴 수 있을지에는 의구심을 갖고 있다 업계 관계자는 도매대가 인하율이 크고 망을 제공하는 것은 긍정적이라면서도 수익배분 도매제공의 의무화 설비를 가진 업체에 대한 접속료 정산 도입 등의 제도적 개선이 필요하다고 말했다형태소 분석 :  ['이동', '통신망', '빌려', '사용', '알뜰', '올해', '도입', '내년', '부터', '의무', '된다', '정부', '알뜰', '사업자', '통신사', '통신망', '빌리', '비용', '매대', '가을', '지난해', '보다', '으로', '낮춰', '알뜰', '요금', '인하', '유도', '지만', '줄어드', '알뜰', '시장', '살릴', '을지', '지켜봐야', '상황', '과학', '기술', '정보', '통신부', '알뜰', '활성', '추진', '대책', '발표', '알뜰', '가입자', '으로', '이동', '통신', '시장', '차지', '한다', '출시', '저렴', '요금제', '통신비', '부담', '낮춰', '하지만', '지난해', '통신', '준보', '편제', '요금', '내놓', '이후', '알뜰', '이탈', '현상', '지속', '우선', '올해', '이상', '알뜰', '시장', '나온다', '통신사', '알뜰', '사업자', '에게', '도매', '제공', '할지', '여부', '통신사', '자율', '정한다', '앞서', '플러스', '알뜰', '사업', '시작', '국민은행', '제공', '한다고', '밝힌', '텔레콤', '특정', '휴사', '선택', '올해', '알뜰', '내놓', '내년', '부터', '알뜰', '제공', '의무', '된다', '지난', '일자', '종료', '도매', '제공', '의무', '제도', '유효', '기간', '월일', '까지', '연장', '전기', '통신', '사업', '개정안', '국회', '에서', '통과', '관련', '고시', '개정', '텔레콤', '도매', '제공', '의무', '다는', '과기', '정통부', '관계자', '텔레콤', '자사', '계약', '알뜰', '사업자', '에게', '의무', '제공', '알뜰', '사업자', '경쟁', '에서', '밀릴', '우려', '플러스', '제공', '라고', '알뜰', '사업자', '상품', '만드', '방식', '가지', '하나', '통신사', '로부터', '음성', '문자', '데이터', '도매', '사들인', '바탕', '으로', '통신사', '보다', '저렴', '요금제', '내놓', '방식', '종량제', '도매', '제공', '위해', '정부', '도매', '대가', '인하', '음성', '데이터', '단문', '메시지', '지난해', '음성', '데이터', '단문', '메시지', '비해', '높여', '다른', '방식', '일정', '비용', '통신사', '통신사', '정액', '요금제', '그대로', '판매', '면서', '차액', '범위', '에서', '저렴', '요금제', '내놓', '방식', '수익', '배분', '도매', '제공', '정부', '텔레콤', '보편', '요금제', '플랜', '요금제', '알뜰', '사업자', '판매', '기존', '텔레콤', '도매', '제공', '밴드', '데이터', '요금제', '최고', '구간', '대가', '포인트', '낮췄', '알뜰', '업계', '대체로', '반기', '분위기', '지만', '알뜰', '시장', '살릴', '을지', '의구심', '업계', '관계자', '도매', '대가', '인하', '제공', '긍정', '라면서', '수익', '배분', '도매', '제공', '의무', '설비', '가진', '업체', '대한', '속료', '정산', '도입', '제도', '개선', '필요', '다고']",
        "url": "/newstext-morp"
    }
    ,
    
    "newstext-konlpy": {
        "title": "기사 텍스트 정제 - konlpy가 지원하는 형태소 분석기 비교하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)konlpy 형태소 분석기 성능비교from konlpy.tag import Kkmafrom konlpy.tag import Komoranfrom konlpy.tag import Hannanum#from konlpy.tag import Mecabimport MeCabfrom konlpy.tag import Oktimport re# 형태소 분석을 위한 객체 생성.kkma = Kkma()komoran = Komoran()hannanum = Hannanum()mecab = MeCab.Tagger()#mecab = Mecab()okt = Okt()C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,                the kernel may be left running.  Please let us know                about your system (bitness, Python, etc.) at                ipython-dev@scipy.org  ipython-dev@scipy.org\"\"\")\"\"\"    Parsing 규칙의 문제점, split을 \",\" 기준으로 하는데, token이 \",\" 인 경우에는 쉼표만 잘려서 나오기 때문에,     + \"%,\" 같이 특수문자와 쉼표가 같이 등장하는 경우도 생각해주어야 함.        (\",\", \"SC\") 의 원래 튜플이 만들어지지 않음.        명사 분석의 경우 해당 토큰이 필요하지 않으니 pass        형태소 분석과 POS tagging의 경우 해당 토큰이 필요하므로, token[0]이 ' 인 경우엔 따로 (\",\", \"SC\")를 집어 넣어줘야함.\"\"\"def mecab_nouns(text):    nouns = []        # 우리가 원하는 TOKEN\\tPOS의 형태를 추출하는 정규표현식.    pattern = re.compile(\".*\\t[A-Z]+\")         # 패턴에 맞는 문자열을 추출하여 konlpy의 mecab 결과와 같아지도록 수정.    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]            # 추출한 token중에 POS가 명사 분류에 속하는 토큰만 선택.    for token in temp:        if token[1] == \"NNG\" or token[1] == \"NNP\" or token[1] == \"NNB\" or token[1] == \"NNBC\" or token[1] == \"NP\" or token[1] == \"NR\":             nouns.append(token[0])            return nounsdef mecab_morphs(text):    morphs = []        # 우리가 원하는 TOKEN\\tPOS의 형태를 추출하는 정규표현식.    pattern = re.compile(\".*\\t[A-Z]+\")         # 패턴에 맞는 문자열을 추출하여 konlpy의 mecab 결과와 같아지도록 수정.    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]            # 추출한 token중에 문자열만 선택.    for token in temp:        morphs.append(token[0])        return morphsdef mecab_pos(text):    pos = []    # 우리가 원하는 TOKEN\\tPOS의 형태를 추출하는 정규표현식.    pattern = re.compile(\".*\\t[A-Z]+\")         # 패턴에 맞는 문자열을 추출하여 konlpy의 mecab 결과와 같아지도록 수정.    pos = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]        #group(0)으로 string으로 만들어 준다    return pos  정규 표현식은 특정한 규칙을 가진 문자열의 패턴을 표현하는 데 사용하는 표현식(Expression)으로 텍스트에서 특정 문자열을 검색하거나 치환할 때 흔히 사용된다.문장 분석 품질 비교  1. 띄어쓰기가 제대로 되어있지 않은 문장text = \"아버지가방에들어가신다\"# 꼬꼬마 형태소 분석 결과kkma.pos(text)[('아버지', 'NNG'), ('가방', 'NNG'), ('에', 'JKM'), ('들어가', 'VV'), ('시', 'EPH'), ('ㄴ다', 'EFN')]# 코모란 형태소 분석 결과komoran.pos(text)[('아버지', 'NNG'), ('가방', 'NNP'), ('에', 'JKB'), ('들어가', 'VV'), ('시', 'EP'), ('ㄴ다', 'EC')]hannanum.pos(text)[('아버지가방에들어가', 'N'), ('이', 'J'), ('시ㄴ다', 'E')]mecab_pos(text)[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('신다', 'EP')]okt.pos(text)[('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]  2. 오탈자 때문에 불완전한 문장text2 = \"ㄱㅐㄴㅏ리가 피어있는 동산에 누워있고싶ㄷㅏ\"# 꼬꼬마 형태소 결과 출력하기.print(\"꼬꼬마 : %s\\n\" % kkma.pos(text2))print(\"코모란 : %s\\n\" % komoran.pos(text2))print(\"한나눔 : %s\\n\" % hannanum.pos(text2))print(\"mecab : %s\\n\" % mecab_pos(text2))print(\"Okt : %s\\n\" % okt.pos(text2))꼬꼬마 : [('ㄱㅐㄴㅏ리', 'UN'), ('가', 'JKS'), ('피', 'VV'), ('어', 'ECD'), ('있', 'VXV'), ('는', 'ETD'), ('동산', 'NNG'), ('에', 'JKM'), ('눕', 'VV'), ('어', 'ECS'), ('있', 'VV'), ('고', 'ECE'), ('싶ㄷㅏ', 'UN')]코모란 : [('개나리', 'NNP'), ('가', 'JKS'), ('피', 'VV'), ('어', 'EC'), ('있', 'VX'), ('는', 'ETM'), ('동산', 'NNP'), ('에', 'JKB'), ('눕', 'VV'), ('어', 'EC'), ('있', 'VX'), ('고', 'EC'), ('싶', 'VX'), ('다', 'EC')]한나눔 : [('ㄱㅐㄴㅏ리', 'N'), ('가', 'J'), ('피', 'P'), ('어', 'E'), ('있', 'P'), ('는', 'E'), ('동산', 'N'), ('에', 'J'), ('누워있고싶ㄷㅏ', 'N')]mecab : [('ㄱ', 'NNG'), ('ㅐㄴㅏ리가', 'UNKNOWN'), ('피', 'VV'), ('어', 'EC'), ('있', 'VX'), ('는', 'ETM'), ('동산', 'NNG'), ('에', 'JKB'), ('누워', 'VV'), ('있', 'VX'), ('고', 'EC'), ('싶', 'VX'), ('ㄷ', 'NNG'), ('ㅏ', 'UNKNOWN')]Okt : [('ㄱㅐㄴㅏ', 'KoreanParticle'), ('리가', 'Noun'), ('피어있는', 'Verb'), ('동산', 'Noun'), ('에', 'Josa'), ('누워있고싶', 'Verb'), ('ㄷㅏ', 'KoreanParticle')]  3. 속도 비교text3 = \"\"\"5G 이동통신망을 빌려 사용하는 ‘5G 알뜰폰’이 올해 도입되고, 내년부터는 의무화된다.정부는 알뜰폰 사업자(MNVO)가 통신사(MNO)에 통신망을 빌리는 비용(도매대가)을 지난해보다 큰 폭으로 낮춰, 알뜰폰 요금 인하를 유도하기로 했다. 하지만 줄어드는 알뜰폰 시장을 살릴 수 있을지는 지켜봐야 하는 상황이다.과학기술정보통신부는 알뜰폰 활성화 추진대책을 25일 발표했다. 알뜰폰 가입자는 800만명으로 이동통신 시장의 12%를 차지한다. 2011년 출시 뒤 저렴한 요금제로 통신비 부담을 낮춰왔다. 하지만 지난해 5월 통신 3사가 준보편제 요금을 내놓은 이후 알뜰폰 이탈 현상이 지속되고 있다.우선 올해 안에 3개 이상의 5G 알뜰폰이 시장에 나온다. 통신사가 5G망을 알뜰폰 사업자에게 도매 제공할지 여부는 통신사 자율로 정한다. 앞서 LG유플러스는 오는 10월 알뜰폰 사업을 시작하는 KB국민은행에 5G망을 제공한다고 밝힌 바 있다. SK텔레콤와 KT도 특정 제휴사를 선택해 올해 안에 5G 알뜰폰을 내놓기로 했다.내년부터는 5G 알뜰폰 제공이 의무화된다. 지난 22일자로 종료된 도매제공 의무제도의 유효기간을 2022년 9월22일까지 연장하는 전기통신사업법 개정안이 국회에서 통과되면, 관련 고시를 개정해 SK텔레콤의 5G망 도매제공을 의무화하겠다는 것이다.과기정통부 관계자는 “SK텔레콤이 자사와 계약을 맺은 13개 알뜰폰 사업자에게 5G망을 의무 제공하면, 그 외 31개의 알뜰폰 사업자들이 경쟁에서 밀릴 것을 우려해 KT와 LG유플러스도 5G망을 제공하게 될 것”이라고 내다봤다.알뜰폰 사업자가 상품을 만드는 방식 크게 2가지다. 하나는 통신사로부터 음성·문자·데이터를 도매로 사들인 뒤 이를 바탕으로 통신사보다 저렴한 요금제를 내놓는 방식(종량제 도매제공)이다. 이를 위해 정부는 도매대가 인하율을 음성 17.8%, 데이터 19.2%, 단문메시지 1.15%로, 지난해 음성 15.1%, 데이터 19.1%, 단문메시지 1.13%에 비해 높여 잡았다.또 다른 방식은 일정비용을 통신사에 내고 통신사의 정액 요금제를 그대로 판매하면서, 그 차액의 범위에서 저렴한 요금제를 내놓는 방식(수익배분 도매제공)이다. 정부는 SK텔레콤의 준보편 요금제인 ‘T플랜 요금제’를 알뜰폰 사업자가 재판매할 수 있게 했다. 기존에 SK텔레콤이 도매제공했던 ‘밴드데이터 요금제’의 최고구간의 대가도 1.5%포인트 낮췄다.알뜰폰 업계는 대체로 반기는 분위기지만, 알뜰폰 시장을 살릴 수 있을지에는 의구심을 갖고 있다. 업계 관계자는 “도매대가 인하율이 크고, 5G망을 제공하는 것은 긍정적”이라면서도 “수익배분 도매제공의 의무화, 설비를 가진 업체에 대한 접속료 정산 도입 등의 제도적 개선이 필요하다”고 말했다.\"\"\"%%timeprint(kkma.pos(text3)[:5])[('5', 'NR'), ('G', 'OL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO')]Wall time: 4.13 s%%timeprint(komoran.pos(text3)[:5])[('5', 'SN'), ('G', 'SL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO')]Wall time: 70 ms%%timeprint(hannanum.pos(text3)[:5])[('5G', 'N'), ('이동통신망', 'N'), ('을', 'J'), ('빌리', 'P'), ('어', 'E')]Wall time: 1.82 s%%timeprint(mecab_pos(text3)[:5])#5개만 짤라서 출력결과 확인 가능[('5', 'SN'), ('G', 'SL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO')]Wall time: 256 ms%%timeprint(mecab_nouns(text3))['이동', '통신망', '사용', '알뜰', '폰', '올해', '도입', '내년', '의무', '정부', '알뜰', '폰', '사업자', '통신사', '통신망', '비용', '도매', '대가', '지난해', '폭', '알뜰', '폰', '요금', '인하', '유도', '알뜰', '폰', '시장', '수', '상황', '과학', '기술', '정보', '통신부', '알뜰', '폰', '활성', '추진', '대책', '일', '발표', '알뜰', '폰', '가입자', '만', '명', '이동', '통신', '시장', '차지', '년', '출시', '뒤', '요금제', '통신비', '부담', '지난해', '월', '통신', '사', '준보', '편제', '요금', '이후', '알뜰', '폰', '이탈', '현상', '지속', '올해', '안', '개', '이상', '알뜰', '폰', '시장', '통신사', '망', '알뜰', '폰', '사업자', '도매', '제공', '여부', '통신사', '자율', '유', '플러스', '월', '알뜰', '폰', '사업', '시작', '국민은행', '망', '제공', '바', '텔레콤', '특정', '휴사', '선택', '올해', '안', '알뜰', '폰', '내년', '알뜰', '폰', '제공', '의무', '일자', '종료', '도매', '제공', '의무', '제도', '유효', '기간', '년', '월', '일', '연장', '전기', '통신', '사업', '법', '개정안', '국회', '통과', '관련', '고시', '개정', '텔레콤', '망', '도매', '제공', '의무', '것', '과기', '정통부', '관계자', '텔레콤', '자사', '계약', '개', '알뜰', '폰', '사업자', '망', '의무', '제공', '외', '개', '알뜰', '폰', '사업자', '경쟁', '것', '우려', '유', '플러스', '망', '제공', '것', '알뜰', '폰', '사업자', '상품', '방식', '가지', '하나', '통신사', '음성', '문자', '데이터', '도매', '뒤', '이', '바탕', '통신사', '요금제', '방식', '종량제', '도매', '제공', '이', '정부', '도매', '대가', '인하', '음성', '데이터', '단문', '메시지', '지난해', '음성', '데이터', '단문', '메시지', '방식', '일정', '비용', '통신사', '통신사', '정액', '요금제', '판매', '차액', '범위', '요금제', '방식', '수익', '배분', '도매', '제공', '정부', '텔레콤', '보편', '요금', '제인', '플랜', '요금제', '알뜰', '폰', '사업자', '판매', '수', '기존', '텔레콤', '도매', '제공', '밴드', '데이터', '요금제', '최고', '구간', '대가', '포인트', '알뜰', '폰', '업계', '분위기', '알뜰', '폰', '시장', '수', '의구심', '업계', '관계자', '매대', '인하', '망', '제공', '것', '긍정', '서도', '수익', '배분', '도매', '제공', '의무', '설비', '업체', '접', '속료', '정산', '도입', '등', '제도', '개선', '필요', '말']Wall time: 4 ms%%timeprint(mecab_pos(text3))[('5', 'SN'), ('G', 'SL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO'), ('빌려', 'VV'), ('사용', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('‘', 'SY'), ('5', 'SN'), ('G', 'SL'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('’', 'SY'), ('이', 'MM'), ('올해', 'NNG'), ('도입', 'NNG'), ('되', 'XSV'), ('고', 'EC'), (',', 'SC'), ('내년', 'NNG'), ('부터', 'JX'), ('는', 'JX'), ('의무', 'NNG'), ('화', 'XSN'), ('된다', 'XSV'), ('.', 'SF'), ('정부', 'NNG'), ('는', 'JX'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업자', 'NNG'), ('(', 'SSO'), ('MNVO', 'SL'), (')', 'SSC'), ('가', 'JKS'), ('통신사', 'NNG'), ('(', 'SSO'), ('MNO', 'SL'), (')', 'SSC'), ('에', 'JKB'), ('통신망', 'NNG'), ('을', 'JKO'), ('빌리', 'VV'), ('는', 'ETM'), ('비용', 'NNG'), ('(', 'SSO'), ('도매', 'NNG'), ('대가', 'NNG'), (')', 'SSC'), ('을', 'JKO'), ('지난해', 'NNG'), ('보다', 'JKB'), ('큰', 'VA'), ('폭', 'NNG'), ('으로', 'JKB'), ('낮춰', 'VV'), (',', 'SC'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('요금', 'NNG'), ('인하', 'NNG'), ('를', 'JKO'), ('유도', 'NNG'), ('하', 'XSV'), ('기', 'ETN'), ('로', 'JKB'), ('했', 'VV'), ('다', 'EF'), ('.', 'SF'), ('하', 'VV'), ('지만', 'EC'), ('줄어드', 'VV'), ('는', 'ETM'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('시장', 'NNG'), ('을', 'JKO'), ('살릴', 'VV'), ('수', 'NNB'), ('있', 'VV'), ('을지', 'EC'), ('는', 'JX'), ('지켜봐야', 'VV'), ('하', 'VV'), ('는', 'ETM'), ('상황', 'NNG'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('과학', 'NNG'), ('기술', 'NNG'), ('정보', 'NNG'), ('통신부', 'NNG'), ('는', 'JX'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('활성', 'NNG'), ('화', 'XSN'), ('추진', 'NNG'), ('대책', 'NNG'), ('을', 'JKO'), ('25', 'SN'), ('일', 'NNBC'), ('발표', 'NNG'), ('했', 'XSV'), ('다', 'EF'), ('.', 'SF'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('가입자', 'NNG'), ('는', 'JX'), ('800', 'SN'), ('만', 'NR'), ('명', 'NNBC'), ('으로', 'JKB'), ('이동', 'NNG'), ('통신', 'NNG'), ('시장', 'NNG'), ('의', 'JKG'), ('12', 'SN'), ('%', 'SY'), ('를', 'JKO'), ('차지', 'NNG'), ('한다', 'XSV'), ('.', 'SY'), ('2011', 'SN'), ('년', 'NNBC'), ('출시', 'NNG'), ('뒤', 'NNG'), ('저렴', 'XR'), ('한', 'XSA'), ('요금제', 'NNP'), ('로', 'JKB'), ('통신비', 'NNG'), ('부담', 'NNG'), ('을', 'JKO'), ('낮춰', 'VV'), ('왔', 'VX'), ('다', 'EF'), ('.', 'SF'), ('하지만', 'MAJ'), ('지난해', 'NNG'), ('5', 'SN'), ('월', 'NNBC'), ('통신', 'NNG'), ('3', 'SN'), ('사', 'NR'), ('가', 'JKS'), ('준보', 'NNG'), ('편제', 'NNG'), ('요금', 'NNG'), ('을', 'JKO'), ('내놓', 'VV'), ('은', 'ETM'), ('이후', 'NNG'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('이탈', 'NNG'), ('현상', 'NNG'), ('이', 'JKS'), ('지속', 'NNG'), ('되', 'XSV'), ('고', 'EC'), ('있', 'VX'), ('다', 'EF'), ('.', 'SF'), ('우선', 'MAG'), ('올해', 'NNG'), ('안', 'NNG'), ('에', 'JKB'), ('3', 'SN'), ('개', 'NNBC'), ('이상', 'NNG'), ('의', 'JKG'), ('5', 'SN'), ('G', 'SL'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('이', 'JKS'), ('시장', 'NNG'), ('에', 'JKB'), ('나온다', 'VV'), ('.', 'SF'), ('통신사', 'NNG'), ('가', 'JKS'), ('5', 'SN'), ('G', 'SL'), ('망', 'NNG'), ('을', 'JKO'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업자', 'NNG'), ('에게', 'JKB'), ('도매', 'NNG'), ('제공', 'NNG'), ('할지', 'XSV'), ('여부', 'NNG'), ('는', 'JX'), ('통신사', 'NNG'), ('자율', 'NNG'), ('로', 'JKB'), ('정한다', 'VV'), ('.', 'SF'), ('앞서', 'VV'), ('LG', 'SL'), ('유', 'NNP'), ('플러스', 'NNP'), ('는', 'JX'), ('오', 'VV'), ('는', 'ETM'), ('10', 'SN'), ('월', 'NNBC'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업', 'NNG'), ('을', 'JKO'), ('시작', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('KB', 'SL'), ('국민은행', 'NNP'), ('에', 'JKB'), ('5', 'SN'), ('G', 'SL'), ('망', 'NNG'), ('을', 'JKO'), ('제공', 'NNG'), ('한다고', 'XSV'), ('밝힌', 'VV'), ('바', 'NNB'), ('있', 'VV'), ('다', 'EF'), ('.', 'SF'), ('SK', 'SL'), ('텔레콤', 'NNP'), ('와', 'JC'), ('KT', 'SL'), ('도', 'JX'), ('특정', 'NNG'), ('제', 'MM'), ('휴사', 'NNG'), ('를', 'JKO'), ('선택', 'NNG'), ('해', 'XSV'), ('올해', 'NNG'), ('안', 'NNG'), ('에', 'JKB'), ('5', 'SN'), ('G', 'SL'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('을', 'JKO'), ('내놓', 'VV'), ('기', 'ETN'), ('로', 'JKB'), ('했', 'VV'), ('다', 'EF'), ('.', 'SF'), ('내년', 'NNG'), ('부터', 'JX'), ('는', 'JX'), ('5', 'SN'), ('G', 'SL'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('제공', 'NNG'), ('이', 'JKS'), ('의무', 'NNG'), ('화', 'XSN'), ('된다', 'XSV'), ('.', 'SF'), ('지난', 'VV'), ('22', 'SN'), ('일자', 'NNG'), ('로', 'JKB'), ('종료', 'NNG'), ('된', 'XSV'), ('도매', 'NNG'), ('제공', 'NNG'), ('의무', 'NNG'), ('제도', 'NNG'), ('의', 'JKG'), ('유효', 'NNG'), ('기간', 'NNG'), ('을', 'JKO'), ('2022', 'SN'), ('년', 'NNBC'), ('9', 'SN'), ('월', 'NNBC'), ('22', 'SN'), ('일', 'NNBC'), ('까지', 'JX'), ('연장', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('전기', 'NNG'), ('통신', 'NNG'), ('사업', 'NNG'), ('법', 'NNG'), ('개정안', 'NNG'), ('이', 'JKS'), ('국회', 'NNG'), ('에서', 'JKB'), ('통과', 'NNG'), ('되', 'XSV'), ('면', 'EC'), (',', 'SC'), ('관련', 'NNG'), ('고시', 'NNG'), ('를', 'JKO'), ('개정', 'NNG'), ('해', 'XSV'), ('SK', 'SL'), ('텔레콤', 'NNP'), ('의', 'JKG'), ('5', 'SN'), ('G', 'SL'), ('망', 'NNG'), ('도매', 'NNG'), ('제공', 'NNG'), ('을', 'JKO'), ('의무', 'NNG'), ('화', 'XSN'), ('하', 'XSV'), ('겠', 'EP'), ('다는', 'ETM'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('과기', 'NNG'), ('정통부', 'NNG'), ('관계자', 'NNG'), ('는', 'JX'), ('“', 'SSO'), ('SK', 'SL'), ('텔레콤', 'NNP'), ('이', 'JKS'), ('자사', 'NNG'), ('와', 'JC'), ('계약', 'NNG'), ('을', 'JKO'), ('맺', 'VV'), ('은', 'ETM'), ('13', 'SN'), ('개', 'NNBC'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업자', 'NNG'), ('에게', 'JKB'), ('5', 'SN'), ('G', 'SL'), ('망', 'NNG'), ('을', 'JKO'), ('의무', 'NNG'), ('제공', 'NNG'), ('하', 'XSV'), ('면', 'EC'), (',', 'SC'), ('그', 'MM'), ('외', 'NNB'), ('31', 'SN'), ('개', 'NNBC'), ('의', 'JKG'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업자', 'NNG'), ('들', 'XSN'), ('이', 'JKS'), ('경쟁', 'NNG'), ('에서', 'JKB'), ('밀릴', 'VV'), ('것', 'NNB'), ('을', 'JKO'), ('우려', 'NNG'), ('해', 'XSV'), ('KT', 'SL'), ('와', 'JC'), ('LG', 'SL'), ('유', 'NNG'), ('플러스', 'NNG'), ('도', 'JX'), ('5', 'SN'), ('G', 'SL'), ('망', 'NNG'), ('을', 'JKO'), ('제공', 'NNG'), ('하', 'XSV'), ('게', 'EC'), ('될', 'VV'), ('것', 'NNB'), ('”', 'SSC'), ('이', 'VCP'), ('라고', 'EC'), ('내', 'VX'), ('다', 'EC'), ('봤', 'VX'), ('다', 'EF'), ('.', 'SF'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업자', 'NNG'), ('가', 'JKS'), ('상품', 'NNG'), ('을', 'JKO'), ('만드', 'VV'), ('는', 'ETM'), ('방식', 'NNG'), ('크', 'VA'), ('게', 'EC'), ('2', 'SN'), ('가지', 'NNBC'), ('다', 'VCP'), ('.', 'SF'), ('하나', 'NR'), ('는', 'JX'), ('통신사', 'NNG'), ('로부터', 'JKB'), ('음성', 'NNG'), ('·', 'SC'), ('문자', 'NNG'), ('·', 'SC'), ('데이터', 'NNG'), ('를', 'JKO'), ('도매', 'NNG'), ('로', 'JKB'), ('사들인', 'VV'), ('뒤', 'NNG'), ('이', 'NP'), ('를', 'JKO'), ('바탕', 'NNG'), ('으로', 'JKB'), ('통신사', 'NNG'), ('보다', 'JKB'), ('저렴', 'XR'), ('한', 'XSA'), ('요금제', 'NNP'), ('를', 'JKO'), ('내놓', 'VV'), ('는', 'ETM'), ('방식', 'NNG'), ('(', 'SSO'), ('종량제', 'NNG'), ('도매', 'NNG'), ('제공', 'NNG'), (')', 'SSC'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('이', 'NP'), ('를', 'JKO'), ('위해', 'VV'), ('정부', 'NNG'), ('는', 'JX'), ('도매', 'NNG'), ('대가', 'NNG'), ('인하', 'NNG'), ('율', 'XSN'), ('을', 'JKO'), ('음성', 'NNG'), ('17', 'SN'), ('.', 'SY'), ('8', 'SN'), ('%,', 'SY'), ('데이터', 'NNG'), ('19', 'SN'), ('.', 'SY'), ('2', 'SN'), ('%,', 'SY'), ('단문', 'NNG'), ('메시지', 'NNG'), ('1', 'SN'), ('.', 'SY'), ('15', 'SN'), ('%', 'SY'), ('로', 'JKB'), (',', 'SC'), ('지난해', 'NNG'), ('음성', 'NNG'), ('15', 'SN'), ('.', 'SY'), ('1', 'SN'), ('%,', 'SY'), ('데이터', 'NNG'), ('19', 'SN'), ('.', 'SY'), ('1', 'SN'), ('%,', 'SY'), ('단문', 'NNG'), ('메시지', 'NNG'), ('1', 'SN'), ('.', 'SY'), ('13', 'SN'), ('%', 'SY'), ('에', 'JKB'), ('비해', 'VV'), ('높여', 'VV'), ('잡', 'VV'), ('았', 'EP'), ('다', 'EF'), ('.', 'SF'), ('또', 'MAG'), ('다른', 'MM'), ('방식', 'NNG'), ('은', 'JX'), ('일정', 'NNG'), ('비용', 'NNG'), ('을', 'JKO'), ('통신사', 'NNG'), ('에', 'JKB'), ('내', 'VV'), ('고', 'EC'), ('통신사', 'NNG'), ('의', 'JKG'), ('정액', 'NNG'), ('요금제', 'NNP'), ('를', 'JKO'), ('그대로', 'MAG'), ('판매', 'NNG'), ('하', 'XSV'), ('면서', 'EC'), (',', 'SC'), ('그', 'MM'), ('차액', 'NNG'), ('의', 'JKG'), ('범위', 'NNG'), ('에서', 'JKB'), ('저렴', 'XR'), ('한', 'XSA'), ('요금제', 'NNP'), ('를', 'JKO'), ('내놓', 'VV'), ('는', 'ETM'), ('방식', 'NNG'), ('(', 'SSO'), ('수익', 'NNG'), ('배분', 'NNG'), ('도매', 'NNG'), ('제공', 'NNG'), (')', 'SSC'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('정부', 'NNG'), ('는', 'JX'), ('SK', 'SL'), ('텔레콤', 'NNP'), ('의', 'JKG'), ('준', 'XPN'), ('보편', 'NNG'), ('요금', 'NNG'), ('제인', 'NNG'), ('‘', 'SY'), ('T', 'SL'), ('플랜', 'NNG'), ('요금제', 'NNP'), ('’', 'SY'), ('를', 'JKO'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('사업자', 'NNG'), ('가', 'JKS'), ('재', 'XPN'), ('판매', 'NNG'), ('할', 'XSV'), ('수', 'NNB'), ('있', 'VV'), ('게', 'EC'), ('했', 'VX'), ('다', 'EF'), ('.', 'SF'), ('기존', 'NNG'), ('에', 'JKB'), ('SK', 'SL'), ('텔레콤', 'NNP'), ('이', 'JKS'), ('도매', 'NNG'), ('제공', 'NNG'), ('했', 'XSV'), ('던', 'ETM'), ('‘', 'SY'), ('밴드', 'NNG'), ('데이터', 'NNG'), ('요금제', 'NNP'), ('’', 'SY'), ('의', 'JKG'), ('최고', 'NNG'), ('구간', 'NNG'), ('의', 'JKG'), ('대가', 'NNG'), ('도', 'JX'), ('1', 'SN'), ('.', 'SY'), ('5', 'SN'), ('%', 'SY'), ('포인트', 'NNG'), ('낮췄', 'VV'), ('다', 'EF'), ('.', 'SF'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('업계', 'NNG'), ('는', 'JX'), ('대체로', 'MAG'), ('반기', 'VV'), ('는', 'ETM'), ('분위기', 'NNG'), ('지만', 'VCP'), (',', 'SC'), ('알뜰', 'NNG'), ('폰', 'NNG'), ('시장', 'NNG'), ('을', 'JKO'), ('살릴', 'VV'), ('수', 'NNB'), ('있', 'VV'), ('을지', 'EC'), ('에', 'JKB'), ('는', 'JX'), ('의구심', 'NNG'), ('을', 'JKO'), ('갖', 'VV'), ('고', 'EC'), ('있', 'VX'), ('다', 'EF'), ('.', 'SF'), ('업계', 'NNG'), ('관계자', 'NNG'), ('는', 'JX'), ('“', 'SSO'), ('도', 'JX'), ('매대', 'NNG'), ('가', 'JKS'), ('인하', 'NNG'), ('율', 'XSN'), ('이', 'JKS'), ('크', 'VA'), ('고', 'EC'), (',', 'SC'), ('5', 'SN'), ('G', 'SL'), ('망', 'NNG'), ('을', 'JKO'), ('제공', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('것', 'NNB'), ('은', 'JX'), ('긍정', 'NNG'), ('적', 'XSN'), ('”', 'SSC'), ('이', 'VCP'), ('라면', 'EC'), ('서도', 'NNG'), ('“', 'SSO'), ('수익', 'NNG'), ('배분', 'NNG'), ('도매', 'NNG'), ('제공', 'NNG'), ('의', 'JKG'), ('의무', 'NNG'), ('화', 'XSN'), (',', 'SC'), ('설비', 'NNG'), ('를', 'JKO'), ('가진', 'VV'), ('업체', 'NNG'), ('에', 'JKB'), ('대한', 'VV'), ('접', 'NNBC'), ('속료', 'NNG'), ('정산', 'NNG'), ('도입', 'NNG'), ('등', 'NNB'), ('의', 'JKG'), ('제도', 'NNG'), ('적', 'XSN'), ('개선', 'NNG'), ('이', 'JKS'), ('필요', 'NNG'), ('하', 'XSA'), ('다', 'EC'), ('”', 'SSC'), ('고', 'EC'), ('말', 'NNG'), ('했', 'XSV'), ('다', 'EF'), ('.', 'SF')]Wall time: 3 ms%%timeprint(mecab_morphs(text3))['5', 'G', '이동', '통신망', '을', '빌려', '사용', '하', '는', '‘', '5', 'G', '알뜰', '폰', '’', '이', '올해', '도입', '되', '고', ',', '내년', '부터', '는', '의무', '화', '된다', '.', '정부', '는', '알뜰', '폰', '사업자', '(', 'MNVO', ')', '가', '통신사', '(', 'MNO', ')', '에', '통신망', '을', '빌리', '는', '비용', '(', '도매', '대가', ')', '을', '지난해', '보다', '큰', '폭', '으로', '낮춰', ',', '알뜰', '폰', '요금', '인하', '를', '유도', '하', '기', '로', '했', '다', '.', '하', '지만', '줄어드', '는', '알뜰', '폰', '시장', '을', '살릴', '수', '있', '을지', '는', '지켜봐야', '하', '는', '상황', '이', '다', '.', '과학', '기술', '정보', '통신부', '는', '알뜰', '폰', '활성', '화', '추진', '대책', '을', '25', '일', '발표', '했', '다', '.', '알뜰', '폰', '가입자', '는', '800', '만', '명', '으로', '이동', '통신', '시장', '의', '12', '%', '를', '차지', '한다', '.', '2011', '년', '출시', '뒤', '저렴', '한', '요금제', '로', '통신비', '부담', '을', '낮춰', '왔', '다', '.', '하지만', '지난해', '5', '월', '통신', '3', '사', '가', '준보', '편제', '요금', '을', '내놓', '은', '이후', '알뜰', '폰', '이탈', '현상', '이', '지속', '되', '고', '있', '다', '.', '우선', '올해', '안', '에', '3', '개', '이상', '의', '5', 'G', '알뜰', '폰', '이', '시장', '에', '나온다', '.', '통신사', '가', '5', 'G', '망', '을', '알뜰', '폰', '사업자', '에게', '도매', '제공', '할지', '여부', '는', '통신사', '자율', '로', '정한다', '.', '앞서', 'LG', '유', '플러스', '는', '오', '는', '10', '월', '알뜰', '폰', '사업', '을', '시작', '하', '는', 'KB', '국민은행', '에', '5', 'G', '망', '을', '제공', '한다고', '밝힌', '바', '있', '다', '.', 'SK', '텔레콤', '와', 'KT', '도', '특정', '제', '휴사', '를', '선택', '해', '올해', '안', '에', '5', 'G', '알뜰', '폰', '을', '내놓', '기', '로', '했', '다', '.', '내년', '부터', '는', '5', 'G', '알뜰', '폰', '제공', '이', '의무', '화', '된다', '.', '지난', '22', '일자', '로', '종료', '된', '도매', '제공', '의무', '제도', '의', '유효', '기간', '을', '2022', '년', '9', '월', '22', '일', '까지', '연장', '하', '는', '전기', '통신', '사업', '법', '개정안', '이', '국회', '에서', '통과', '되', '면', ',', '관련', '고시', '를', '개정', '해', 'SK', '텔레콤', '의', '5', 'G', '망', '도매', '제공', '을', '의무', '화', '하', '겠', '다는', '것', '이', '다', '.', '과기', '정통부', '관계자', '는', '“', 'SK', '텔레콤', '이', '자사', '와', '계약', '을', '맺', '은', '13', '개', '알뜰', '폰', '사업자', '에게', '5', 'G', '망', '을', '의무', '제공', '하', '면', ',', '그', '외', '31', '개', '의', '알뜰', '폰', '사업자', '들', '이', '경쟁', '에서', '밀릴', '것', '을', '우려', '해', 'KT', '와', 'LG', '유', '플러스', '도', '5', 'G', '망', '을', '제공', '하', '게', '될', '것', '”', '이', '라고', '내', '다', '봤', '다', '.', '알뜰', '폰', '사업자', '가', '상품', '을', '만드', '는', '방식', '크', '게', '2', '가지', '다', '.', '하나', '는', '통신사', '로부터', '음성', '·', '문자', '·', '데이터', '를', '도매', '로', '사들인', '뒤', '이', '를', '바탕', '으로', '통신사', '보다', '저렴', '한', '요금제', '를', '내놓', '는', '방식', '(', '종량제', '도매', '제공', ')', '이', '다', '.', '이', '를', '위해', '정부', '는', '도매', '대가', '인하', '율', '을', '음성', '17', '.', '8', '%,', '데이터', '19', '.', '2', '%,', '단문', '메시지', '1', '.', '15', '%', '로', ',', '지난해', '음성', '15', '.', '1', '%,', '데이터', '19', '.', '1', '%,', '단문', '메시지', '1', '.', '13', '%', '에', '비해', '높여', '잡', '았', '다', '.', '또', '다른', '방식', '은', '일정', '비용', '을', '통신사', '에', '내', '고', '통신사', '의', '정액', '요금제', '를', '그대로', '판매', '하', '면서', ',', '그', '차액', '의', '범위', '에서', '저렴', '한', '요금제', '를', '내놓', '는', '방식', '(', '수익', '배분', '도매', '제공', ')', '이', '다', '.', '정부', '는', 'SK', '텔레콤', '의', '준', '보편', '요금', '제인', '‘', 'T', '플랜', '요금제', '’', '를', '알뜰', '폰', '사업자', '가', '재', '판매', '할', '수', '있', '게', '했', '다', '.', '기존', '에', 'SK', '텔레콤', '이', '도매', '제공', '했', '던', '‘', '밴드', '데이터', '요금제', '’', '의', '최고', '구간', '의', '대가', '도', '1', '.', '5', '%', '포인트', '낮췄', '다', '.', '알뜰', '폰', '업계', '는', '대체로', '반기', '는', '분위기', '지만', ',', '알뜰', '폰', '시장', '을', '살릴', '수', '있', '을지', '에', '는', '의구심', '을', '갖', '고', '있', '다', '.', '업계', '관계자', '는', '“', '도', '매대', '가', '인하', '율', '이', '크', '고', ',', '5', 'G', '망', '을', '제공', '하', '는', '것', '은', '긍정', '적', '”', '이', '라면', '서도', '“', '수익', '배분', '도매', '제공', '의', '의무', '화', ',', '설비', '를', '가진', '업체', '에', '대한', '접', '속료', '정산', '도입', '등', '의', '제도', '적', '개선', '이', '필요', '하', '다', '”', '고', '말', '했', '다', '.']Wall time: 6 ms%%timeprint(okt.pos(text3)[:5])[('5', 'Number'), ('G', 'Alpha'), ('이', 'Determiner'), ('동', 'Modifier'), ('통신망', 'Noun')]Wall time: 302 ms",
        "url": "/newstext-konlpy"
    }
    ,
    
    "newstext-a1": {
        "title": "기사 텍스트 정제 - 형태소 분석기 성능비교",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)konlpy 형태소 분석기 성능비교  anaconda 터미널에서 설치하기  conda create -n text_analysis python=3.6 anaconda(base) C:&gt;conda activate text_analysis(text_analysis) PS C:&gt;pip install konlpy 설치해 주기https://konlpy-ko.readthedocs.io/ko/v0.4.3/KoNLPy: 파이썬 한국어 NLPKoNLPy(“코엔엘파이”라고 읽습니다)는 한국어 정보처리를 위한 파이썬 패키지#######################################################################  설치 과정(text_analysis) PS C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages&gt; pip install .\\mecab_python-0.996_ko_0.9.2_msvc-cp36-cp36m-win_amd64.whlProcessing c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\mecab_python-0.996_ko_0.9.2_msvc-cp36-cp36m-win_amd64.whlInstalling collected packages: mecab-pythonSuccessfully installed mecab-python-0.996-ko-0.9.2-msvc(text_analysis) PS C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages&gt; pythonPython 3.6.10 |Anaconda, Inc.| (default, May  7 2020, 19:46:08) [MSC v.1916 64 bit (AMD64)] on win32Type “help”, “copyright”, “credits” or “license” for more information.            import MeCab                  m - Me      MeCab        MemoryError(            m - MeCab.Tagger()      Traceback (most recent call last):File “\", line 1, in NameError: name 'm' is not defined            m = MeCab.Tagger()                  out = m.parse(“미캅이 잘 설치되었는지 확인합니다.”)                  pr      print(    property(            print(out)미      NNP,인명,F,미,,,,캅      NNP,인명,T,캅,,,,이      JKS,,F,이,,,,*잘      MAG,,T,잘,,,,*설치    NNG,행위,F,설치,,,,되      XSV,,F,되,,,,*었      EP,,T,었,,,,*는지    EC,,F,는지,,,,*확인    NNG,행위,T,확인,,,,합니다  XSV+EF,,F,합니다,Inflect,XSV,EF,하/XSV/+ᄇ니다/EF/*.       SF,,,,,,,*EOS            중간에 오타 가 좀 있습니다        change kernel 에서 Python [conda env:text_analysis]  가상환경 변경해 주기  #!pip install eunjeon!pip install konlpyRequirement already satisfied: konlpy in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (0.5.2)Requirement already satisfied: lxml&gt;=4.1.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from konlpy) (4.5.2)Requirement already satisfied: colorama in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from konlpy) (0.4.3)Requirement already satisfied: JPype1&gt;=0.7.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from konlpy) (1.0.2)Requirement already satisfied: numpy&gt;=1.6 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from konlpy) (1.17.0)Requirement already satisfied: tweepy&gt;=3.7.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from konlpy) (3.10.0)Requirement already satisfied: beautifulsoup4==4.6.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from konlpy) (4.6.0)Requirement already satisfied: typing-extensions in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from JPype1&gt;=0.7.0-&gt;konlpy) (3.7.4.2)Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (1.3.0)Requirement already satisfied: requests[socks]&gt;=2.11.1 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (2.24.0)Requirement already satisfied: six&gt;=1.10.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (1.15.0)WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.You should consider upgrading via the 'c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\python.exe -m pip install --upgrade pip' command.Requirement already satisfied: oauthlib&gt;=3.0.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (3.1.1)Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (3.0.4)Requirement already satisfied: certifi&gt;=2017.4.17 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (2020.6.20)Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (1.25.9)Requirement already satisfied: idna&lt;3,&gt;=2.5 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (2.10)Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (1.7.1)!pip install eunjeonRequirement already satisfied: eunjeon in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (0.4.0)WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.You should consider upgrading via the 'c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\python.exe -m pip install --upgrade pip' command.Python [conda env:text_analysis]  kernel 써줌from konlpy.tag import Mecabmecab = Mecab(dicpath='C:\\mecab\\mecab-ko-dic')print(mecab.morphs(u'서울대입구역의.'))['서울대입구역', '의', '.']from konlpy.tag import Kkmafrom konlpy.tag import Komoranfrom konlpy.tag import Hannanumfrom konlpy.tag import Okt# 형태소 분석을 위한 객체 생성.kkma = Kkma()komoran = Komoran()hannanum = Hannanum()okt = Okt()  Kkma is a morphological analyzer and natural language processing system written in Java, developed by the Intelligent Data Systems (IDS) Laboratory at SNU.  Kkma는 서울대학교 IDS(Intelligent Data Systems) 연구소에서 개발한 Java로 작성된 형태소 분석기 및 자연어 처리 시스템입니다.      코모란은 2013년부터 샤인웨어에서 개발한 비교적 새로운 오픈소스 한국어 형태소 분석기입니다.        Okt(Open Korean Text)는 트위터에서 만든 오픈소스 한국어 처리기인 twitter-korean-text를 이어받아 만들고 있는 프로젝트이다.  문장 분석 품질 비교  1. 띄어쓰기가 제대로 되어있지 않은 문장text = \"아버지가방에들어가신다\"# 꼬꼬마 형태소 분석 결과# 코모란 형태소 분석 결과hannanum.pos(text)[('아버지가방에들어가', 'N'), ('이', 'J'), ('시ㄴ다', 'E')]mecab.pos(text)[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('신다', 'EP+EC')]okt.pos(text)[('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]  2. 오탈자 때문에 불완전한 문장text2 = \"ㄱㅐㄴㅏ리가 피어있는 동산에 누워있고싶ㄷㅏ\"# 꼬꼬마 형태소 결과 출력하기.print(\"코모란 : %s\\n\" % komoran.pos(text2))print(\"한나눔 : %s\\n\" % hannanum.pos(text2))print(\"mecab : %s\\n\" % mecab.pos(text2))print(\"Okt : %s\\n\" % okt.pos(text2))코모란 : [('개나리', 'NNP'), ('가', 'JKS'), ('피', 'VV'), ('어', 'EC'), ('있', 'VX'), ('는', 'ETM'), ('동산', 'NNP'), ('에', 'JKB'), ('눕', 'VV'), ('어', 'EC'), ('있', 'VX'), ('고', 'EC'), ('싶', 'VX'), ('다', 'EC')]한나눔 : [('ㄱㅐㄴㅏ리', 'N'), ('가', 'J'), ('피', 'P'), ('어', 'E'), ('있', 'P'), ('는', 'E'), ('동산', 'N'), ('에', 'J'), ('누워있고싶ㄷㅏ', 'N')]mecab : [('ㄱ', 'NNG'), ('ㅐㄴㅏ리가', 'UNKNOWN'), ('피', 'VV'), ('어', 'EC'), ('있', 'VX'), ('는', 'ETM'), ('동산', 'NNG'), ('에', 'JKB'), ('누워', 'VV+EC'), ('있', 'VX'), ('고', 'EC'), ('싶', 'VX'), ('ㄷ', 'NNG'), ('ㅏ', 'UNKNOWN')]Okt : [('ㄱㅐㄴㅏ', 'KoreanParticle'), ('리가', 'Noun'), ('피어있는', 'Verb'), ('동산', 'Noun'), ('에', 'Josa'), ('누워있고싶', 'Verb'), ('ㄷㅏ', 'KoreanParticle')]  3. 속도 비교text3 = \"\"\"5G 이동통신망을 빌려 사용하는 ‘5G 알뜰폰’이 올해 도입되고, 내년부터는 의무화된다.정부는 알뜰폰 사업자(MNVO)가 통신사(MNO)에 통신망을 빌리는 비용(도매대가)을 지난해보다 큰 폭으로 낮춰, 알뜰폰 요금 인하를 유도하기로 했다. 하지만 줄어드는 알뜰폰 시장을 살릴 수 있을지는 지켜봐야 하는 상황이다.과학기술정보통신부는 알뜰폰 활성화 추진대책을 25일 발표했다. 알뜰폰 가입자는 800만명으로 이동통신 시장의 12%를 차지한다. 2011년 출시 뒤 저렴한 요금제로 통신비 부담을 낮춰왔다. 하지만 지난해 5월 통신 3사가 준보편제 요금을 내놓은 이후 알뜰폰 이탈 현상이 지속되고 있다.우선 올해 안에 3개 이상의 5G 알뜰폰이 시장에 나온다. 통신사가 5G망을 알뜰폰 사업자에게 도매 제공할지 여부는 통신사 자율로 정한다. 앞서 LG유플러스는 오는 10월 알뜰폰 사업을 시작하는 KB국민은행에 5G망을 제공한다고 밝힌 바 있다. SK텔레콤와 KT도 특정 제휴사를 선택해 올해 안에 5G 알뜰폰을 내놓기로 했다.내년부터는 5G 알뜰폰 제공이 의무화된다. 지난 22일자로 종료된 도매제공 의무제도의 유효기간을 2022년 9월22일까지 연장하는 전기통신사업법 개정안이 국회에서 통과되면, 관련 고시를 개정해 SK텔레콤의 5G망 도매제공을 의무화하겠다는 것이다.과기정통부 관계자는 “SK텔레콤이 자사와 계약을 맺은 13개 알뜰폰 사업자에게 5G망을 의무 제공하면, 그 외 31개의 알뜰폰 사업자들이 경쟁에서 밀릴 것을 우려해 KT와 LG유플러스도 5G망을 제공하게 될 것”이라고 내다봤다.알뜰폰 사업자가 상품을 만드는 방식 크게 2가지다. 하나는 통신사로부터 음성·문자·데이터를 도매로 사들인 뒤 이를 바탕으로 통신사보다 저렴한 요금제를 내놓는 방식(종량제 도매제공)이다. 이를 위해 정부는 도매대가 인하율을 음성 17.8%, 데이터 19.2%, 단문메시지 1.15%로, 지난해 음성 15.1%, 데이터 19.1%, 단문메시지 1.13%에 비해 높여 잡았다.또 다른 방식은 일정비용을 통신사에 내고 통신사의 정액 요금제를 그대로 판매하면서, 그 차액의 범위에서 저렴한 요금제를 내놓는 방식(수익배분 도매제공)이다. 정부는 SK텔레콤의 준보편 요금제인 ‘T플랜 요금제’를 알뜰폰 사업자가 재판매할 수 있게 했다. 기존에 SK텔레콤이 도매제공했던 ‘밴드데이터 요금제’의 최고구간의 대가도 1.5%포인트 낮췄다.알뜰폰 업계는 대체로 반기는 분위기지만, 알뜰폰 시장을 살릴 수 있을지에는 의구심을 갖고 있다. 업계 관계자는 “도매대가 인하율이 크고, 5G망을 제공하는 것은 긍정적”이라면서도 “수익배분 도매제공의 의무화, 설비를 가진 업체에 대한 접속료 정산 도입 등의 제도적 개선이 필요하다”고 말했다.\"\"\"%%timeprint(kkma.pos(text3)[:5])[('5', 'NR'), ('G', 'OL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO')]Wall time: 19.2 s%%timeprint(komoran.pos(text3)[:5])[('5', 'SN'), ('G', 'SL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO')]Wall time: 132 ms%%timeprint(hannanum.pos(text3)[:5])[('5G', 'N'), ('이동통신망', 'N'), ('을', 'J'), ('빌리', 'P'), ('어', 'E')]Wall time: 1.15 s%%timeprint(mecab.pos(text3)[:5])[('5', 'SN'), ('G', 'SL'), ('이동', 'NNG'), ('통신망', 'NNG'), ('을', 'JKO')]Wall time: 1.17 s%%timeprint(okt.pos(text3)[:5])[('5', 'Number'), ('G', 'Alpha'), ('이', 'Determiner'), ('동', 'Modifier'), ('통신망', 'Noun')]Wall time: 410 ms# 먼저 패키지를 설치하고#  !pip install IPython from IPython.display import Image  # 주피터 노트북에 이미지 삽입Image(\"Performance.png\")  보통의 정확도를 원한다면 “Komoran” 또는 “Hannanum” (이번 분석 중 Komoran의 놀라운 발전에 감짝 놀랐습니다.)속도는 느리더라도 정확하고 상세한 품사 정보를 원한다면 “Kkma”어느 정도의 띄어쓰기 되어 있는 “인터넷” 영화평/상품명을 처리할 땐 “Okt”(만약 띄어쓰기가 없다면 느린 처리속도는 감수해야함)",
        "url": "/newstext-a1"
    }
    ,
    
    "navernews-crawling": {
        "title": "네이버 뉴스 데이터 가져오기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)네이버 뉴스 데이터 가져오기      네이버 오픈 API로 기사 URL 크롤링    bs4 + selenium으로 기사 제목 및 내용 크롤링        https://developers.naver.com/products/service-api/search/search.md오픈 API 이용 신청 클릭하기        https://developers.naver.com/docs/serviceapi/search/blog/blog.md#%EB%B8%94%EB%A1%9C%EA%B7%B8 에서네이버 검색 Open API 예제 (python) 볼수 있음  import osimport sysimport urllib.requestimport requestsclient_id = \"7Rw0IMw6pollWxMoWmep\"client_secret = \"MA_4fslk3O\" # 발급받은 client_secretencText = urllib.parse.quote(\"네이버\")#url에 파이썬 글자 붙여줌url = \"https://openapi.naver.com/v1/search/news?query=\" + encText # json 결과# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과request = urllib.request.Request(url)request.add_header(\"X-Naver-Client-Id\",client_id)request.add_header(\"X-Naver-Client-Secret\",client_secret)response = urllib.request.urlopen(request) #접속 하게끔 해줌rescode = response.getcode() #request를 response 코드로 전달 #200 나오면 정상임if(rescode==200):    response_body = response.read()#     result = requests.get(response.geturl(),#                           headers={\"X-Naver-Client-Id\":client_id,#                                    \"X-Naver-Client-Secret\":client_secret}#                          )#     news_data.append(result.json())    print(response_body.decode('utf-8'))else:    print(\"Error Code:\" + rescode){\"lastBuildDate\": \"Thu, 03 Jun 2021 13:20:51 +0900\",\"total\": 3164334,\"start\": 1,\"display\": 10,\"items\": [{\"title\": \"'알고있지만' 한소희x송강, 설렘 포텐 터지는 케미! 붙어만 있어도 심쿵♥\",\"originallink\": \"http://www.osen.co.kr/article/G1111592396\",\"link\": \"https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589\",\"description\": \"원작 &lt;b&gt;네이버&lt;/b&gt;웹툰 ‘알고있지만’(작가 정서)) 측은 3일, 설렘 포텐을 제대로 터뜨린 포스터 촬영현장 메이킹... 동명의 인기 &lt;b&gt;네이버&lt;/b&gt;웹툰을 원작으로 하는 ‘알고있지만,’은 사랑은 못 믿어도 연애는 하고 싶은 여자... \",\"pubDate\": \"Thu, 03 Jun 2021 13:19:00 +0900\"},{\"title\": \"'잡동산' 승관, '랜덤 홈쇼핑' 준비...어린이 고객 만족도 100%\",\"originallink\": \"http://www.slist.kr/news/articleView.html?idxno=256469\",\"link\": \"http://www.slist.kr/news/articleView.html?idxno=256469\",\"description\": \"사진=채널S '잡동산' 제공 3일 방송되는 채널S '잡동산' 측은 승관이 준비한 '랜덤 홈쇼핑'에서 노련한 진행 실력을 뽐내는 어린이 고객님의 활약을 담은 영상을 &lt;b&gt;네이버&lt;/b&gt;TV 공식 채널을 통해 선공개했다. '잡동산'의 9번째 잡... \",\"pubDate\": \"Thu, 03 Jun 2021 13:18:00 +0900\"},{\"title\": \"일동후디스, 필수 영양소로 채운 '하이뮨 프로틴 밸런스 음료' 출시\",\"originallink\": \"http://www.seoulwire.com/news/articleView.html?idxno=444495\",\"link\": \"http://www.seoulwire.com/news/articleView.html?idxno=444495\",\"description\": \"일동후디스 '하이뮨 프로틴 밸런스 음료'는 일동후디스 건강기능식품 공식 쇼핑몰인 '하이뮨 몰' 및 &lt;b&gt;네이버&lt;/b&gt; 스마트스토어 등으로 만나볼 수 있다. 일동후디스 관계자는 &amp;quot;'하이뮨 프로틴 밸런스 음료'는 기존 하이뮨에... \",\"pubDate\": \"Thu, 03 Jun 2021 13:18:00 +0900\"},{\"title\": \"“상쾌한 민트와 카카오의 시원한 만남” 오리온, 여름 한정판 초코파이하우스...\",\"originallink\": \"http://theviewers.co.kr/View.aspx?No=1658068\",\"link\": \"http://theviewers.co.kr/View.aspx?No=1658068\",\"description\": \"현재 전국의 편의점 냉장 코너를 비롯해 도곡본점, 압구정점 등 초코파이하우스 매장과 이커머스 채널 ‘&lt;b&gt;네이버&lt;/b&gt; 스마트스토어 오리온 직영몰’, ‘쿠팡’, ‘마켓컬리’, ‘헬로네이처’ 등에서 판매 중이다. 오리온... \",\"pubDate\": \"Thu, 03 Jun 2021 13:18:00 +0900\"},{\"title\": \"매일유업, 빨대 없는 멸균우유 ‘매일우유 빨대뺐소’ 출시\",\"originallink\": \"http://www.mdtoday.co.kr/mdtoday/index.html?no=421899\",\"link\": \"http://www.mdtoday.co.kr/mdtoday/index.html?no=421899\",\"description\": \"매일우유 빨대뺐소는 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에서 단독으로 판매한다. 매일유업은 최근 몇 년... 이벤트 기간 동안 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에 제품을 음용하는 모습을 포토리뷰로 등록하면 매일 1명에게... \",\"pubDate\": \"Thu, 03 Jun 2021 13:18:00 +0900\"},{\"title\": \"넷기어, 뮤럴 디지털 액자 대상 프로모션 실시\",\"originallink\": \"https://zdnet.co.kr/view/?no=20210603131528\",\"link\": \"https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=092&amp;aid=0002223965\",\"description\": \"행사 기간 중 &lt;b&gt;네이버&lt;/b&gt; 넷기어스토어를 통해 21.5인치 MC315는 27% 할인한 68만 6천200원에, 27인치 MC327은 15% 할인한 106만 2천500원에 판매한다. 두 제품 모두 전세계 미술관·박물관의 명화 등을 1년간 무제한... \",\"pubDate\": \"Thu, 03 Jun 2021 13:17:00 +0900\"},{\"title\": \"천안시태조산청소년수련관, 모바일 속 가상공간 구축\",\"originallink\": \"http://www.ccdailynews.com/news/articleView.html?idxno=2061275\",\"link\": \"http://www.ccdailynews.com/news/articleView.html?idxno=2061275\",\"description\": \"제페토는 &lt;b&gt;네이버&lt;/b&gt;제트가 운영하는 글로벌 메타버스(현실세계와 3차원 가상세계를 혼합한 공간) 플랫폼으로, 증강 현실(AR) 기술을 활용해 가상현실에서 나만의 아바타로 다양한 사람들과 교류할 수 있다.... \",\"pubDate\": \"Thu, 03 Jun 2021 13:16:00 +0900\"},{\"title\": \"'알고있지만' 한소희X송강, 청춘 케미 제대로..웹툰 찢고 나온 비주얼\",\"originallink\": \"http://biz.heraldcorp.com/view.php?ud=202106031313096524233_1\",\"link\": \"https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=112&amp;aid=0003440732\",\"description\": \"비욘드제이·스튜디오N·JTBC스튜디오/원작 &lt;b&gt;네이버&lt;/b&gt;웹툰 '알고있지만'(작가 정서)) 측은 3일, 설렘 포텐을... 동명의 인기 &lt;b&gt;네이버&lt;/b&gt;웹툰을 원작으로 하는 ‘알고있지만,’은 사랑은 못 믿어도 연애는 하고 싶은 여자 유나비와... \",\"pubDate\": \"Thu, 03 Jun 2021 13:15:00 +0900\"},{\"title\": \"당국, 60세 미만 잔여백신 접종 지침 번복 '혼선'\",\"originallink\": \"http://www.yonhapnewstv.co.kr/MYH20210603011200038/?did=1825m\",\"link\": \"https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=422&amp;aid=0000488191\",\"description\": \"이어 오후 6시 보충 자료에서 기존 예비명단 중 60세 미만은 오늘(3일)까지만 접종이 가능하고, 내일(4일)부터는 &lt;b&gt;네이버&lt;/b&gt;·카카오 앱으로 공개되는 잔여량으로만 예약이 가능하다고 설명했습니다. 이후 오후 10시 다시... \",\"pubDate\": \"Thu, 03 Jun 2021 13:15:00 +0900\"},{\"title\": \"매일유업, 빨대 없는 멸균우유 '매일우유 빨대뺐소' 출시\",\"originallink\": \"http://www.finomy.com/news/articleView.html?idxno=94066\",\"link\": \"http://www.finomy.com/news/articleView.html?idxno=94066\",\"description\": \"매일우유 빨대뺐소는 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에서 단독으로 판매한다. 매일유업은 최근 몇 년 이상기온과 생태계 파괴 등 환경 문제가 사회적으로 대두되자 발빠르게 환경을 고려한 제품을 출시하고 있다. 지난해... \",\"pubDate\": \"Thu, 03 Jun 2021 13:14:00 +0900\"}]}import osimport sysimport urllib.requestimport requestsnews_data = []client_id = \"7Rw0IMw6pollWxMoWmep\"client_secret = \"MA_4fslk3O\" # 발급받은 client_secretencText = urllib.parse.quote(\"네이버\")#url에 파이썬 글자 붙여줌url = \"https://openapi.naver.com/v1/search/news?query=\" + encText # json 결과# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과request = urllib.request.Request(url)request.add_header(\"X-Naver-Client-Id\",client_id)request.add_header(\"X-Naver-Client-Secret\",client_secret)response = urllib.request.urlopen(request) #접속 하게끔 해줌rescode = response.getcode() #request를 response 코드로 전달 #200 나오면 정상임if(rescode==200):#    response_body = response.read()    result = requests.get(response.geturl(),                          headers={\"X-Naver-Client-Id\":client_id,                                   \"X-Naver-Client-Secret\":client_secret}                         )    news_data.append(result.json()) # 키 , 값 형태인 json 형태로 만들기#    print(response_body.decode('utf-8'))else:    print(\"Error Code:\" + rescode)# 먼저 패키지를 설치하고#  !pip install IPython from IPython.display import Image  # 주피터 노트북에 이미지 삽입Image(\"navererror.png\")naver_news_link = []for page in news_data:    #print(page)    page_news_link = []        for item in page['items']:        #print(item)        temp_link = item['link']        #print(temp_link)        if \"naver\" in temp_link:            page_news_link.append(temp_link)        naver_news_link.append(page_news_link)        # 사이트 확인하기에 편한 코드 구조.for page in naver_news_link:    for link in page:        print(link)https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=092&amp;aid=0002223965https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=112&amp;aid=0003440732https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=422&amp;aid=0000488191네이버 OPEN API를 통해 가져온 데이터 확인하기.news_data[{'lastBuildDate': 'Thu, 03 Jun 2021 13:20:51 +0900',  'total': 3164334,  'start': 1,  'display': 10,  'items': [{'title': \"'알고있지만' 한소희x송강, 설렘 포텐 터지는 케미! 붙어만 있어도 심쿵♥\",    'originallink': 'http://www.osen.co.kr/article/G1111592396',    'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589',    'description': '원작 &lt;b&gt;네이버&lt;/b&gt;웹툰 ‘알고있지만’(작가 정서)) 측은 3일, 설렘 포텐을 제대로 터뜨린 포스터 촬영현장 메이킹... 동명의 인기 &lt;b&gt;네이버&lt;/b&gt;웹툰을 원작으로 하는 ‘알고있지만,’은 사랑은 못 믿어도 연애는 하고 싶은 여자... ',    'pubDate': 'Thu, 03 Jun 2021 13:19:00 +0900'},   {'title': '“상쾌한 민트와 카카오의 시원한 만남” 오리온, 여름 한정판 초코파이하우스...',    'originallink': 'http://theviewers.co.kr/View.aspx?No=1658068',    'link': 'http://theviewers.co.kr/View.aspx?No=1658068',    'description': '현재 전국의 편의점 냉장 코너를 비롯해 도곡본점, 압구정점 등 초코파이하우스 매장과 이커머스 채널 ‘&lt;b&gt;네이버&lt;/b&gt; 스마트스토어 오리온 직영몰’, ‘쿠팡’, ‘마켓컬리’, ‘헬로네이처’ 등에서 판매 중이다. 오리온... ',    'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},   {'title': \"일동후디스, 필수 영양소로 채운 '하이뮨 프로틴 밸런스 음료' 출시\",    'originallink': 'http://www.seoulwire.com/news/articleView.html?idxno=444495',    'link': 'http://www.seoulwire.com/news/articleView.html?idxno=444495',    'description': \"일동후디스 '하이뮨 프로틴 밸런스 음료'는\\xa0일동후디스 건강기능식품 공식 쇼핑몰인 '하이뮨 몰' 및 &lt;b&gt;네이버&lt;/b&gt; 스마트스토어 등으로\\xa0만나볼 수 있다. 일동후디스 관계자는 &amp;quot;'하이뮨 프로틴 밸런스 음료'는 기존 하이뮨에... \",    'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},   {'title': \"'잡동산' 승관, '랜덤 홈쇼핑' 준비...어린이 고객 만족도 100%\",    'originallink': 'http://www.slist.kr/news/articleView.html?idxno=256469',    'link': 'http://www.slist.kr/news/articleView.html?idxno=256469',    'description': \"사진=채널S '잡동산' 제공 3일 방송되는 채널S '잡동산' 측은 승관이 준비한 '랜덤 홈쇼핑'에서 노련한 진행 실력을 뽐내는 어린이 고객님의 활약을 담은 영상을 &lt;b&gt;네이버&lt;/b&gt;TV 공식 채널을 통해 선공개했다. '잡동산'의 9번째 잡... \",    'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},   {'title': '매일유업, 빨대 없는 멸균우유 ‘매일우유 빨대뺐소’ 출시',    'originallink': 'http://www.mdtoday.co.kr/mdtoday/index.html?no=421899',    'link': 'http://www.mdtoday.co.kr/mdtoday/index.html?no=421899',    'description': '매일우유 빨대뺐소는 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에서 단독으로 판매한다. 매일유업은 최근 몇 년... 이벤트 기간 동안 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에 제품을 음용하는 모습을 포토리뷰로 등록하면 매일 1명에게... ',    'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},   {'title': '넷기어, 뮤럴 디지털 액자 대상 프로모션 실시',    'originallink': 'https://zdnet.co.kr/view/?no=20210603131528',    'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=092&amp;aid=0002223965',    'description': '행사 기간 중 &lt;b&gt;네이버&lt;/b&gt; 넷기어스토어를 통해 21.5인치 MC315는 27% 할인한 68만 6천200원에, 27인치 MC327은 15% 할인한 106만 2천500원에 판매한다. 두 제품 모두 전세계 미술관·박물관의 명화 등을 1년간 무제한... ',    'pubDate': 'Thu, 03 Jun 2021 13:17:00 +0900'},   {'title': '천안시태조산청소년수련관, 모바일 속 가상공간 구축',    'originallink': 'http://www.ccdailynews.com/news/articleView.html?idxno=2061275',    'link': 'http://www.ccdailynews.com/news/articleView.html?idxno=2061275',    'description': '제페토는 &lt;b&gt;네이버&lt;/b&gt;제트가 운영하는 글로벌 메타버스(현실세계와 3차원 가상세계를 혼합한 공간) 플랫폼으로, 증강 현실(AR) 기술을 활용해 가상현실에서 나만의 아바타로 다양한 사람들과 교류할 수 있다.... ',    'pubDate': 'Thu, 03 Jun 2021 13:16:00 +0900'},   {'title': \"'알고있지만' 한소희X송강, 청춘 케미 제대로..웹툰 찢고 나온 비주얼\",    'originallink': 'http://biz.heraldcorp.com/view.php?ud=202106031313096524233_1',    'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=112&amp;aid=0003440732',    'description': \"비욘드제이·스튜디오N·JTBC스튜디오/원작 &lt;b&gt;네이버&lt;/b&gt;웹툰 '알고있지만'(작가 정서)) 측은 3일, 설렘 포텐을... 동명의 인기 &lt;b&gt;네이버&lt;/b&gt;웹툰을 원작으로 하는 ‘알고있지만,’은 사랑은 못 믿어도 연애는 하고 싶은 여자 유나비와... \",    'pubDate': 'Thu, 03 Jun 2021 13:15:00 +0900'},   {'title': \"당국, 60세 미만 잔여백신 접종 지침 번복 '혼선'\",    'originallink': 'http://www.yonhapnewstv.co.kr/MYH20210603011200038/?did=1825m',    'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=422&amp;aid=0000488191',    'description': '이어 오후 6시 보충 자료에서 기존 예비명단 중 60세 미만은 오늘(3일)까지만 접종이 가능하고, 내일(4일)부터는 &lt;b&gt;네이버&lt;/b&gt;·카카오 앱으로 공개되는 잔여량으로만 예약이 가능하다고 설명했습니다. 이후 오후 10시 다시... ',    'pubDate': 'Thu, 03 Jun 2021 13:15:00 +0900'},   {'title': \"매일유업, 빨대 없는 멸균우유 '매일우유 빨대뺐소' 출시\",    'originallink': 'http://www.finomy.com/news/articleView.html?idxno=94066',    'link': 'http://www.finomy.com/news/articleView.html?idxno=94066',    'description': '매일우유 빨대뺐소는 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에서 단독으로 판매한다. 매일유업은 최근 몇 년 이상기온과 생태계 파괴 등 환경 문제가 사회적으로 대두되자 발빠르게 환경을 고려한 제품을 출시하고 있다. 지난해... ',    'pubDate': 'Thu, 03 Jun 2021 13:14:00 +0900'}]}]news_data[0]{'lastBuildDate': 'Thu, 03 Jun 2021 13:20:51 +0900', 'total': 3164334, 'start': 1, 'display': 10, 'items': [{'title': \"'알고있지만' 한소희x송강, 설렘 포텐 터지는 케미! 붙어만 있어도 심쿵♥\",   'originallink': 'http://www.osen.co.kr/article/G1111592396',   'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589',   'description': '원작 &lt;b&gt;네이버&lt;/b&gt;웹툰 ‘알고있지만’(작가 정서)) 측은 3일, 설렘 포텐을 제대로 터뜨린 포스터 촬영현장 메이킹... 동명의 인기 &lt;b&gt;네이버&lt;/b&gt;웹툰을 원작으로 하는 ‘알고있지만,’은 사랑은 못 믿어도 연애는 하고 싶은 여자... ',   'pubDate': 'Thu, 03 Jun 2021 13:19:00 +0900'},  {'title': '“상쾌한 민트와 카카오의 시원한 만남” 오리온, 여름 한정판 초코파이하우스...',   'originallink': 'http://theviewers.co.kr/View.aspx?No=1658068',   'link': 'http://theviewers.co.kr/View.aspx?No=1658068',   'description': '현재 전국의 편의점 냉장 코너를 비롯해 도곡본점, 압구정점 등 초코파이하우스 매장과 이커머스 채널 ‘&lt;b&gt;네이버&lt;/b&gt; 스마트스토어 오리온 직영몰’, ‘쿠팡’, ‘마켓컬리’, ‘헬로네이처’ 등에서 판매 중이다. 오리온... ',   'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},  {'title': \"일동후디스, 필수 영양소로 채운 '하이뮨 프로틴 밸런스 음료' 출시\",   'originallink': 'http://www.seoulwire.com/news/articleView.html?idxno=444495',   'link': 'http://www.seoulwire.com/news/articleView.html?idxno=444495',   'description': \"일동후디스 '하이뮨 프로틴 밸런스 음료'는\\xa0일동후디스 건강기능식품 공식 쇼핑몰인 '하이뮨 몰' 및 &lt;b&gt;네이버&lt;/b&gt; 스마트스토어 등으로\\xa0만나볼 수 있다. 일동후디스 관계자는 &amp;quot;'하이뮨 프로틴 밸런스 음료'는 기존 하이뮨에... \",   'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},  {'title': \"'잡동산' 승관, '랜덤 홈쇼핑' 준비...어린이 고객 만족도 100%\",   'originallink': 'http://www.slist.kr/news/articleView.html?idxno=256469',   'link': 'http://www.slist.kr/news/articleView.html?idxno=256469',   'description': \"사진=채널S '잡동산' 제공 3일 방송되는 채널S '잡동산' 측은 승관이 준비한 '랜덤 홈쇼핑'에서 노련한 진행 실력을 뽐내는 어린이 고객님의 활약을 담은 영상을 &lt;b&gt;네이버&lt;/b&gt;TV 공식 채널을 통해 선공개했다. '잡동산'의 9번째 잡... \",   'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},  {'title': '매일유업, 빨대 없는 멸균우유 ‘매일우유 빨대뺐소’ 출시',   'originallink': 'http://www.mdtoday.co.kr/mdtoday/index.html?no=421899',   'link': 'http://www.mdtoday.co.kr/mdtoday/index.html?no=421899',   'description': '매일우유 빨대뺐소는 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에서 단독으로 판매한다. 매일유업은 최근 몇 년... 이벤트 기간 동안 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에 제품을 음용하는 모습을 포토리뷰로 등록하면 매일 1명에게... ',   'pubDate': 'Thu, 03 Jun 2021 13:18:00 +0900'},  {'title': '넷기어, 뮤럴 디지털 액자 대상 프로모션 실시',   'originallink': 'https://zdnet.co.kr/view/?no=20210603131528',   'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=092&amp;aid=0002223965',   'description': '행사 기간 중 &lt;b&gt;네이버&lt;/b&gt; 넷기어스토어를 통해 21.5인치 MC315는 27% 할인한 68만 6천200원에, 27인치 MC327은 15% 할인한 106만 2천500원에 판매한다. 두 제품 모두 전세계 미술관·박물관의 명화 등을 1년간 무제한... ',   'pubDate': 'Thu, 03 Jun 2021 13:17:00 +0900'},  {'title': '천안시태조산청소년수련관, 모바일 속 가상공간 구축',   'originallink': 'http://www.ccdailynews.com/news/articleView.html?idxno=2061275',   'link': 'http://www.ccdailynews.com/news/articleView.html?idxno=2061275',   'description': '제페토는 &lt;b&gt;네이버&lt;/b&gt;제트가 운영하는 글로벌 메타버스(현실세계와 3차원 가상세계를 혼합한 공간) 플랫폼으로, 증강 현실(AR) 기술을 활용해 가상현실에서 나만의 아바타로 다양한 사람들과 교류할 수 있다.... ',   'pubDate': 'Thu, 03 Jun 2021 13:16:00 +0900'},  {'title': \"'알고있지만' 한소희X송강, 청춘 케미 제대로..웹툰 찢고 나온 비주얼\",   'originallink': 'http://biz.heraldcorp.com/view.php?ud=202106031313096524233_1',   'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=112&amp;aid=0003440732',   'description': \"비욘드제이·스튜디오N·JTBC스튜디오/원작 &lt;b&gt;네이버&lt;/b&gt;웹툰 '알고있지만'(작가 정서)) 측은 3일, 설렘 포텐을... 동명의 인기 &lt;b&gt;네이버&lt;/b&gt;웹툰을 원작으로 하는 ‘알고있지만,’은 사랑은 못 믿어도 연애는 하고 싶은 여자 유나비와... \",   'pubDate': 'Thu, 03 Jun 2021 13:15:00 +0900'},  {'title': \"당국, 60세 미만 잔여백신 접종 지침 번복 '혼선'\",   'originallink': 'http://www.yonhapnewstv.co.kr/MYH20210603011200038/?did=1825m',   'link': 'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=422&amp;aid=0000488191',   'description': '이어 오후 6시 보충 자료에서 기존 예비명단 중 60세 미만은 오늘(3일)까지만 접종이 가능하고, 내일(4일)부터는 &lt;b&gt;네이버&lt;/b&gt;·카카오 앱으로 공개되는 잔여량으로만 예약이 가능하다고 설명했습니다. 이후 오후 10시 다시... ',   'pubDate': 'Thu, 03 Jun 2021 13:15:00 +0900'},  {'title': \"매일유업, 빨대 없는 멸균우유 '매일우유 빨대뺐소' 출시\",   'originallink': 'http://www.finomy.com/news/articleView.html?idxno=94066',   'link': 'http://www.finomy.com/news/articleView.html?idxno=94066',   'description': '매일우유 빨대뺐소는 매일유업 &lt;b&gt;네이버&lt;/b&gt; 브랜드스토어에서 단독으로 판매한다. 매일유업은 최근 몇 년 이상기온과 생태계 파괴 등 환경 문제가 사회적으로 대두되자 발빠르게 환경을 고려한 제품을 출시하고 있다. 지난해... ',   'pubDate': 'Thu, 03 Jun 2021 13:14:00 +0900'}]}가져온 URL이 네이버 뉴스인지 확인하기.news_data[0]['items'][0]['link'] #첫번째 link 가져온다'https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589'print(news_data[0]['items'][0]['link']) #네이버 뉴스 확인했음https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589page_news_link = []for item in news_data[0]['items']:    link = item['link']    if \"naver\" in link: #naver 뉴스만 가져오기        page_news_link.append(link)        len(page_news_link)4네이버 뉴스 기사 크롤링! (여러 페이지 가져오기)import osimport sysimport urllib.requestimport requestsnews_data = []page_count = 3client_id = \"7Rw0IMw6pollWxMoWmep\"client_secret = \"MA_4fslk3O\" # 발급받은 client_secretencText = urllib.parse.quote(\"암호화폐\")#url에 파이썬 글자 붙여줌for idx in range(page_count):    url = \"https://openapi.naver.com/v1/search/news?query=\" + encText + \"&amp;start=\" + str(idx * 10 + 1)# json 결과    # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과    request = urllib.request.Request(url)    request.add_header(\"X-Naver-Client-Id\",client_id)    request.add_header(\"X-Naver-Client-Secret\",client_secret)    response = urllib.request.urlopen(request) #접속 하게끔 해줌    rescode = response.getcode() #request를 response 코드로 전달     #200 나오면 정상임    if(rescode==200):    #    response_body = response.read()        result = requests.get(response.geturl(),                              headers={\"X-Naver-Client-Id\":client_id,                                       \"X-Naver-Client-Secret\":client_secret}                             )        news_data.append(result.json()) # 키 , 값 형태인 json 형태로 만들기    #    print(response_body.decode('utf-8'))    else:        print(\"Error Code:\" + rescode)print(len(news_data))3naver_news_link = []for page in news_data:    naver_news_link = []    for item in page['items']:        link = item['link']        if \"naver\" in link:            page_news_link.append(link)    naver_news_link.append(page_news_link)    print(len(naver_news_link))1import pandas as pdimport numpy as npfrom selenium import webdriverfrom selenium.webdriver.common.alert import Alertfrom tqdm import tqdm_notebook #파이썬 진행표시바 표시하기: tqdm#  tqdm 설치# 시작 → Anaconda prompt → 마우스 우클릭 → 관리자권한으로 실행  을 눌러주시고. # conda install tqdm 으로 설치하시거나, # 콘다가 설치되어있지 않으시면 pip install tqdm 으로 하시면 됩니다.import requestsimport pickle #텍스트 상태의 데이터가 아닌 파이썬 객체 자체를 파일로 저장하는 것import reimport ast  from bs4 import BeautifulSoup from urllib.request import urlopenimport urllibimport time# 가상 크롬드라이버를 불러옴.# 윈도우 10의 경우 chromedriver.exe    #If you are using Chrome version 91, please download ChromeDriver 91.0.4472.19driver = webdriver.Chrome(\"driver/chromedriver\") #91버전 으로 chromedriver 사용하기Image(\"chromeversion.png\")#! conda install -c conda-forge tqdmnaver_news_title = []naver_news_content = []# tqdm_notebookfor n in tqdm_notebook(range(len(naver_news_link))):    #print(n)    news_page_title = []    news_page_content = []        for idx in tqdm_notebook(range(len(naver_news_link[n]))):                    ########### 긁어온 URL로 접속하기 ############            try:            driver.get(naver_news_link[n][idx])            print(naver_news_link[n][idx])                    except:            print(\"Timeout!\")            continue                        try:            response = driver.page_source                    #except UnexpectedAlertPresentExcepion:             except:            #driver.switch_to_alert().accept()            print(\"게시글이 삭제된 경우입니다.\")            continue                soup = BeautifulSoup(response, \"html.parser\")         # 1. BeautifulSoup가 필요한 이유# request.text를 이용해 가져온 데이터는 텍스트형태의 html 입니다.# 텍스트형태의 데이터에서 어떻게 원하는 html 요소에 접근할 수 있을까요?# 이를 쉽게 할 수 있게 도와주는 녀석이 바로 \"뷰티풀수프\"입니다!! (이름이 특이하죠)# 즉, 날 것의 html을 의미있는 객체로 만들어서 사용자가 요리하기 쉽게 만드는 겁니다.                        ###### 뉴스 타이틀 긁어오기 ######                title = None                try:            item = soup.find('div', class_=\"article_info\")            title = item.find('h3', class_=\"tts_head\").get_text()            #print(title)        except:            title = \"OUTLINK\"                #print(title)        news_page_title.append(title)                        ###### 뉴스 본문 긁어오기 ######                doc = None        text = \"\"                        data = soup.find_all(\"div\", {\"class\" : \"_article_body_contents\"})        if data: #data가 가져왔으면            for item in data:                text = text + str(item.find_all(text=True)).strip() # 공백제거  / 인자로 전달된 문자를 String의 왼쪽과 오른쪽에서 제거한다                text = ast.literal_eval(text) # literal_eval   =&gt; AST(Abstract Syntax Trees) module 에서 제공하는 함수 / AST 모듈은 문법을 구조화 시켜주는 모듈 이다             #  기본 type 정도만 변환해주는 용도로 사용 가능 / text 으로 변환 해준다                doc = ' '.join(text) # 리스트로 저장해줌           else:            doc = \"OUTLINK\"                      news_page_content.append(doc.replace('\\n', ' '))   #replace () 함수는 첫 번째 인자를 두 번째 인자로 대체한다 .                    naver_news_title.append(news_page_title)    naver_news_content.append(news_page_content)    time.sleep(2)         print(naver_news_title[0])print(\"==================================\")print(naver_news_content[0])&lt;ipython-input-17-6c4fa407f4e2&gt;:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`  for n in tqdm_notebook(range(len(naver_news_link))):  0%|          | 0/1 [00:00&lt;?, ?it/s]&lt;ipython-input-17-6c4fa407f4e2&gt;:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`  for idx in tqdm_notebook(range(len(naver_news_link[n]))):  0%|          | 0/18 [00:00&lt;?, ?it/s]https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=109&amp;aid=0004417589https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=092&amp;aid=0002223965https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=106&amp;oid=112&amp;aid=0003440732https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=422&amp;aid=0000488191https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=053&amp;aid=0000029126https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=009&amp;aid=0004803600https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=003&amp;aid=0010531901https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=008&amp;aid=0004596652https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=003&amp;aid=0010531815https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=003&amp;aid=0010531770https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=003&amp;aid=0010531761https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=031&amp;aid=0000602265https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=025&amp;aid=0003106796https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=018&amp;aid=0004946424https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=105&amp;oid=018&amp;aid=0004946419https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=104&amp;oid=016&amp;aid=0001843723https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=100&amp;oid=008&amp;aid=0004596619https://news.naver.com/main/read.nhn?mode=LSD&amp;mid=sec&amp;sid1=101&amp;oid=025&amp;aid=0003106788['OUTLINK', '넷기어, 뮤럴 디지털 액자 대상 프로모션 실시', 'OUTLINK', \"당국, 60세 미만 잔여백신 접종 지침 번복 '혼선'\", '중국의 ‘코인 죽이기’는 디지털 위안화 살리기', '매일 오르는 코인은 있어도 한주간 오른 코인은 없는 이유', '비트코인 급락에 금값은 반등…올들어 최고', 'SNT(Super-Net-Tech), 암호화폐 온라인쇼핑 플랫폼 LUS와 사업 MOU', '금융위, 암호화폐 논의 본격화…거래소 20곳 대면회의', \"'5억 이상 해외 계좌 신고' 시작…숨기면 과태료 '폭탄'\", \"'고팍스' 운영사 스트리미, 코로나19 백신 휴가 시행\", '가상자산 거래소 플라이빗, 자금세탁방지 실무 교육 실시', '상장ㆍ암호화폐 카드 출시…코인베이스 훈풍에 도지코인 급등', '금융위, 가상자산거래소와 첫 간담회…컨설팅 제공', \"포블게이트, 가상자산 담보 대출 서비스 '넥스핀 2.0' 오픈\", '中 가상자산 채굴 전면 퇴출?...지방정부도 압박', '\"이준석 봤지?\"…\\'신선한 반란\\'은 시작됐다', \"車업계 반격에 뒤뚱거리는 '테슬라'…'소형차'로 위기 돌파?\"]==================================['OUTLINK', \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    구매 후기 작성시 와이파이6 유무선공유기·증폭기 증정 (지디넷코리아=권봉석  기자) 넷기어 뮤럴 캔버스. (사진=넷기어) 넷기어가 오는 23일까지 뮤럴 디지털 액자를 최대 27% 할인판매한다. 대상 제품은 27인치 풀HD 디스플레이를 탑재한 'MC327', 21.5인치 풀HD 디스플레이를 탑재한 'MC315' 등 2종이다. 행사 기간 중 네이버 넷기어스토어를 통해 21.5인치 MC315는 27% 할인한 68만 6천200원에, 27인치 MC327은 15% 할인한 106만 2천500원에 판매한다. 두 제품 모두 전세계 미술관·박물관의 명화 등을 1년간 무제한 감상할 수 있는 뮤럴 멤버십 1년권을 기본 제공한다. 구매 후기를 남길 경우 MC327은 와이파이6 유무선 공유기 'RAX20'이나 와이파이6 증폭기 'EAX20'을 추가로 증정한다. MC315는 뮤럴 멤버십 1년권이나 와이파이5(802.11ac) 증폭기 'EX7700'을 받을 수 있다. 권봉석 기자(bskwon@zdnet.co.kr)   ▶ 지디넷코리아 '홈페이지'   ▶ 네이버 채널 구독하기 © 메가뉴스 &amp; ZDNET, A RED VENTURES COMPANY, 무단전재-재배포 금지 \\t  // 본문 내용   \", 'OUTLINK', '   본문 내용     TV플레이어      동영상 뉴스        // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t방역 당국이 코로나 19  잔여 백신 접종 지침을 하루 새 2차례 번복하면서 혼선이 빚어졌습니다. 코로나 19  예방접종대응추진단은 어제(2일) 오후 2시  10 분 보도자료를 통해 위탁의료기관 접종은 내일(4일)부터  60 세 이상만을 대상으로 한다고 발표했습니다. 이어 오후 6시 보충 자료에서 기존 예비명단 중  60 세 미만은 오늘(3일)까지만 접종이 가능하고, 내일(4일)부터는 네이버·카카오 앱으로 공개되는 잔여량으로만 예약이 가능하다고 설명했습니다. 이후 오후  10 시 다시 자료를 내고 기존 예비명단자는 9일까지 유예기간을 두고 접종이 가능하다고 지침을 또 바꿨습니다. 연합뉴스 TV  기사문의 및 제보 : 카톡/라인  jebo23  ▶ 네이버에서 연합뉴스TV를 구독하세요  ▶ 연합뉴스TV 생방송 만나보기   ▶ 균형있는 뉴스, 연합뉴스TV 앱 다운받기    // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    photo  셔터스톡 지난 5월  19 일, 암호화폐는 벼랑 끝으로 내몰렸다. 보통  2017 년의 불장을 ‘시즌 1’ , 올해의 불장을 ‘시즌 2’ 라고 부르는데, “시즌2의 종말이 시작됐다”며 투자자들은 아우성쳤다. 이날 1비트코인( btc )은 4만 3000 달러에서 3만달러까지 폭락했다. 1시간 사이에  15 % 이상 급락하기도 했다. 알트코인들은 더 큰 폭락을 겪으며 사람들의 패닉셀을 끌어냈다. 알트코인 중에서는  30 % 이상 폭락한 코인을 쉽게 찾아볼 수 있었다.      암호화폐 시장이 어느 정도 조정을 겪을 것이라는 건 예측 가능한 일이었다. 가격이 너무 올랐고, 금융당국 등에서 경고가 쏟아졌으며, 일론 머스크 테슬라  CEO 처럼 이 바닥의 인플루언서들이 부정적인 메시지를 쏟아냈다. 하지만 이 정도의 급락은 예측하지 못했던 일이었다.      폭락의 원인은 중국발 규제였다. 지난 5월  19 일 중국 당국은 ‘암호화폐 서비스 금지 명령’을 하달했다. 중국 국가인터넷금융협회, 중국은행협회, 중국결제청산협회 등 3개 단체는 금융 및 결제 서비스를 제공하는 업체들에 가상자산 서비스를 중단할 것을 촉구하는 성명을 냈다. “암호화폐? 中 안정 추구에 방해”      중국에서의 정책 영향력은 발언자를 살펴봐야 한다. 누구의 입에 의해 천명됐는지가 중요하다. 지난 5월  21 일 류허 중국 국무원 부총리는 “비트코인의 거래와 채굴 행위가 금융시스템 전반을 위협한다”며 3개 단체 성명의 내용을 재확인했다. 시진핑(習近平) 국가주석의 경제 브레인으로 통하는 류 부총리가 직접 못을 박고 나섰다는 점에서 이번 규제는 꽤 무겁게 느껴진다.      여전히 일각에서는 중국의 규제를 양치기 소년처럼 보는 시선이 있다. 과거 규제 속에서도 여전히 투자가 이뤄져 왔기 때문이다. 중국 당국은  2013 년과  2017 년에도 강력한 규제를 실행한 바 있다. 그 때문에 바이낸스( Binance ) 등 중국의 대규모 거래소들은 케이맨제도 등에 본사를 세워 역외에서 영업을 해야 했고, 중국의 법정화폐인 위안화로 암호화폐를 사는 길은 막혔다. 그런다고 규제가 개인의 암호화폐 소유까지 막은 건 아니었다. 중국인들은 규제를 피해 알음알음 암호화폐를 거래했다.      지난 2월 말  6500 만원을 찍던 비트코인이  5000 만원 초반대로 추락했다가 급반등으로 가격이 회복되는 일이 있었다. 중국인들의 매수세가 빠른 회복의 원동력이었다. 중국 투자자들은 알리페이나 위챗페이로 브로커와  p2p  장외거래를 통해 테더( USDT )를 사고 이 테더를 거래소에 입금해 비트코인을 구매한다. 테더는 달러화와 연동되는 스테이블 코인으로 1테더는 1달러의 가치를 갖는다. 지난 2월 반등했을 때, 위안화로 표시된 테더 가격에는  1~2 %의 프리미엄이 붙었는데 그만큼 수요가 많았다는 뜻이다.      반대로 이번 조치가 예사롭지 않다는 징후는 규제 직후 바로 나타났다. 일단 개인 시장이 일순간 침묵했다. 류허 부총리가 말한 거래의 금지는 그동안 묵인했던 테더를 활용한 개인의 거래다. 중국 사정을 잘 아는 암호화폐 관계자는 “이번 금지조치가 내려진 뒤 테더를 거래하는 대형 브로커들이 일시적으로 확 줄어들었다”고 말했다. 중국 당국의 조치가 내려진 직후 위안화로 매겨진 테더의 가격도 폭락했는데 현금화하느라 매도가 쏟아졌을 거라는 추측이 나왔다.      팬데믹 이후 커져가는 사회불안을 잠재우기 위해 중국은 지금 경제의 방향을 성장보다 안정에 맞추고 있다. 이사벨라 베버 매사추세츠대 교수는 “지금 중국의 금융구조는 안정에 힘을 실은 상태다. 암호화폐 거품이 꺼질 경우 생길 수 있는 경제적 충격을 막기 위해 중국 정부가 규제를 재차 언급하고 나선 것도 크게 놀랄 일은 아니다”라고 말했다. 경제가 국가의 지배 아래서 시장화된 중국에서 정부의 통제를 벗어난 자본은 쉽게 용납될 수 없다. 그런 점에서 암호화폐는 특별관리대상이다. 엄포와 방관 대신 관리와 통제의 시기가 왔다는 게 베버 교수의 지적이다.      자본 유출에 대한 위험도 마찬가지다. 중국 정부는 암호화폐가 자본 유출의 수단이 될 수 있다고 믿는다. 이런 경계심은 자본 통제의 욕망이 강한 중국 정부가 코인 시장을 죽일 수 있는 근거이기도 했다. 중국인이 법적으로 해외로 반출할 수 있는 외화는 1인당 5만달러지만 테더를 구입해 전송한다면 정부의 상한선은 무의미하다. 블록체인 분석업체 체이널리시스( Chainalysis )의 지난해 8월 보고서에 따르면, 이전 1년 동안  180 억달러 이상의 테더가 동아시아의 지갑에서 해외로 전송됐다. 보고서는 “해당 국가 투자자들이 해외 자본 이전 제한 규정을 피하기 위해 테더를 활용하고 있을지 모른다”고 지적했다. “비트코인 싹 잘라라”   사우스차이나모닝포스트는  “중국이 암호화폐 규제에 나선 건  디지털위안화와 암호화폐를  분명하게 구별하기 위해서” 라고 보도했다.  여기서 구별이란 제도권 내  유일한 디지털화폐는  인민은행이 발행하는  디지털위안화뿐이란 걸 뜻한다.    중앙은행이 직접 암호화폐를 발행하고 경쟁상대를 퇴출시킬 수 있다는 건 코인 시장의 가장 큰 리스크이다. 골드만삭스 출신으로 가상자산 유동성 제공업체인  B2C2 재팬을 이끌고 있는 필립 길레스피  CEO 가 “디지털위안화는 암호화폐 시장의 가장 큰 리스크가 될 것”이라고 말하는 이유다.      중국이 새로운 규제를 천명한 시점은 디지털위안화 등장이 임박한 때와 맞물린다.  2014 년부터 중앙은행 디지털화폐( CBDC ) 연구를 시작한 중국 인민은행은 내년 초 중국 대륙에 디지털위안화를 보급할 계획을 갖고 있다. 이미 디지털위안화는 실물과 동등한 권한을 갖도록 법적 정비까지 마친 상태다. 지난해  10 월 남부 대도시인 선전에서 실제 사용 테스트를 끝냈고 최근에는 홍콩에서 역외를 넘나드는 실험도 실시했다. 다른 두 도시 간의 연계 실험도 마무리됐고 지금은 태국, 아랍에미리트( UAE ) 등과 해외 결제를 실현하기 위한 플랫폼을 개발 중이다.      사우스차이나모닝포스트( SCMP )는 “중국이 암호화폐 규제에 나선 건 디지털위안화와 암호화폐를 분명하게 구별하기 위해서”라고 보도했다. 여기서 구별이란 제도권 내 유일한 디지털화폐는 인민은행이 발행하는 디지털위안화뿐이란 걸 뜻한다.      보리스 슐로스버그  BK 에셋 디렉터는 “디지털위안화는 모든 통화를 추적할 수 있다는 점에서 정부에 엄청난 통제력을 준다. 중국 정책 입안자들은 이제 모든 소비자의 선택을 알 수 있게 되고 소비 행태에까지 직접적인 영향을 줄 수 있다”고 말했다. 하지만 중앙은행이 발행하는 디지털화폐는 필연적으로 프라이버시 침해 논란을 몰고 온다. 내 계좌와 사용기록 등을 정부가 파악할 수 있다는 우려로  CBDC 에 대한 거부감도 크다. 이런 상황에서 암호화폐 시장이 커지는 건 새로 안착해야 할  CBDC 에 큰 장애물이다. 중국 내 첫 번째 디지털화폐는 비트코인이 아니라 디지털위안화가 돼야 한다는 것은 중국 정부 입장에서 체제 유지의 문제나 다름없고, 그러기 위해서 경쟁자의 싹을 자를 필요가 있었다는 게 이번 규제의 배경 중 하나다.      문제는 이후다. 류 부총리의 발언이 각 성에 하달되고 구체적인 지침과 단속으로 가시화할 때까지는 시간이 걸린다. 그 이후 나타나는 사회적 양상에 따라 암호화폐 시장은 또 한 번 충격을 받을 수 있다. 둥시먀오(董希淼) 푸단대 금융연구소 겸임연구원은 “(중국 정부가) 향후 비트코인 등 암호화폐의 불법 거래 행위를 타격하는 조치를 내놓을 것”이라고 예상했다. 유동성에 문제가 생길지 모를 또 한 번의 충격이 있을 수 있다는 얘기다. 김회권 기자  khg @ chosun.com ▶네이버 메인에서 [주간조선] 구독하기  ▶주간조선 홈페이지에서 더 많은 기사 보기 -  Copyrights  ⓒ 조선뉴스프레스 - 주간조선, 무단 전재 및 재배포 금지 - \\t  // 본문 내용   ', \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    - 비트코인 일주일째 같은 가격.. 곧 방향성 결정날 것 - 바닥권 코인 단기 상승 후 조정 반복되는 시장 - 지금은 단기 혹은 관망으로 대응 필요 *디브리핑은 매일경제, 블록크래프터스, 고위드와 함께하는 디스트리트에서 제공하는 암호화폐 시황입니다. 안녕하세요. 2021 년 6월 3일 오후  12 시, 디브리핑의 문호준입니다. 지난 하루 동안의 암호화폐 주요 시황 살펴보겠습니다. [비트코인]   △비트코인 차트, 출처: 업비트 비트코인은 일주일 가까이 4, 350 만 원 부근에서 횡보를 이어가고 있습니다. 비트코인 도미넌스(시가총액 점유율)는  41.5 %로 지난 5월  24 일 고점을 찍은 뒤 계속 하락하고 있으며, 김치프리미엄(해외보다 높게 형성된 가격)은 4%대로 해외보다 더 많이 하락할 리스크는 많이 없어졌습니다. [주요 코인]   △시가총액  TOP   100  코인, 출처:  Coinmarketcap 시가총액  TOP   100  코인을 보면 전일 엠덱스( MDX ,  -2.92 %)를 비롯한 6개 코인을 제외하고는 모두 상승했습니다. 그 중 거래소 코인인 오케이비( OKB , + 27 %)가 가장 크게 올랐으며, 도지코인( DOGE , + 15 %), 아이오타( IOTA , + 16 %), 아이콘( ICX , + 12 %) 등도 강세를 보였습니다.   △아이오타( IOTA ) 차트, 출처: 업비트 비트코인이 횡보하자 상대적으로 덜 오른 코인들이 짧게 반등하는 순환 패턴이 이어지는 모습입니다.   △최근 1주일 상승률 상위 코인, 출처: 업비트 최근 1주일동안 상승률이 가장 높았던 코인만 보더라도 얼마나 빠르게 순환매가 돌고 있는지 알 수 있습니다. 데일리로 보면 크게 오르는 코인들이 있지만 1주일 기준으로는 크게 오른 코인이 없다는 것은, 단기적으로 오른 코인이 다시 하락하는 순환이 돌고 있기 때문입니다. [총정리] 비트코인은 조만간 횡보를 깨고 반등이나 하락으로 방향을 잡을 것입니다. 반등에 이어 상승장으로 전환할 경우에는 ‘달리는 말에 올라타(오르는 코인을 매수)’는 것이 가능하지만, 지금처럼 횡보하거나, 반등하거나, 하락할 경우에는 바닥권 코인에 대한 단기 투자나 관망이 시장에 대한 가장 합리적인 대응법이라 생각됩니다. 이것으로  2021 년 6월 3일 디브리핑을 마치겠습니다. 감사합니다. [문호준 암호화폐 애널리스트]  r_start //  r_end // ▶ '경제 1위' 매일경제, 네이버에서 구독하세요 ▶ 매경이 전하는 지식레터 '매콤달콤' 받아보세요 ▶ 매경이 알려주는 '취업비법' 한달간 무료 [ⓒ 매일경제 &amp;  mk.co.kr , 무단전재 및 재배포 금지] \\t  // 본문 내용   \", '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    1900 달러 선 재돌파…연초 수준 회복 지난달  26 일 6만 8430 원, 올해 최고치 \"비트코인 급락에 안전자산 선호현상\" \"중장기적으론 박스권에서 움직일 듯\" [서울=뉴시스]홍효식 기자 = 비트코인 등 암호화폐가 반토막 수준으로 급락하는 반면 금값이 올들어 최고치를 기록하고 있는 가운데  30 일 서울 종로구 한국금거래소 종로본점에 골드바가 진열돼 있다. 한국거래소에 따르면  30 일 오전  10 시 기준  1g 당 금 시세는 6만 7750 원을 기록하고 있다.  2021.05.30.   yesphoto @ newsis.com  [서울=뉴시스] 이승주 기자 = 올초 하락세를 이어가던 금값이 반등하더니 최근 올들어 최고치를 기록했다. 비트코인 등 암호화폐 시세가 절반 가까이 급락하자 안전자산으로 분류되는 금으로 투자수요가 돌아서는 것으로 분석된다. 3일 한국거래소에 따르면 전일 국제 금 시세는 종가 기준 온스 당  1916.08 달러를 기록했다. 전일( 1903.63 달러) 대비  0.65 % 오른 수치다.  금 시세는 지난해 역대 최고치를 기록하더니 올들어 하락세가 계속됐다. 특히 지난 1월8일  1907.42 달러를 기록한 뒤  1900 선을 밑돌더니 심지어  1600 달러 대까지 떨어졌다. 하지만 지난달부터 반등세를 이어가면서  1900 선을 재돌파했다. g당으로는 지난 2일 금 시세는 6만 8130 원을 기록했다. 이는 전일(6만 7990 원) 대비  0.21 % 상승한 수치다. 이는 올초 수준을 회복한 것은 물론 지난 1월4일(6만 6910 원)을 상회하는 수치다. 특히 지난달  26 일에는 6만 8430 원까지 올랐는데 이는 올들어 최고치다. 금값은 지난해 8월 역대 최고치인 7만 8440 원까지 올랐다. 전 세계적으로 코로나 19  사태가 진정될 기미가 보이지 않자 투자자들이 안전한 피난처로 여겨지는 금으로 몰려든 것으로 분석된다. 현물 금 가격은 지난해 들어서 8월까지  30 % 넘게 급등했는데, 이는  1979 년 이후 가장 많이 오른 것이다. 당시 투자업계에서는 이같은 상승세가 올해 상반기까지 계속될 것이란 전망이 우세했다. 하지만 금값은 이후 점차 하락해 올초 3월 31 일 기준 6만 1400 원까지 떨어졌다. 이는 올들어 최저치다.  그랬던 금값이 지난달부터 다시 반등하더니 올들어 최고치를 기록한 셈이다. 이에 대해 전규연 하나금융투자 연구원은 \"지지부진하던 금 가격이 4월 이후 반등하더니 5월부터 추세적 상승을 시도하고 있다\"며 \"안정적인 금리 흐름과 달러 약세가 금 가격 상승을 지지하고 있다\"고 분석했다. [서울=뉴시스] 고승민 기자 = 미국 코인베이스의 자사 전문투자자 거래소 \\'코인베이스 프로\\'에 상장된다는 소식에 도지코인이 상승세를 보인 3일 서울 빗썸 강남고객센터 모니터에 암호화폐 시세가 표시돼 있다.  2021.06.03.   kkssmm99 @ newsis.com 투자업계는 이 같은 반등세를 암호화폐 급락에 따른 안전자산 선호 강화로도 풀이했다.  올들어 급등했던 암호화폐는 검은수요일이라 불리는 지난  19 일 이후 하락세다. 대표적인 암호화폐 비트코인은 지난달  14 일 역대 최고치( 8148 만 7000 원)까지 올랐지만 미국 전기자동차 기업 테슬라의 비트코인 결제 중단 소식에 이어 중국과 미국의 규제 움직임 등에 한달여 만에 반토막 수준까지 하락한 셈이다. 게다가 테슬라의 최고경영자( CEO ) 일론 머스크의 일관성 잃은 발언으로 변동성이 커지더니 한때  3000 만원대까지 떨어지면서 투자자들의 원성이 고조됐다.  암호화폐거래소 빗썸에 따르면 이날 오전 8시 19 분 기준 비트코인 가격은  4370 만 2000 원에 거래됐다. 비트코인은 6월들어  4200 만 ~4400 만원대에서 등락을 거듭하고 있다. 역대 최고치의 절반 수준을 조금 웃도는 수준이다. 업비트에선  4372 만 4000 원에 거래 중이다.  나중혁 하나금융투자 연구원은 \"인플레이션에 대한 효율적인 헤지수단으로 인식되면서 지난해 4분기부터 비트코인 신탁으로 자금 유입이 빠르게 전개됐다\"면서 \"이달들어 비트코인 신탁의 자금이 급격히 줄어드는 가운데 금 상품으로는 자금 유입이 늘어났다. 최근 비트코인으로 옮겨갔던 인플레이션 헤지용 금 투자 수요가 돌아오는 것\"이라고 분석했다. 나 연구원은 \"암호화폐 변동성이 확대될수록 금 투자가 확대될 개연성이 높지만 올해 하반기 미 연준의 스탠스 전환을 고려하면 전고점 경신 가능성은 낮다\"며 \"금은 인플레이션 헤지와 안전자산 수요가 늘어나면서 단기적으로 상승한 뒤 중장기적으로 온스 당  1600~1950 달러 박스권 내에서 움직일 것 같다\"고 전망했다. ☞공감언론 뉴시스   joo47 @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t[머니투데이 중기&amp;창업팀 허남이 기자]  SNT ( Super-Net-Technology )는 명품 아울렛인 암호화폐 온라인쇼핑 플랫폼  LUS 와 전략적 사업 협약 ( MOU )을 체결했다.  사진제공= SNT   SNT 는 이번 협약이  LUS 와의 핀 테크 기반 결제 플랫폼에 대한 새로운 전략적 계약으로 간주된다고 말했다. 두 회사의 전략적 계약에는 비즈니스 및 결제 기술에 대한 협력을 수행하는 블록체인의 상호 운용성 향상에 동의하는 것으로 포함된다. 두 회사는 암호화폐 자산 결제 등 다양한 분야에서 블록체인 노하우를 공유하고 협업을 통한 시너지 효과를 기대한다고 전했다. 또한 이번 계약을 통해  SNT 와  LUS 는 기존  LUS  인프라를 기반으로 온라인 브랜드 비즈니스 협력 시스템을 공동 구축할 예정이며, 거기에서 동남아 브랜드 블록체인 시장을 연결하는 시장을 구축할 것이라고 말했다. SNT 는  SNT  지갑과 같은 현재 암호화폐 시장의 핫키를 결합한 몇 안되는 플랫폼 중 하나이기 때문에  DEFI ;  P2P , 쇼핑몰이 시장의 주목을 받고 있다. SNT   LAB 은  Juda   Mall  및  Fintech  결제 시스템과  2021  년 7월 오픈 예정인 블록체인 결제 프로젝트를 결합하기 위한 계약을 체결했으며,  LUS 은 계속해서 자체 사업 영역을 확장하고 있다. 거기에서 사람들이 토큰으로 서비스 비용을 지불할 수 있는 서비스도 제공된다. 그리고 오는 6월  13 일에  SNT 는 글로벌 거래소  SPexchange 에  IEO 로 상장이 된다. SNT   LAB  재단 이현호 대표는 \" LUS  쇼핑과의 협력을 통해 많은 사용자에게 블록체인 기반 결제 서비스를 제공할 수 있게 되었다\"며 \"다양한 기술을 도입하여 사용자에게 더 많은 편의와 혜택을 제공할 것이다\"고 말했다. 또한  LUS  관계자는 \"파트너십을 통해 끊임없이 확장되는 블록체인 기술을 통해 아울렛 시장에 대해 더욱 밝은 미래와 시장을 선보이게 됐다\"고 전했다.  article_split 중기&amp;창업팀 허남이 기자  nyheoo @ ▶부동산 투자는 [부릿지] ▶주식 투자는 [부꾸미TALK] ▶부자되는 뉴스, 머니투데이 구독하기   &lt;저작권자 ⓒ \\'돈이 보이는 리얼타임 뉴스\\' 머니투데이, 무단전재 및 재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    금융위 주무부처 결정 이후 첫 회의 금융위 \"신고 관련 사항 등 논의 예정\" [서울=뉴시스] 박민석 기자 = 금융위원회(뉴시스 DB )  2020.04.23.  *재판매 및  DB  금지 [서울=뉴시스] 최현호 기자 = 금융위원회(금융위)가 국내 암호화폐 거래소들과의 대면회의를 진행한다. 금융위가 암호화폐 주무부처로 지정된 뒤 첫 회의다. 3일 금융위에 따르면 금융정보분석원( FIU )은 이날 오후 4시 은행연합회에서 암호화폐 거래소  20 곳 관계자들과 간담회를 가진다. 이번 간담회는 지난달 금융위가 암호화폐와 관련 사업체 관리 감독 주무부처로 결정된 후 첫 회의다. 이날 간담회는 비공개로 진행된다. 간담회에선 가상자산 사업자 주의사항, 취급금지 가산자산 규정 추진 방향 등을 논의하는 것으로 전해졌다. 금융위 관계자는 \"지난 정부 발표 대책 내용과 신고 관련 사항 정도(를 논의할 예정)\"이라고 말했다. 간담회는 금융위가 주무부처로 결정된 뒤 가상자산사업자들의 납세, 시행령 개정방향 등 관련 문의가 몰리자 긴급히 결정된 것으로 알려졌다. 금융위는 추후 다른 가상자산사업자 등과도 회의를 진행할 예정이다. 다만 금융위 관계자는 \"아직은 구체적인 계획이 없다\"고 밝혔다. ☞공감언론 뉴시스   wrcmania @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    국세청, 잔액 5억 이상 해외 계좌 신고 안내 매월 말일 중 어느 하루라도 초과 시 알려야 이달 말까지 신고 않으면 최대  20 % 과태료 지난  10 년간  1475 억 과태료 ·63 명 형사 고발 [홍콩= AP/ 뉴시스] 홍콩의 홍콩상하이은행( HSBC ) 건물 앞 모습. 이 사진은 기사 내용과 직접적 관련 없음 [세종=뉴시스] 김진욱 기자 = 해외 금융 계좌 신고 기간이 다가왔다. 해외 계좌 잔액 합계가 \\'매월 말일 중 어느 하루\\'라도 5억원을 초과했다면 이달 말까지 반드시 신고해야 한다. 이를 숨겼다가는 미·과소 신고 금액의  20 %를 과태료로 내야 한다. 지난  10 년간 총  1475 억원의 과태료가 부과됐다. 숨긴 금액이  50 억원을 넘으면 형사 처벌도 받을 수 있다. 국세청은 3일 이런 내용의 해외 계좌 신고 의무를 안내했다. 신고 의무자는 거주자(국내에 주소를 뒀거나,  183 일 이상 거소를 둔 개인)·내국 법인이다. 지난해 보유한 해외 계좌 중 거래가 없거나, 같은 해 해지했더라도 기준을 충족한다면 신고해야 한다. 신고 대상에는 예·적금뿐만 아니라 주식(주식예탁증서( DR ) 포함)·채권·펀드·파생상품·보험상품 등이 모두 포함된다. 잔액은 계좌에 보유한 각 자산을 평가하고, 그 금액을 해당 표시 통화의 환율로 바꾼 뒤 자산별 금액을 모두 더해 산출한다. 만약 피상속인 명의의 해외 계좌를 여러 명이 공동으로 상속받았다면 상속인 각자의 상속분만큼만 환산해 더한다. 본인 명의가 아닌 차명 계좌의 경우 명의자(거주자)와 실소유자 모두에게 신고 의무가 있다. 공동명의 계좌라면 명의자 각각 신고해야 한다. 이때 명의자-실소유자, 각 공동명의자는 계좌 잔액 전부를 각자 보유한 것으로 간주하므로 신고 기준 계산에 유의해야 한다. 암호화폐 계좌의 경우 오는  2022 년 1월1일 이후 신고 의무가 생기는 잔액부터 대상에 포함한다. 최초 신고 시기는  2023 년 6월이다. 대상자는 홈택스(\\'신고·납부→일반 신고→해외 금융 계좌 신고\\' 경로)에서 간편하게 전자 신고할 수 있다. 올해부터는 모바일 애플리케이션 손택스로도 신고할 수 있다. 국세청은 코로나 19  예방을 위해 홈택스·손택스 등을 이용한 비대면 신고를 권장했다. 신고 대상 연도 종료일  10 년( 2011 년 1월1일 ~2020 년  12 월 31 일) 전부터 국내에 주소·거소를 둔 기간 합계가 5년 이하인 외국인 거주자, 신고 대상 연도 종료일 1년( 2020 년 1월1일 ~12 월 31 일) 전부터 국내에 거소를 둔 기간 합계가  183 일 이하인 재외국민 등은 신고 의무가 면제된다. 국세청은 이번 신고 기간 이후 외국 과세 당국과의 정보 교환 자료 등을 정밀 분석해 미·과소 신고자 검증에 나설 계획이다. 기간 내 이를 신고하지 않거나, 줄여 신고한 경우 해당 금액의  10~20 %를 과태료로 내야 한다. 미·과소 신고 금액이  20 억원 이하라면 그  10 %를,  20 억 ~50 억원이라면  \\'2 억원+ 20 억원 초과액 ×15 %\\'를,  50 억원 초과라면  \\'6 억 5000 만원+ 50 억원 초과액 ×20 %\\'를 문다. 상한액은  20 억원이다. 미·과소 신고 금액이  50 억원 초과 시 형사 처벌을 받거나, 인적 사항 등이 공개될 수 있다. 국세청은 지난  10 년간 총  63 명을 형사 고발하고, 7명의 명단을 공개한 바 있다. 또 신고 의무 위반자는 자금 출처 소명을 요구받을 수 있다. 미(거짓)소명 시 해당 금액의  20 %만큼 추가 과태료를 물어야 한다. 국세청은 최대  20 억원 규모의 해외 계좌 미신고 포상금제도 운영하고 있다. 과태료 또는 벌금 납부액이  2000 만원 ~2 억원이면 그  15 %를, 2억 ~5 억원이면  \\'3000 만원+2억원 초과액 ×10 %\\'를, 5억원 초과 시  \\'6000 만원+5억원 초과액 ×5 %\\'를 과태료로 준다. 국세청은 \"해외 계좌 신고 의무자에게 최대한의 신고 편의를 제공하고, 신고자 및 그 내용에 관해서는 관련 법률에 따라 비밀을 철저히 유지하겠다\"면서 \"신고 의무자는 자진 신고가 최선의 선택이라는 생각으로 성실하게 신고해 달라\"고 했다. ☞공감언론 뉴시스   str8fwd @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    . *재판매 및  DB  금지 [서울=뉴시스] 유자비 기자 = 암호화폐 거래소 고팍스를 운영하는 스트리미는 임직원의 안전과 코로나 19  백신 접종 독려를 위해 코로나 19  백신을 접종하는 모든 임직원에게 유급 휴가를 제공한다고 3일 밝혔다. 백신유급 휴가 대상자는  1991 년  12 월 31 일 이전 출생자 중 사전접종 예약이 없거나 접종 이력이 없는 모든 임직원에게 적용된다.  백신 휴가제도 시행에 따라 스트리미 임직원들은 백신 접종 당일 유급 휴가가 제공되며 이상 징후 발생시 유급 휴가 1일이 추가 제공된다.\\u2028 스트리미 관계자는 \"임직원의 건강과 안전을 지키는 것이 최우선 원칙\"이라며 \"백신 휴가제도 시행으로 백신 접종률을 높이고 코로나 19  극복에 기여해 일상의 정상화가 하루 빨리 오기를 기대한다\"고 말했다. 한편 스트리미는 지난해 코로나 19  발생 초기부터 전직원 재택근무를 시행하고, 재택근무 기간 중 업무상 불가피하게 출근하는 임직원에게는 교통비를 지급해 왔다. \\u2028 ☞공감언론 뉴시스   jabiu @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    총 3차례 걸쳐  AML  제도 교육 가상자산 거래소 플라이빗 임직원들이 자금세탁방지( AML ) 실무 교육을 받고 있다.  [사진=한국디지털거래소] [아이뉴스 24  허재영 기자] 가상자산(암호화폐) 거래소 플라이빗의 운영사 한국디지털거래소가 전체 임직원을 대상으로 자금세탁방지 업무 전문성을 강화하기 위해 자금세탁방지( AML )에 대한 실무 교육을 실시했다고 3일 밝혔다. 플라이빗은 자금세탁방지 제도를 정확하게 이해함과 동시에 실무 역량 강화를 제고하기 위한 목적으로 총 세 차례에 걸쳐 교육을 진행했다. 이는 가상자산 사업자( VASP )로서 특정금융정보법에 따라  AML  의무를 철저히 준수하기 위한 것이라는 설명이다. 이번 교육 내용은 ▲  AML  제도 개요 ▲ 가상자산 관련 법령 개정 내용 ▲ 자금세탁방지제도 검사감독방향 및 관련 법률 위반 사례 ▲ 자금세탁방지 제도 실무적용 및 관련 고객 응대 방안 등에 대한 주제로 구성됐다. 앞서 플라이빗은 임직원들의 준법의식 및 업무수행 능력을 향상하기 위해 지난 2월  AML  내부통제를 위한 임직원 교육을 실시한 바 있다. 플라이빗 관계자는 \"자금세탁방지 교육을 정기적으로 실시하는 것은 물론 선진화된 자금세탁방지 제도 교육 체계를 수립함으로써 업무를 수행하는 데 필요한 역량과 전문성을 강화시킬 방침\"이라고 말했다. /허재영 기자( huropa@inews24.com) ▶네이버 채널에서 \\'아이뉴스24\\'를 구독해주세요. ▶재밌는 아이뉴스TV 영상보기   ▶아이뉴스24 바로가기 [ⓒ 아이뉴스 24  무단전재 및 재배포 금지]    // 본문 내용   ', \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}        코인베이스 전용 카드 출시와 도지코인 상장 소식에 암호화폐 가격이 들썩이고 있다.                미국 최대 암호화폐 거래소인 코인베이스발 호재로 암호화폐 가격이 들썩이고 있다. 코인베이스가 암호화폐 전용 카드(직불카드) 출시와 함께 도지코인 거래를 허용한다는 소식이 전해지면서다. 코인베이스 입성에 도지코인 몸값은 눈에 띄게 급등했다. 3일 오전  11 시 20 분 현재 코인마켓캡에서 도지코인은  41.4 센트에 거래되고 있다. 오전 7시 한때는 몸값이  43 센트를 넘기기도 했다.  24 시간 전보다  24 % 폭등한 가격이다.       코인베이스가 도지코인의 거래를 허용하면서, 도지코인 가격이  20 % 이상 급등했다.          CNBC  등 외신에 따르면 코인베이스는 3일부터 전문 중개인용 자산거래 플랫폼 ‘코인베이스 프로’에서 도지코인을 거래할 수 있게 한다고 지난 1일(현지시각) 발표했다. 그동안 '장난으로 만든' 도지코인의 거래를 허용하지 않던 코인베이스가 방침을 바꿔 거래를 허용한 것이다.         코인베이스 카드 출시 소식도 암호화폐 시장에는 호재다. 지난 1일 코인베이스에 따르면 코인베이스 카드 이용자들은 애플페이와 구글페이를 통해 결제할 수 있게 됐다. 암호화폐구입도 한층 쉬워질 전망이다. 또 카드 이용자는 비트코인 등 암호화폐 잔액으로 매장에서 물품을 구입하거나 현금인출기( ATM )에서 돈을 인출할 수 있다. 코인베이스는 이번 카드 출시를 기념해 결제 시마다 비트코인 1%씩, 스텔라 4%씩 돌려주는 리워드(보상)도 제공할 계획이다.          코인베이스발 호재로 도지코인을 제외한 주요 암호화폐 가격도 오름세다. 현재( 11 시  20 분) 암호화폐 대장주인 비트코인은 코인마켓캡에서  3733 달러에 거래되고 있다.  24 시간 전보다 3% 가까이 올랐다. 같은 시간 이더리움은  24 시간 전보다  3.1 %, 카르다노는  2.06 % 각각 상승하고 있다.          염지현 기자  yjh @ joongang.co.kr     ▶  그가 들려주는 이야기, 이상언의 '더 모닝' ▶  건강한 주식 맛집, 앤츠랩이 차린 메뉴 ▶  '실검'이 사라졌다, 이슈는 어디서 봐? ⓒ중앙일보( https : / / joongang.co.kr ), 무단 전재 및 재배포 금지 \\t  // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    거래소  20 곳 참여할 듯 [이데일리 이승현 기자] 금융위원회가 가상자산(암호화폐) 사업자 관리 및 감독 주무부처로 지정된 이후 처음으로 가상자산거래소들과 만난다. 3일 금융권에 따르면 금융위 산하 금융정보분석원( FIU )은 이날 오후 4시 서울 중구 은행연합회관에서 ‘가상자산거래소 신고등록 안내 컨설팅(가칭)’ 비공개 간담회를 개최한다. 이 자리에는 정보보호 관리체계( ISMS ) 인증을 얻은 국내 가상자산거래소  20 곳이 참석하는 것으로 알려졌다. 이날 간담회에서  FIU 는 가상자산사업자 관리를 위한 정부 입장을 설명하고 향후 제도개선 방향을 안내할 것으로 전망된다. 앞서 지난달  28 일 정부는 ‘가상자산 거래 관리방안’을 발표하며 가상자산거래소의 조속한 신고를 위해 필요한 보완사항에 대한 컨설팅을 제공하겠다는 계획을 밝혔다. 간담회에선 가상자산 사업자 신고요건과 함께 사업자 취급금지 가상자산 규정, 사업자 시세조종 금지 등에 대한 내용이 논의될 전망이다. 가상자산사업자 신고요건은  ISMS  인증 획득, 실명확인 입출금 계정 개설, 대표·임원이 특정금융정보법·범죄수익은닉규제법·금융관련법령 등 위반 없음 등이다.  금융위는 가상자산사업자 등이 자체 발행한 가상자산에 대해 매매와 교환을 중개 및 알선하는 행위를 금지하고, 사업자의 시세조종행위를 금지하는 방안을 추진하고 있다.  금융위는 특정금융정보법에 따라 가상자산사업자에 대해 신고유예 기한인 9월 말까지 조속한 신고를 유도하고 컨설팅을 제공할 예정이다. 이후에는 신고한 사업자의 관리와 감독에 초점을 맞추기로 했다. 기존 가상자산사업자는 요건을 갖춰 9월  24 일까지  FIU 에 신고를 마쳐야 한다. 3일 오전 서울 강남구 암호화폐 거래소 업비트 라운지 전광판에 비트코인과 알트코인 시세가 표시되고 있다. (사진=연합뉴스) 이승현 ( leesh @ edaily.co.kr ) ▶ #24시간 빠른 #미리보는 뉴스 #eNews+ ▶ 네이버에서 '이데일리 뉴스'를 만나보세요 ▶ 빡침해소, 청춘뉘우스 '스냅타임' ＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지＞    // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    비트코인 등 담보로 원화 대출가상자산 가격 하락 대비 위험 관리 지원 6월말까지 출시 기념 무이자 이벤트 (사진=포블게이트) [이데일리 김국배 기자] 국내 암호화폐 거래소 포블게이트는 핀테크 기업 민트플렉스와 가상 자산 담보 대출 서비스 ‘넥스핀  2.0’ 을 제공한다고 3일 밝혔다. 넥스핀  2.0 은 민트플렉스가 선보인 가상자산 담보 원화 대출 서비스로, 전문가들이 설계한 알고리즘을 기반으로 자체 개발한 리스크 관리시스템( RMS )을 제공한다. 이를 통해 안정적인 대출 원금 정산 서비스와 함께 담보 자산 가치 하락에 따른 위험 관리를 지원받을 수 있다는 게 회사 측 설명이다. 회사 측은 “심사를 거쳐 디지털 자산 가격의 최대  50 %까지만 대출을 지원하며, 디지털 자산 가격이 (대출 당시보다)  45 % 하락하는 시점에는 매도를 진행해 위험을 줄이는 방식”이라고 설명했다. 현재 담보로 지정할 수 있는 가상자산은 비트코인으로, 향후 이더리움을 포함한 글로벌  10 위권 내 가상자산으로 대상을 확대할 예정이다. 포블게이트 고객들은 신용등급, 대출한도 상관없이 원화 대출 서비스를 이용할 수 있으며 대출 기간은 1개월 혹은 3개월 중에 선택할 수 있다.  포블게이트는 신규 서비스 오픈을 기념해 오는  30 일까지 무이자 혜택 이벤트를 진행한다. 이 기간 가입한 회원 중 선착순  100 명에게는  5000 원 상당의 비트코인을 증정하며, 1개월 이상 대출 만기 서비스를 이용하는 고객 중  40 명을 추첨해 첫 달 무이자 혜택을 제공한다. 다만, 무이자 혜택은 최대  200 만원 한도 내에서 적용된다.  200 만원 이상 초과 대출분에 대해선 기본 이자율을 적용한다. 김국배 ( vermeer @ edaily.co.kr ) ▶ #24시간 빠른 #미리보는 뉴스 #eNews+ ▶ 네이버에서 '이데일리 뉴스'를 만나보세요 ▶ 빡침해소, 청춘뉘우스 '스냅타임' ＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지＞    // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    쓰촨성, 채굴 현황파악...단속예고 네이멍구, 지난달 채굴 규제안 발표 중국 중앙정부가 가상자산 채굴 금지령을 내린 이후 지방정부도 단속 움직임에 동참하고 있다. 채굴업자의 탈중국 움직임도 본격화하고 있는 가운데, 일각에선 정부의 단속 하에 본토에서 운영되는 벌어지는 가상자산 채굴 현장이 결국에 모두 폐쇄될 수도 있다는 관측도 제기된다. 3일 관영 글로벌타임스에 따르면 전날 쓰촨성 에너지 규제당국은 가상자산 채굴 실태를 조사하는 좌담회를 열었다. 이날 좌담회의 구체적인 내용은 공개되지 않았으나, 쓰촨성 내 가상자산 채굴 현황에 대한 심도있는 보고가 진행된 것으로 알려졌다. 앞서 중국 국가에너지자원국 쓰촨성 지부는 “중앙 차원의 요청에 따라 쓰촨성 내 가상자산 채굴 관련 상황을 충분히 파악하기 위해 좌담회를 열게 됐다”고 밝힌 바 있다. 쓰촨성은 신장위구르자치구와 함께 중국 내에서 가상자산 채굴이 가장 활발하게 이뤄지는 지역으로 꼽힌다. 풍부한 수자원 덕분에 값 싼 전기를 공급받을 수 있기 때문이다. 이날 좌담회는 사실상 쓰촨성 당국이 가상자산 채굴 현황 파악을 시작으로 대대적인 단속에 나설 것임을 예고한 것으로 해석된다. 글로벌타임스는 “중앙 정부가 비트코인 채굴과 단속을 강화하겠다고 선언한 이후 지방자체단체가 관련 노력을 강화하고 있다”면서 “쓰촨성 관리도 채굴업자에 대한 더 많은 조치를 고심하고 있는 것으로 보인다”고 전했다. 지난달  21 일 중국 국무원 금융안정발전위원회는 류허 부총재 주재 회의에서 가상자산 채굴과 거래 행위에 대한 강력한 단속 의지를 밝혔다. 이에 같은 달  25 일 중국 네이멍구자치구는 가상자산 채굴 행위를 전면 금지하는 이른바 ‘암호화폐 채굴 행위 타격을 위한 8대 조치’ 초안을 발표했다. 규제안에는 가상자산 채굴업자 만이 아니라 땅을 빌려주거나 전기를 제공하는 등 해당 행위에 연루된 이들을 모두 처벌하겠다는 내용이 담겼다. 참여 개인과 기업을 ‘신용 불량 명단’에 올리겠다는 내용도 포함됐다. 전문가는 장기적으로는 중국에서 가상자산 채굴 행위 자체가 사라질 수 있다고 추측했다. 중앙 정부가 명시적으로 채굴장을 모두 폐쇄해야 한다고 밝히지는 않았으나, 이미 가상자산 시장에서는 중국 내 채굴 행위에 대한 비관론이 확산되고 있다는 설명이다. 디지털르네상스재단의 상무이자 비트코인 투자자인 카오인은 “많은 채굴업자들이 중국 정부의 강경 입장을 감지하고 캐나다 등 (채굴에) 우호적인 국가로 이전하고 있다”고 밝혔다. 손미정 기자 ▶환경적 대화기구 '헤럴드에코' ▶밀리터리 전문 콘텐츠 ‘헤밀’ ▶헤럴드경제 네이버 채널 구독 -  Copyrights  ⓒ 헤럴드경제 &amp;  heraldbiz.com , 무단 전재 및 재배포 금지 - \\t  // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t[머니투데이 더리더 홍세미 편승민 임윤희 기자] [[심층리포트-청년·초선 돌풍 어디까지]] start_block ━ 심층리포트① 여야, 초선 등 신예 정치인 목소리 커져…대선 향배 가를 수도 ━ end_block 젊은 정치인이 대세로 떠오르던 시절이 있었다. 김영삼 전 대통령( YS )이  1971 년 제7대 대통령 선거에 출마할 때 내건 슬로건은 ‘ 40 대 기수론’이다. 정권교체를 위해  40 대의 젊은 지도자가 필요하다는 것이다. ‘젊은 신민당’ 이미지를 내세운  YS  논리에 가세해 당시  45 세였던 김대중 전 대통령( DJ )과  48 세였던 이철승 전 의원이 대선에 뛰어들었다. 당시 신민당의 총재였던 유진산 전 총재는 이들을 향해 ‘입에서 아직 젖 비린내가 난다’는 의미인 ‘구상유취(口尙乳臭)’라고 비유하며 폄하했다. 2021 년 정치권도 당시와 비슷한 일이 벌어지고 있다. 국민의힘 전당대회에 나선 중진 의원이 신예 정치인을 두고 ‘예쁜 스포츠카’, ‘동네 뒷산’으로 비유했다. 국민의힘 전당대회에 출마한 나경원 후보는 지난달  24 일  CBS  라디오 ‘김현정의 뉴스쇼’에 출연, “이번 당 대표는 사실 멋지고 예쁜 스포츠카를 끌고 갈 수 있는 자리가 아니라 짐을 잔뜩 실은 화물트럭을 끌고 좁은 골목길을 가야 한다”고 말했다. 전당대회에 출마한 김웅 의원(초선·서울 송파갑), 이준석 전 미래통합당(국민의힘 전신) 최고위원, 김은혜 의원(초선·경기 성남분당갑) 등을 ‘예쁜 스포츠카’에 빗댄 것이다. 당대표에 출마하는 주호영 전 원내대표는 지난달  11 일  CBS  라디오 ‘김현정의 뉴스쇼’에서 ‘김웅 의원, 이준석 전 최고위원 등 젊은 초선급의 약진이 눈에 띈다’는 진행자 말에 “동네 뒷산만 다녀선 안 된다”며 “에베레스트를 오를 수 없다”고 했다. 그는 “설악산과 지리산 등 ‘중간 산’도 다닌 사람이 원정대장을 맡아야 한다”고 말했다. ▲국민의힘 이준석 당 대표 후보가 5월  25 일 서울 마포구 누리꿈스퀘어에서 열린 국민의힘 제1차 전당대회 비전스토리텔링 PT 에서 발표를 하고 있다./사진=뉴시스 ◇이준석 당대표 여론조사 1위…“野 쇄신 인물”  vs . “지나가는 바람” 국민의힘 당대표 후보로 나선 중진 의원들이 신예 정치인을 향해 연달아 견제구를 날리는 것은 여론이 이들에게 반응해서다. 우선  4.5  재보궐선거에서  20 대가 국민의힘을 지지한 게 승리의 요인으로 꼽힌다. 지난  4.7  보궐선거 방송 3사 출구조사에 따르면  20 대  55.3 %가 오세훈 국민의힘 후보를 찍었다. 이번 국민의힘 전당대회를 앞두고 이준석 전 최고위원이 당대표 여론조사 1위를 기록했다. 한길리서치가 쿠키뉴스 의뢰로 지난달  22 일 전국  1000 명을 대상으로 실시한 국민의힘 당 대표 지지도 여론조사에서 이 전 최고위원은  30.1 %로  17.4 %를 기록한 나경원 전 의원을  12.7 %p 앞섰다. 뒤를 주호영 의원이  9.3 %, 김웅 의원이  5.0 %, 김은혜 의원이  4.9 %, 홍문표 의원이  3.7 %, 윤영석 의원이  3.3 %, 조경태 의원이  2.8 %를 기록, 한자릿수 지지율을 보였다(포본오차는  95 % 신뢰수준에 ± 3.1 %포인트·자세한 내용은 중앙선거여론조사심의위원회 홈페이지 참조). 서울과학고와 하버드대를 졸업한 이 전 최고위원은 각종 방송 패널로 출연하며 인지도를 높였다.  26 살이던  2011 년 그는 새누리당 최연소 비상대책위원으로 발탁된 ‘박근혜 키즈’였다. 하지만 박 전 대통령을 포함, 당 지도부를 향해 쓴소리를 마다하지 않으면서 주목을 받았다.  2017 년 박 전 대통령 탄핵 사태 직후 새누리당을 탈당해 바른정당-바른미래당-새로운보수당을 거쳤다. 보수 정당의 합리적 보수 포지션으로  10 년 동안 꾸준히 길을 걸어왔다. 또  SNS 를 활용해 주요 정치인이면 피했을 주제인 젠더 이슈, 여성 징병제, 암호화폐 등과 같은 민감한 주제에 대해 가감 없는 의견을 밝혔다. 기성 정치인에 대한 실망, 그리고 쇄신·변화를 바라는 야권 지지자들의 바람이 이 전 최고위원을 향한 기대로 표출되고 있다는 분석이다. 국민의힘이 ‘도로 새누리당’으로 되지 않기 위한 ‘변화의 인물’로 떠올랐다는 것. 그러나  20 대 남성 표심 몰이에 집중하면서 젠더 갈등을 부추기는 ‘노이즈 마케팅’을 활용해 인지도를 높였다는 비판도 있다. 이 전 최고위원은  4·7  재보선 이후 ‘여성할당제 폐지’를 내세우며 남녀 편가르기 논란의 중심에 섰다. 이와 더불어 이 전 최고위원에 대한 당 안팎의 해석은 엇갈린다. 국민의힘 복당을 선언한 홍 의원은 지난달  25 일 자신의  SNS 에 이 전 최고위원을 겨냥, “한때 지나가는 바람”이라며 “안타까운 몸부림으로 국민들이 보고 있다”고 했다.  이어 “대선을 불과  10 개월 앞둔 이 중차대한 시점에 또다시 실험 정당이 될 수는 없다”고 썼다.  이에 대해 하태경 의원은  SNS 를 통해 “홍준표 의원님, 보수의  2030 세대 확장 훼방 놓지 마십시오”라며 “보수에서는 꿈조차 꾸기 어려웠던  2030 세대 확장의 희망을 현실로 만들어낸 후배 정치인에게 박수를 보내도 모자랄 판에, 새로운 지지층을 지나가는 바람이라고 폄하하고 있다”고 지적했다. ▲더불어민주당  21 대 초선의원들이 4월 9일 오후 국회 소통관에서 재보선 결과에 대한 초선의원들의 공동 입장문 발표하고 있다./사진=뉴시스 ◇與 초선, 쇄신안 밝혔지만…문자폭탄으로 위축 민주당에서도 초선 의원들이 모임 ‘더민초’를 만들며 목소리를 내기 시작했다. 민주당 오영환, 이소영, 전용기, 장경태, 장철민 의원 등 초선 5인은  4.7  재보선 참패 직후 ‘조국 사태’ 등 자체 패인 등을 담은 입장을 내놓으면서 당의 쇄신 필요성을 강조했다.  또 문재인 대통령이 임혜숙·박준영·노형욱 장관 후보자에 대한 청문 보고서 재송부 요청을 한 다음 날인 지난달  12 일 ‘더민초’ 소속 의원  40 여 명이 화상 회의를 열고 “장관 후보자 가운데 최소 한 명 이상은 낙마시켜야 한다”고 밝혔다. 청와대도 이내 “무겁게 받아들인다”며 재고에 들어갔고, 박준영 해수부 장관 후보자가 끝내 자진 사퇴했다.  민주당 초선의원들이 모임을 만들고 목소리를 내고 있지만 당의 변화나 돌풍으로 이어질지는 미지수다.  21 대 국회는 어느 때보다 초선이 많다.  300 명 가운데 절반을 넘는  152 명에 이른다. 민주당의  174 명 중 절반에 가까운  81 명이 초선이다. 수는 많지만 존재감이 약하다는 게 중론이다.  특히 초선 5인이 민주당 자성 목소리를 내자 당 강성 지지자들의 ‘문자 폭탄’을 받아 이들의 활동이 더욱 위축될 수 있다는 의견도 나온다. 이들은 당내 주류인 친문 세력을 비판하는 모습으로 확산되자 당내 강성 지지자들로부터 ‘초선5적’, ‘초선족’으로 비판을 받으며 파장을 일으켰다. 이들은 지난달  11 일 다시 성명서를 내고 “ 2030  청년 세대가 느낀 실망감을 기대감으로 바꾸기 위해 저희가 고민하고 노력해야 하듯 민주당은 다양한 세대와 계층의 국민 목소리를 잘 듣고 더 잘 담아내는 정당이 돼야 한다”고 강조했다.  초선 의원들의 목소리를 당 지도부가 귀담아 듣지 않는 것도 문제라고 지적된다. 재보선 후 4차례 전체모임을 갖고 ‘쇄신위 구성’과 ‘성 비위 사건에 대한 진정성 있는 사과’, ‘당내 민주주의 강화’ 등을 요구했지만 당헌·당규 재개정 등 초기 문제제기는 반영되지 않았다. 최창렬 용인대학교 교수는 “초선 5인이 지난 재보궐 이후 내놓은 반성문과 혁신안이 당 지도부에게 바로 제압당했다”며 “그런 쇄신안을 받지 않는다는 것은 민주당은 여전히 자신들의 진영에 갇혀 있다는 것”이라고 말했다.  최 교수는 “국민의힘 당대표 여론조사에서 이준석이 1위한 것은 소위 ‘수구정당’이라고 불렸던 당이 변하고 있다는 상징”이라며 “송영길 당대표가 되고 나서도 부동산 정책이나 특별하게 개혁한다는 인식을 주지 않고 있다. 민주당이 개혁 메시지를 주지 않으면 변할 수 없다”고 했다. ▲송영길 더불어민주당 대표가 5월  25 일 서울 영등포구 무중력지대 영등포에서 열린 국민소통·민심경청 프로젝트 ‘서울·부산 청년과의 간담회’에서 발언하고 있다./사진=뉴시스 ◇초선 활동 ·2030 표심 중요한 이유 그럼에도 이들의 ‘반란’이 여의도 정치권에 적잖은 충격을 주고 있는 것은 사실이다. 초선들은 통상 당의 쇄신·개혁 역할을 맡았다. 계파나 기득권에서 상대적으로 자유로운 초선의원들의 ‘초심’이 당의 변화를 이끄는 동력이 됐다. 민주당의 천·신·정(천정배·신기남·정동영), 한나라당의 남·원·정(남경필·원희룡·정병국)은 대표적인 소장파로 기록된다.  2000 년 천신정은 정풍운동을 주도, 새천년민주당의 기득권이었던 ‘동교동계 원로의 2선 후퇴를 이끌었다. 이들은  2003 년 참여정부 출범과 열린우리당 창당의 주역이다. 한나라당의 남·원·정(남경필·원희룡·정병국)은 소신파로 당 쇄신을 주도,  2004 년 총선을 앞두고 천막당사로 당 승리를 이끌어  2007 년 정권탈환의 기반을 마련했다. 이들이 속한  18 대 국회 한나라당 초선모임인 민본 21 은 이명박정부를 겨냥, 쓴소리와 개혁정책을 쏟아냈다. 이처럼 초선의 쇄신과 개혁 목소리는 향후 정치 판도를 바꿀 수 있다. 특히 현재 정치권의 시곗 바늘은 내년 대선을 향해 있다. 여야의 신예 정치인이  2030 에게 어떤 메시지를 주느냐에 따라 대선 향배가 달라질 수 있다는 목소리도 나온다.  최 교수는 “다음 대선에서는  2030  표심을 잡는 정당이 이길 가능성이 많다”며 “이 세대는 지금 여당이나 야당을 지지한다기보다 중도층인 경우가 더 많다”고 말했다.  이어 “이들은 급격한 변화를 원한다. 이준석이 당대표 1위한 것도 정치권의 변화를 원했기 때문”이라며 “어느 정당이 변화와 개혁 메시지를 먼저 주는지에 따라 민심이 반응 할 것”이라고 밝혔다. 홍세미 기자  semi4094 @ mt.co.kr start_block ━ 초선이 이끄는 선거열차, ‘ 2030’  태워라 ━ end_block [심층리포트②]내년 대선과 지방선거 앞두고 캐스팅보트 쥔  MZ 세대 공략 사활 김종인 국민의힘 비대위원장이 지난해  12 월 6일 오후 서울 영등포구  KNK 디지털타워에서 열린 '청년국민의힘 창당대회'에서 축사를 하고 있다./사진=뉴스1 정치판에 여야를 막론하고 ‘초선 돌풍’이 몰아치고 있다.  21 대 국회의원  300 명 중 초선 의원은 절반이 넘는  151 명( 50.3 %)이다. 더불어민주당은 지난  4.7 재보선 참패 이후  2030 의원들의 반성문에 이어 여당내 초선 모임인 ‘더민초’가 결성됐다. 지난 4월  22 일 더민초는 여당 지도부를 향해 쇄신위원회를 구성하고 근본적이고 지속적인 쇄신안을 마련할 것을 요구했다. 이날 고영인 더민초 운영위원장은 국회 소통관에서 기자회견을 열고 “민심은 언제나 옳다. 저희가 부족했다”며 “국민께서 주신 엄중한 경고, 깊이 새기고 혁신하기 위해 뭉쳤다”고 밝혔다. 더민초는 지속적인 당 쇄신을 위해 △당내 쇄신위원회 구성 △당 지도부의 박원순·오거돈 성폭력 피해자에 대한 진정성 있는 사과 △ 지역위원회별 ‘쓴소리 경청텐트’ 설치와 ‘세대별 심층토론회’를 통한 국민 소통 △ 당이 주도권을 갖는 당정청 관계 △입법·정책 결정에 앞선 의원 간 집단 토론 활성화 등을 요구했다. 지난달 6일 여의도 전국경제인연합회에서 열린 ‘더민초 쓴소리 경청  20 대에 듣는다’ 간담회에서 한  20 대 남성 참석자는 “박근혜 정부 국정농단 사태 당시 정유라 씨 특혜 등에 분노해 촛불집회에 열심히 참석했다”면서 “하지만 윤미향, 조국 사태 등으로  20 대들은 민주당에 엄청나게 실망했다. 코로나 19 가 아니었으면 촛불집회 대상이 민주당이었을 것”이라고 꼬집었다. 또한, 지난달  12 일 더민초는 청와대에 야당이 부적격 판정한 임혜숙 과학기술정보통신부, 박준영 해양수산부, 노형욱 국토교통부 장관 후보자 중 최소한 1명에 대한 부적격 의견을 내야한다고 요구했다. 이후 박준영 후보자는 입장문을 통해 자진사퇴했다. 국민의힘은 차기 당대표를 뽑는 전당대회를 앞두고 있는 가운데 신진세력의 돌풍이 심상치 않다. 지난달  17 일 발표된 국민의힘 차기 당대표 적합도 여론조사에서 이준석 전 미래통합당 최고위원은  20.4 % 지지를 얻으며 선두에 서는 기염을 토했다. 여론조사기관  PNR 이 머니투데이 더 300 과 미래한국연구소 의뢰로 실시한 조사(표본오차  95 % 신뢰수준에 ± 3.1 %포인트)결과, 이 전 최고위원은  20.4 % 지지율을 보였고 그 뒤를 4선의 나경원 전 의원이  15.5 %로 바짝 쫓았다. 이어 5선 주호영 의원( 12.2 %), 초선 김웅 의원( 8.4 %), 4선 홍문표와 5선 조경태 의원이 각각  4.3 %로 뒤를 이었다. 또한 처음 여론조사 대상에 올랐던 초선 김은혜 의원도  3.5 %라는 의미있는 결과를 얻었다. 여론조사의 자세한 내용은 중앙선거여론조사심의위원회 홈페이지를 참고하면 된다. 당초  1970~1980 년대 초선 및 원외 인사들이 출사표를 낼 때만 해도 당 안팎으로 회의적인 시선이 적지 않았다. 이번에 선출되는 당대표는 내년 대선을 이끌어나가야 하는 중차대한 임무를 맡아야 하기 때문이다. 하지만 당의 영파워는 ‘혁신과 쇄신’을 강조하면서 연일 돌풍을 일으키고 있다. 여론조사 지지율 1위에 오른 이 전 최고위원은 한 인터뷰에서 “내년 대선의 최대 승부처는 ‘ 2030 세대’로 대표되는 젊은 유권자가 될 것”이라며 “당 대표가 되면  2030 세대를 껴안을 방안을 적극 모색하겠다”고 말했다. 이처럼 이 전 최고위원은 특히  MZ 세대로부터 굳건한 지지를 확보하면서 상승세에 더욱 박차를 가하고 있다. ◇ MZ 세대 그들은 누구인가 한국전쟁 이후 태어난  1955 년 ~1963 년생은 ‘베이비붐 세대’,  1960 년대에 태어나  1980 년대 대학을 다니며 민주화 투쟁에 앞장선 세대는 ‘ 386  세대’라 불린다. 이후  1990 년대에는 ‘무언가로 정의할 수 없다’는 의미로 ‘X세대’가 청년층을 가리키는 이름이었다.  요즘 청년세대의 이름은 그럼 무엇이냐?  1980 년 ~1994 년 사이에 태어난 ‘밀레니얼 세대’와  1995 년 이후 태어난 ‘Z세대’를 합쳐  MZ 세대라고 부른다. MZ 세대의 가장 큰 특징은 ‘공정’에 민감하다는 것이다. 노력한 만큼 대가를 받고 기존 사회의 차별을 받는 것을 절대 가만히 두고보지 않는 세대다.   MZ 세대는 직장에서도 당당히 자기 몫을 요구하고, 대기업을 혼쭐내는 세대다. 수직적 조직문화에 익숙한 기성세대와 달리 직장에서 당당하게 목소리를 내는 데 주저하지 않는다. 그렇기에 워라밸(일과 삶의 균형)을 무엇보다 중시하고, 공정한 평가 기준을 요구하면서 기업 문화마저 바꿔나가고 있다. 올해 초  MZ 세대는 대기업 성과급 불만을 직장인 익명게시판인 ‘블라인드’에 게시하며 불공정 사회적 이슈로 키웠고, 생산직 위주 노조와 별도로 최초의 사무직 노조를 결성하기에 이르렀다.  31 살의 직원이 노조를 만드는 데는 불과 일주일밖에 걸리지 않았고, 가입 인원은  4000 명까지 늘었다. 이런 움직임은 다른 대기업들까지 확산되면서, 젊은 층을 중심으로 한 노조 설립이 속속 이어지고 있다. 또한, 이들은 디지털 환경에서 성장한 디지털 네이티브기에 오프라인이 아닌 온라인,  SNS 로 뭉친다. 재테크에도 관심이 많아서 카카오페이, 비트코인과 같은 핀테크 서비스에도 익숙하다. 지난해부터 올해까지 코로나 19 로 인해 불거졌던 동학개미운동, 코인광풍의 주축도 바로  MZ  세대다. 이들의 재테크 전략은 부동산시장까지 번지면서 부동산계의 큰손으로까지 떠오르고 있다. ◇ MZ 세대가 선거판을 흔들다 지난  4.7  재보궐 선거에서  MZ 세대의 표심은 여야의 희비를 갈랐다. 그동안 진보여당의 핵심 지지층으로 여겨졌던  MZ 세대는 재보선에서는 완전히 다른 모습을 보인 것이 여당 참패의 원인이었다. 진보와 보수의 이분법적인 사고를 깨고, 현안별로 소신 있는 목소리를 내고 있는  MZ 세대는 높은 투표율을 보이며 지난 서울, 부산 재보궐 선거의 판세를 뒤흔들었다. 지난 선거 당일 방송3사 출구조사 결과에 따르면 서울  20 대 남성 유권자의  72.5 %는 오세훈 국민의힘 당시 후보에게 투표했다.  30 대 남성 역시  63.8 %가 오 후보에 표를 던졌다고 응답해 박영선 더불어민주당 후보( 32.6 %)에 투표했다는 응답의 2배에 육박했다. 반면  20 대 여성에서는 박 후보가  44.0 %로 오 후보( 40.9 %)보다 지지율이 높게 나왔는데 이는 서울시장 보선이 치러지게 됐던 고 박원순 전 서울시장의 성추문을 남성들은 내로남불로, 여성들은 남성 권력 문제로 받아들였던 것으로 분석됐다. 결국 극심한 취업난과 계속되는 집값 급등으로 내 집 마련이 요원해진 상황 속에서 ‘한국토지주택공사( LH ) 사태’, ‘인천국제공항 사태’ 등 공정성 논란이 계속되자 ‘공정’의 가치를 둔  MZ 세대의 분노가 폭발해버렸다. 송영길 더불어민주당 대표가 지난달  17 일 국회에서 성년의날을 맞아  20 대 청년들과 간담회를 갖기에 앞서 기념촬영을 하고 있다./사진-뉴스1 ◇ MZ 세대, 내년 대선서 ‘캐스팅 보트’로 떠올라 여당의 참패, 야당의 압승으로 끝난  4.7  재보궐 선거에서 가장 주목을 받았던  MZ 세대는 이제 내년 대선의 ‘캐스팅 보트’로 주목받기 시작했다. 불과 4년 전  19 대 대통령 선거에서 문재인 당시 더불어민주당 후보를 당선시킨 주역이  MZ 세대였다. 하지만  4.7  재보궐선거에서 이들은 국민의힘의 손을 들어줬다.  MZ 세대가 이슈에 따라 자기 목소리를 낼 뿐, 특정 정당이나 인물을 지지하지 않는다는 사실을 여실히 보여줬다. 두 번의 선거 결과에서 볼 수 있듯이, 이번 재보선에서  MZ 세대가 국민의힘을 선택했다고 해서 다음 대선에서도 국민의힘에 투표할 것이라는 보장은 없다. 이들은 민주당 지지를 철회했던 것이지 국민의힘을 온전히 지지하게 된 것은 아니기 때문이다. 선거 후 한국리서치·코리아리서치·케이스탯·엠브레인 등 여론조사 전문업체 4곳이 함께 실시한 전국지표조사( NBS )에서 국민의힘이 승리한 주된 요인을 묻는 질문에 “민주당이 잘못해서”라는 답변( 61 %)이 가장 높았다(4월  12~14 일 전국 만  18 세 이상 남녀  1010 명 대상, 표본오차  95 % 신뢰수준에 ± 3.1 %포인트). 또 한 가지 흥미로운 여론조사 결과도 있다. 한국갤럽이 지난 4월  13~15 일 전국 만  18 세 이상  1005 명에게 차기 정치지도자 선호도를 물은 결과,  20 대와  30 대는 가장 선호하는 정치지도자로 여권 대선주자인 이재명 경기지사를 꼽았다. 이 지사는  20 대와  30 대에게 각각  15 %,  16 % 지지를 얻으며 여론조사 전체 1위인 윤석열 전 검찰총장의  2030 세대 지지율(7%,  14 %)을 앞섰다. 이 지사의 경우 기본소득 등의 이슈를 선점하면서 청년 층의 지지를 얻고 있으며, 이 지사 특유의 사이다 화법과 강한 행정 추진력도 지지자들을 끌어들이는 요인이 되고 있다. ◇여야 특명,  MZ 세대를 사로잡아라 여야는 내년  3.9 대선과 6월 지방선거를 앞두고  MZ 세대의 마음을 사로잡기 위해 사활을 걸고 나섰다. 통계청에 따르면  MZ 세대는  2019 년 기준  1696 만 명으로 우리나라 전체 인구의  32 %를 차지한다. 보궐 선거가 끝난 후 당을 재정비한 민주당은 성난 부동산 민심을 의식한 듯 “정부가 실시한 부동산 정책이라도 문제가 있다면 과감히 바꾸겠다”고 밝혔다. 민주당은 부동산특별위원회를 설치하고 관련 정책의 전반적인 검토에 착수했다. 민주당은 당 부동산특위에서 논의 중인 청년·신혼부부 부동산 대출규제 완화가 반전카드가 될 것이라고 기대하고 있다. 무주택 청년·신홍부부에 한해 집값의  90 %까지 대출할 수 있도록 하면 부동산 민심이 돌아설 것이라는 계산이다. 송영길 민주당 대표는 “청년·신혼부부의 경우 집값의 6%만 있으면 자기 집을 가질 수 있는 금융구조를 완성했다”고 강조했다. 국민의힘은 차기 당대표를 뽑는 데 있어 초선 당대표론이 급속히 퍼지고 있다. 일각에서는 국민의힘에 지지를 보낸  2030 세대를 붙잡기 위한 전략이라는 분석이 나왔다. 국민의힘 현역 의원  101 명 중 초선의원은  56 명으로 과반이 넘기에 초선 당대표가 전혀 실현 불가능하지 않다. 지지율 1위를 달리고 있는 이준석 전 최고위원은 “이번에 서울시장 보궐선거에서 보여줬듯이 전통적 보수층에 더해  2030 층을 끌어안지 못하면 선거에 이길 수 없다”며 변화를 추구해야 한다고 강조했다. 한편 지난달  20 일 당 대표 출마를 선언한 나경원 국민의힘 의원은 “경륜과 패기를 넘어선 지혜와 정치력, 결단력의 리더십을 요구한다”며 지지를 호소했다. 나 전 의원은 “ MZ 세대의 현안부터 치매 어르신들의 아픔, 세종시 국회 이전부터 가덕도 신공항 문제, 배달 근로자의 안전부터 기업의 경영 자율성 회복까지 다양한 이슈에 대해 스마트한 답을 내놓을 수 있는 유능한 정당으로 거듭나겠다”고 강조했다. 편승민 기자  carriepyun @ mt.co.kr start_division ━ end_division ‘꼰대정치’ 엎고 세대교체 마중물 될까 [심층리포트③]서열 중심 당내 기득권 걸림돌…민심 어루만질 비전 제시해야 2022 년 대선을 앞두고 당 쇄신을 외치며 존재감을 뽐내고 있는 초선들은 세대교체의 마중물이 될 수 있을까? 이종근 시사평론가는  21 대 국회 초선들의 약진에 대해 “억눌려 있다가 손을 놓으면 굉장히 크게 반등하는 스프링 효과”라고 설명했다. 그러면서 “사회에서 중추적인 역할을 하는  40 대가 정치권에서는 유독  86 세대에 눌려 자기 목소리를 내지 못하고 있었다”고 했다. 최창렬 용인대 교수는 “지나친 선수와 서열 위주의 한국정치 틀이 깨져나가는 조짐으로 봐야 한다”며 “과거의 기득권, 낡은 정치에 대한 국민들의 실증에 대한 반영”이라고 말한다. 그러면서 “과거에는 초·재선들이  40 대 기수론을 앞세워 개혁의 목소리를 많이 냈었는데 언제부터인가 지나치게 숨겨져 있었다. 정상화 과정이라고 본다”고 평가했다. 최 교수가 언급했듯 과거에도 정치권에 초ㆍ재선이 전면에 나서 당내 개혁을 이끌었던 사례는 심심치 않게 찾아볼 수 있다.   2000 년 새천년민주당에서는 당시 ‘천·신·정’(천정배 신기남 정동영)을 필두로 한 초재선 그룹이 당의 실세로 불린 권노갑 민주당 최고위원에게 2선 퇴진을 요구했다. 권 최고위원은 당시 보름 만에 사퇴했다. 소위 ‘보스 중심’ 정당문화에서 이 같은 모습은 일대 파장을 일으켰다. 정풍운동은 당시 민주당 내 주류였던 동교동계의 2선 후퇴를 이끌어내 ‘정치 지형 변화’를 만들었다. 이는 노무현 대통령 당선 및 열린우리당 창당으로까지 이어졌다. 진보당에 개혁을 이끈 ‘정풍운동’이 있었다면 보수당에는 ‘남·원·정 트리오’가 있었다.  1997 년 대선에서 패한 한나라당에는 당 쇄신을 주장하는 소장파가 부상했다.  1999 년에는 ‘미래연대’라는 모임이 만들어졌고,  2000 년  16 대 국회에서 재선한 남경필, 정병국, 원희룡은 미래연대에서 의기투합했다. 세 사람은 ‘남·원·정 트리오’로 불리며 보수정당의 쇄신세력을 대표하는 이름이 됐다. 차떼기 사건으로 보수 정당이 위기에 빠지자  17 대 총선 당시 ‘천막당사’를 가장 먼저 쳤던 것도 이들이다. 2002 년 대선에서 재차 패한 뒤에는 개혁의 선봉에 서며 당을 지탱하는 데 중심 역할을 하며  2007 년 정권탈환의 기반을 닦았다. 남·원·정 트리오 역시 ‘내부 총질’이라는 비난도 받았지만 이들의 따끔한 지도부 비판은 내부 정화작용을 했다. ◇정치 세대교체론의 대명사 영국의 토니 블레어 김종인 전 위원장은 지난달 언론과 인터뷰에서 이달 치러지는 국민의힘 전당대회에 당대표로 출마한 김웅 의원과 이준석 전 최고위원을 향해 “영국 같은 데를 보면 노동당의 토니 블레어의 출현이나 보수당의 캐머런의 출현이나 그 사람들이  30 대에 출현한 사람들”이라고 말했다. 김 전 의원장은 “그런 것을 우리도 한번 생각해볼 필요가 있지 않냐”며 초선 당대표론에 힘을 실어주기도 했다. ‘제3의 길’을 내세우며 등장한 영국의 토니 블레어 총리는 정치판의 세대교체를 언급할 때 단골로 거론되는 인물이다. 영국은 당시에  18 년간 보수당이 장기 집권을 하고 있었고 노동당은 극좌로 흐르며 집권과 멀어지고 있었다. 노동당 당수에 오른 토니 블레어는 ‘신노동당’( New   Labour )이라는 브랜딩을 통해 고든 브라운과 함께 영국 노동당의 우클릭을 주도했다.  90 년대 보수당 정권 시절부터 이어진 노후화된 제조업 탈피 및 금융, 문화 산업 중심으로의 체제 개편을 계승하고 신자유주의적인 정책을 대거 받아들였다. 1997 년부터  2005 년까지 3차례의 총선을 승리로 이끌었으며, 역대 노동당 최장수 내각, 전후 유일하게 영국 총리를  10 년 넘게 역임했다. 이 외에도  39 세 때 보수당대표가 돼 당을 대대적으로 뜯어고친 뒤 5년 후 정권까지 탈환했던 영국의 데이비드 캐머런,  38 세에 기성 정당에 대항해 새로 당을 만들어 이듬해에 정권을 거머쥔 프랑스의 에마뉘엘 마크롱 대통령 등이  30 대 기수로 정치판을 뒤흔든 기록을 가지고 있다. ◇여야 초선들 당심 넘어 시대정신 담은 콘텐츠 제시해야 “민주당 혁신의 주체가 되겠다”고 선언한 더불어민주당의  50 여 명 초선의원들은 민심보다 혹독한 당심을 뛰어넘어야 한다. 국민의힘 역시 전당대회에 출마를 밝힌 초선의원들과 중진 간에 불협화음을 통해 당내 기득권층과의 마찰을 고스란히 드러냈다. 진보당과 보수당의 초선들은 당 쇄신이라는 공통 미션을 가지고 기득권층과 맞붙었다. 전문가들은 초선들이 실질적인 정치 변화를 이뤄내기 위해선 당 권력에도 저항하며 민심에 맞는 지속적인 문제 제기와 구체적 비전 제시에 나서야 한다고 강조한다. 이종근 시사평론가는 세대교체의 가장 큰 걸림돌로 ‘꼰대정치’를 꼽았다. 이 평론가는 “내용을 가지고 비판하는 게 아니라 나이가 몇이야 하는 대응이 바로 꼰대정치”라고 말했다. 이어 “꼰대정치가 사려져야 세대 간에 바람직한 충돌이 일어난다”고 말했다. 그러면서 초선들에게는 “시대정신을 담은 콘텐츠를 제시해야 민심을 얻을 것”이라고 조언했다. 최창렬 용인대 교수는 “국민적 지지와 당심은 다를 수 있기 때문에 초선들이 당원들의 지지를 받는 데 애로점이 있을 것”이라며 “그런 정당문화를 돌파하고 기득권 정치를 타파하기 위해서라도 강한 메시지를 내야 한다”고 강조했다. 또 “젊다는 것만 강조할 것이 아니라 구체적인 부동산 정책이나 빈부 격차의 문제 해법, 백신 공급 같은 국민들이 공분을 사고 있는 문제에 정확한 입장과 대안을 제시해야 한다”고 말했다. 초선들의 가장 큰 걸림돌로 당내 기득권층을 지목하는 목소리가 커지자 일부 중진들이 응원 메시지를 내며 초선에 힘을 실어주고 있다. 보수진영의 원조 소장파인 원희룡 제주도지사는 지난달  24 일 자신의 페이스북에서 “젊은 바람이 전당대회를 흽쓸고 있다”며 “이 바람의 동력은 변화에 대한 열망”이라고 말했다. 원 지사는 또 젊은 돌풍이 중진의 변화도 몰고 올 것이라면서 “중진들까지 변화해야 우리 당이 더 큰 변화로 국민에게 다가갈 수 있다”며 “중진은 그대로 있고 초선만 바뀌어서는 성공으로 평가받지 못한다”고 지적했다. 오세훈 서울시장 역시 국민의힘 전당대회를 위해 열린 토론회를 보고 지난달  23 일 페이스북에 “방금 전 0선, 초선들이 자체적으로 벌인 토론회를 유튜브로 봤다”며 “발랄한 그들의 생각과 격식 파괴, 탈권위적 비전을 접하면서 우리 당의 밝은 미래를 봤다”고 말했다. 특히 “정치권 공식대로 예상 가능한 결과라면 기대감도 매력도 물거품처럼 사라질 것”이라면서 “유쾌한 반란이 손에 땀을 쥐게 하는 게임으로 이어진다면, 기대감을 한껏 자극할 것”이라고 했다. 이어 “유쾌한 반란의 주인공, 그런 대표가 선출되기를 간절히 바란다”고 이들에게 지지의사를 밝혔다. 임윤희 기자  yunis @ mt.co.kr ▶본 기사는 입법국정전문지 더리더( the   Leader ) 6월호에 실린 기사입니다. article_split 홍세미 편승민 임윤희 기자  theleader @ mt.co.kr ▶부동산 투자는 [부릿지] ▶주식 투자는 [부꾸미TALK] ▶부자되는 뉴스, 머니투데이 구독하기   &lt;저작권자 ⓒ '돈이 보이는 리얼타임 뉴스' 머니투데이, 무단전재 및 재배포 금지&gt; \\t  // 본문 내용   \", '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}        지난해 9월 독일 \\'기가팩토리 베를린\\' 공장을 방문한 일론 머스크 테슬라  CEO .  AP =연합            테슬라가 전기차 보급이 가장 빠른 서유럽 시장에서 폴크스바겐에 역전당해 1위 자리를 내줬다. 글로벌 자동차조사업체 슈미트 오토모티브 리서치에 따르면 최근  12 개월( 2020 년 5월 ~2021 년 4월)간 독일을 포함한 서유럽  18 개국에 등록된 테슬라 차량은  10 만 2500 대이다. 테슬라가 이처럼 월 평균 판매량이 1만대 안팎에 머물러 있는 사이 전 세계 자동차시장 1위인 폴크스바겐의 순수전기차( BEV )는  20 만 6400 대가 등록돼 월평균 2만대 가량이 판매됐다.          3일 현지 언론 등에 따르면 테슬라와 폴크스바겐의 판매량은 2년 전인  2019 년과 비교하면 완전히 뒤집힌 결과다. 이 기간 테슬라는  10 만 9700 대, 폴크스바겐  BEV 는 4만 6500 대가 팔렸다. 테슬라는  2019 년 보급형 전기차 모델 3를 유럽 시장에 선보인 이후 시장을 주도했지만, 지난해 폴크스바겐이 전기차 전용 플랫폼( MEB )을 장착한  ID.3 를 내놓으면서 테슬라를 따라잡기 시작했다.         폴크스바겐은 지난 4월 진일보한  ID·4 를 내놓으며, 더 탄력이 붙었다. 리서치는  ID.3 와  ID.4 와 같은 스포츠유틸리티차량( SUV )과 크로스오버가 \"유럽 전기차 시장을 지배하고 있다\"고 덧붙였다. 유럽 소비자는 고급 세단이나 덩치 큰  SUV 보단 실용성 있는 차를 선호하는 편인데, 전기차 보급이 확대되면서 폴크스바겐·르노·피아트의 크로스오버형 전기차 판매가 늘고 있다고 설명했다.           제조사별 유럽 전기차 판매. 그래픽=김영옥 기자  yesok @ joongang.co.kr            또 다른 조사기관  EV 볼륨즈의 최근  12 월간 서유럽시장 전기차 판매 대수는 테슬라가 기존 완성차업체에 밀리고 있다는 점을 보여준다. 이 기간 테슬라는 폴크스바겐( 21 만 6009 대)에 1위를 내준 것은 물론 르노·닛산 얼라이언스( 15 만 6494 대)·스텔란티스( 11 만 2640 대)·현대차그룹( 10 만 9095 대)에 이어 5위( 10 만 3346 대)에 머물렀다.         테슬라 전기차는 최근 중국에서도 신통치 않다. 중국자동차공업협회에 따르면 테슬라 모델 3은 올해( 1~4 월) 중국 시장에서 7만 3296 대를 팔아  SMGW 의 우링홍광 미니( 12 만 5925 대)에 크게 뒤졌다. 우링홍광 미니의  GM 과 상하이차·우링의 합작법인이 만든 초소형 전기차다. 또 중국 시장에서 생산돼 판매되는 모델 Y(2만 1819 대)는  BYD 의 한(2만 7101 대), 장성기차의 오라  R1 (2만 2371 대), 체리차의  eQ1 (1만 8990 대)보다 밀렸다. 한국자동차산업협회 관계자는 \"중국에서 신형 전기차가 대거 출시되며 시장에서 차지하는 테슬라 전기차의 비중이 줄었다\"고 말했다.             올해 중국시장 모델별 전기차 판매. 그래픽=차준홍 기자  cha.junhong @ joongang.co.kr            서유럽과 중국은 가장 큰 전기차 시장이다. 모든 완성차업체가 전기차의 기술력과 마케팅을 쏟아붓는 전장이다. 서유럽은 현대차·기아를 비롯한 기존 완성차업가 앞다퉈 신형 전기차를 출시하고 있고, 중국은 상하이차 ·BYD 등 기존 전기차 강자에 니오·샤오펑·리샹 등 스타트업 등이 각축을 벌이는 중이다. 반면  2010 년 모델 S를 선보인 이후 글로벌 전기차 시장을 선점한 테슬라의 시장점유율은 점차 줄어들고 있다.           테슬라는 \\'오토 파일럿\\'과 같은 반자율 주행, 소프트웨어 실시간 업데이트( SOTA ) 등 기존 완성차업체보다 앞선 기술을 통해 시장을 선점했다. 그러나 \\'단차(차체 이음새의 틈)\\' 등 고질적인 품질 문제, 부실한 사후관리( AS ), 다른 브랜드보다 비싼 가격 등은 단점으로 꼽힌다. 최근엔 일론 머스크 테슬라  CEO 가 트위터로 사업과 관계없는 암호화폐와 관련해 \\'입방정\\'을 떨어 테슬라 브랜드에 대한 전 세계 소비자의 반감이 늘었다.         전문가들은 테슬라의 성패는 지금의 판매 대수보단 \"미래에 있다\"는 시각이다. 고태봉 하이투자증권 리서치센터장은 \"연말 기가팩토리 베를린과 내년 기가팩토리 텍사스가 가동을 시작하면 판매 대수는 늘어날 것\"이라며 \"테슬라는 단순히 차 판매가 아니라 향후 \\'자율주행( Full   Self   Driving )\\' 구독서비스, 차량 공유 등을 통해 이익을 창출하겠다고 한 만큼 마진이 박해도 전기차 보급에 치중할 것\"이라고 말했다. 다만 \"각 국의 규제 등 수많은 난관을 뚫고 실제로 그런 세상을 구현할 지는 지켜봐야 한다\"고 덧붙였다.         기가팩토리 베를린은 지난해 9월, 테슬라가 배터리데이에서 밝힌 \"2만 5000 달러(약  3000 만원) 전기차\" 생산기지로 유력한 곳이기도 하다. 유럽 소비자를 겨냥한 B세그먼트(소형 차) 전기차에 새로운 배터리를 장착할 것으로 관측된다. 테슬라는 배터리데이 당시 \"향후  2~3 년 내\"에 2만 5000 달러 전기차를 선보이겠다고 발표했다. 지난 1월 일론 머스크  CEO 는 자신의 트윗 계정에 연말  \\'AI (인공지능) 데이\\'가 있을 것이라고 예고하기도 했다. 업계는 자율주행 기술 관련 내용이 발표될 것으로 예상했다. 테슬라는  2030 년 전기차  2000 만대를 보급하겠다고 했다. 폭스바겐의 2배 규모다.    김영주 기자  humanest @ joongang.co.kr   ▶  그가 들려주는 이야기, 이상언의 \\'더 모닝\\' ▶  건강한 주식 맛집, 앤츠랩이 차린 메뉴 ▶  \\'실검\\'이 사라졌다, 이슈는 어디서 봐? ⓒ중앙일보( https : / / joongang.co.kr ), 무단 전재 및 재배포 금지 \\t  // 본문 내용   ']크롤링 결과 확인하기.print(naver_news_title[0])['OUTLINK', '넷기어, 뮤럴 디지털 액자 대상 프로모션 실시', 'OUTLINK', \"당국, 60세 미만 잔여백신 접종 지침 번복 '혼선'\", '중국의 ‘코인 죽이기’는 디지털 위안화 살리기', '매일 오르는 코인은 있어도 한주간 오른 코인은 없는 이유', '비트코인 급락에 금값은 반등…올들어 최고', 'SNT(Super-Net-Tech), 암호화폐 온라인쇼핑 플랫폼 LUS와 사업 MOU', '금융위, 암호화폐 논의 본격화…거래소 20곳 대면회의', \"'5억 이상 해외 계좌 신고' 시작…숨기면 과태료 '폭탄'\", \"'고팍스' 운영사 스트리미, 코로나19 백신 휴가 시행\", '가상자산 거래소 플라이빗, 자금세탁방지 실무 교육 실시', '상장ㆍ암호화폐 카드 출시…코인베이스 훈풍에 도지코인 급등', '금융위, 가상자산거래소와 첫 간담회…컨설팅 제공', \"포블게이트, 가상자산 담보 대출 서비스 '넥스핀 2.0' 오픈\", '中 가상자산 채굴 전면 퇴출?...지방정부도 압박', '\"이준석 봤지?\"…\\'신선한 반란\\'은 시작됐다', \"車업계 반격에 뒤뚱거리는 '테슬라'…'소형차'로 위기 돌파?\"]print(naver_news_content[0])['OUTLINK', \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    구매 후기 작성시 와이파이6 유무선공유기·증폭기 증정 (지디넷코리아=권봉석  기자) 넷기어 뮤럴 캔버스. (사진=넷기어) 넷기어가 오는 23일까지 뮤럴 디지털 액자를 최대 27% 할인판매한다. 대상 제품은 27인치 풀HD 디스플레이를 탑재한 'MC327', 21.5인치 풀HD 디스플레이를 탑재한 'MC315' 등 2종이다. 행사 기간 중 네이버 넷기어스토어를 통해 21.5인치 MC315는 27% 할인한 68만 6천200원에, 27인치 MC327은 15% 할인한 106만 2천500원에 판매한다. 두 제품 모두 전세계 미술관·박물관의 명화 등을 1년간 무제한 감상할 수 있는 뮤럴 멤버십 1년권을 기본 제공한다. 구매 후기를 남길 경우 MC327은 와이파이6 유무선 공유기 'RAX20'이나 와이파이6 증폭기 'EAX20'을 추가로 증정한다. MC315는 뮤럴 멤버십 1년권이나 와이파이5(802.11ac) 증폭기 'EX7700'을 받을 수 있다. 권봉석 기자(bskwon@zdnet.co.kr)   ▶ 지디넷코리아 '홈페이지'   ▶ 네이버 채널 구독하기 © 메가뉴스 &amp; ZDNET, A RED VENTURES COMPANY, 무단전재-재배포 금지 \\t  // 본문 내용   \", 'OUTLINK', '   본문 내용     TV플레이어      동영상 뉴스        // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t방역 당국이 코로나 19  잔여 백신 접종 지침을 하루 새 2차례 번복하면서 혼선이 빚어졌습니다. 코로나 19  예방접종대응추진단은 어제(2일) 오후 2시  10 분 보도자료를 통해 위탁의료기관 접종은 내일(4일)부터  60 세 이상만을 대상으로 한다고 발표했습니다. 이어 오후 6시 보충 자료에서 기존 예비명단 중  60 세 미만은 오늘(3일)까지만 접종이 가능하고, 내일(4일)부터는 네이버·카카오 앱으로 공개되는 잔여량으로만 예약이 가능하다고 설명했습니다. 이후 오후  10 시 다시 자료를 내고 기존 예비명단자는 9일까지 유예기간을 두고 접종이 가능하다고 지침을 또 바꿨습니다. 연합뉴스 TV  기사문의 및 제보 : 카톡/라인  jebo23  ▶ 네이버에서 연합뉴스TV를 구독하세요  ▶ 연합뉴스TV 생방송 만나보기   ▶ 균형있는 뉴스, 연합뉴스TV 앱 다운받기    // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    photo  셔터스톡 지난 5월  19 일, 암호화폐는 벼랑 끝으로 내몰렸다. 보통  2017 년의 불장을 ‘시즌 1’ , 올해의 불장을 ‘시즌 2’ 라고 부르는데, “시즌2의 종말이 시작됐다”며 투자자들은 아우성쳤다. 이날 1비트코인( btc )은 4만 3000 달러에서 3만달러까지 폭락했다. 1시간 사이에  15 % 이상 급락하기도 했다. 알트코인들은 더 큰 폭락을 겪으며 사람들의 패닉셀을 끌어냈다. 알트코인 중에서는  30 % 이상 폭락한 코인을 쉽게 찾아볼 수 있었다.      암호화폐 시장이 어느 정도 조정을 겪을 것이라는 건 예측 가능한 일이었다. 가격이 너무 올랐고, 금융당국 등에서 경고가 쏟아졌으며, 일론 머스크 테슬라  CEO 처럼 이 바닥의 인플루언서들이 부정적인 메시지를 쏟아냈다. 하지만 이 정도의 급락은 예측하지 못했던 일이었다.      폭락의 원인은 중국발 규제였다. 지난 5월  19 일 중국 당국은 ‘암호화폐 서비스 금지 명령’을 하달했다. 중국 국가인터넷금융협회, 중국은행협회, 중국결제청산협회 등 3개 단체는 금융 및 결제 서비스를 제공하는 업체들에 가상자산 서비스를 중단할 것을 촉구하는 성명을 냈다. “암호화폐? 中 안정 추구에 방해”      중국에서의 정책 영향력은 발언자를 살펴봐야 한다. 누구의 입에 의해 천명됐는지가 중요하다. 지난 5월  21 일 류허 중국 국무원 부총리는 “비트코인의 거래와 채굴 행위가 금융시스템 전반을 위협한다”며 3개 단체 성명의 내용을 재확인했다. 시진핑(習近平) 국가주석의 경제 브레인으로 통하는 류 부총리가 직접 못을 박고 나섰다는 점에서 이번 규제는 꽤 무겁게 느껴진다.      여전히 일각에서는 중국의 규제를 양치기 소년처럼 보는 시선이 있다. 과거 규제 속에서도 여전히 투자가 이뤄져 왔기 때문이다. 중국 당국은  2013 년과  2017 년에도 강력한 규제를 실행한 바 있다. 그 때문에 바이낸스( Binance ) 등 중국의 대규모 거래소들은 케이맨제도 등에 본사를 세워 역외에서 영업을 해야 했고, 중국의 법정화폐인 위안화로 암호화폐를 사는 길은 막혔다. 그런다고 규제가 개인의 암호화폐 소유까지 막은 건 아니었다. 중국인들은 규제를 피해 알음알음 암호화폐를 거래했다.      지난 2월 말  6500 만원을 찍던 비트코인이  5000 만원 초반대로 추락했다가 급반등으로 가격이 회복되는 일이 있었다. 중국인들의 매수세가 빠른 회복의 원동력이었다. 중국 투자자들은 알리페이나 위챗페이로 브로커와  p2p  장외거래를 통해 테더( USDT )를 사고 이 테더를 거래소에 입금해 비트코인을 구매한다. 테더는 달러화와 연동되는 스테이블 코인으로 1테더는 1달러의 가치를 갖는다. 지난 2월 반등했을 때, 위안화로 표시된 테더 가격에는  1~2 %의 프리미엄이 붙었는데 그만큼 수요가 많았다는 뜻이다.      반대로 이번 조치가 예사롭지 않다는 징후는 규제 직후 바로 나타났다. 일단 개인 시장이 일순간 침묵했다. 류허 부총리가 말한 거래의 금지는 그동안 묵인했던 테더를 활용한 개인의 거래다. 중국 사정을 잘 아는 암호화폐 관계자는 “이번 금지조치가 내려진 뒤 테더를 거래하는 대형 브로커들이 일시적으로 확 줄어들었다”고 말했다. 중국 당국의 조치가 내려진 직후 위안화로 매겨진 테더의 가격도 폭락했는데 현금화하느라 매도가 쏟아졌을 거라는 추측이 나왔다.      팬데믹 이후 커져가는 사회불안을 잠재우기 위해 중국은 지금 경제의 방향을 성장보다 안정에 맞추고 있다. 이사벨라 베버 매사추세츠대 교수는 “지금 중국의 금융구조는 안정에 힘을 실은 상태다. 암호화폐 거품이 꺼질 경우 생길 수 있는 경제적 충격을 막기 위해 중국 정부가 규제를 재차 언급하고 나선 것도 크게 놀랄 일은 아니다”라고 말했다. 경제가 국가의 지배 아래서 시장화된 중국에서 정부의 통제를 벗어난 자본은 쉽게 용납될 수 없다. 그런 점에서 암호화폐는 특별관리대상이다. 엄포와 방관 대신 관리와 통제의 시기가 왔다는 게 베버 교수의 지적이다.      자본 유출에 대한 위험도 마찬가지다. 중국 정부는 암호화폐가 자본 유출의 수단이 될 수 있다고 믿는다. 이런 경계심은 자본 통제의 욕망이 강한 중국 정부가 코인 시장을 죽일 수 있는 근거이기도 했다. 중국인이 법적으로 해외로 반출할 수 있는 외화는 1인당 5만달러지만 테더를 구입해 전송한다면 정부의 상한선은 무의미하다. 블록체인 분석업체 체이널리시스( Chainalysis )의 지난해 8월 보고서에 따르면, 이전 1년 동안  180 억달러 이상의 테더가 동아시아의 지갑에서 해외로 전송됐다. 보고서는 “해당 국가 투자자들이 해외 자본 이전 제한 규정을 피하기 위해 테더를 활용하고 있을지 모른다”고 지적했다. “비트코인 싹 잘라라”   사우스차이나모닝포스트는  “중국이 암호화폐 규제에 나선 건  디지털위안화와 암호화폐를  분명하게 구별하기 위해서” 라고 보도했다.  여기서 구별이란 제도권 내  유일한 디지털화폐는  인민은행이 발행하는  디지털위안화뿐이란 걸 뜻한다.    중앙은행이 직접 암호화폐를 발행하고 경쟁상대를 퇴출시킬 수 있다는 건 코인 시장의 가장 큰 리스크이다. 골드만삭스 출신으로 가상자산 유동성 제공업체인  B2C2 재팬을 이끌고 있는 필립 길레스피  CEO 가 “디지털위안화는 암호화폐 시장의 가장 큰 리스크가 될 것”이라고 말하는 이유다.      중국이 새로운 규제를 천명한 시점은 디지털위안화 등장이 임박한 때와 맞물린다.  2014 년부터 중앙은행 디지털화폐( CBDC ) 연구를 시작한 중국 인민은행은 내년 초 중국 대륙에 디지털위안화를 보급할 계획을 갖고 있다. 이미 디지털위안화는 실물과 동등한 권한을 갖도록 법적 정비까지 마친 상태다. 지난해  10 월 남부 대도시인 선전에서 실제 사용 테스트를 끝냈고 최근에는 홍콩에서 역외를 넘나드는 실험도 실시했다. 다른 두 도시 간의 연계 실험도 마무리됐고 지금은 태국, 아랍에미리트( UAE ) 등과 해외 결제를 실현하기 위한 플랫폼을 개발 중이다.      사우스차이나모닝포스트( SCMP )는 “중국이 암호화폐 규제에 나선 건 디지털위안화와 암호화폐를 분명하게 구별하기 위해서”라고 보도했다. 여기서 구별이란 제도권 내 유일한 디지털화폐는 인민은행이 발행하는 디지털위안화뿐이란 걸 뜻한다.      보리스 슐로스버그  BK 에셋 디렉터는 “디지털위안화는 모든 통화를 추적할 수 있다는 점에서 정부에 엄청난 통제력을 준다. 중국 정책 입안자들은 이제 모든 소비자의 선택을 알 수 있게 되고 소비 행태에까지 직접적인 영향을 줄 수 있다”고 말했다. 하지만 중앙은행이 발행하는 디지털화폐는 필연적으로 프라이버시 침해 논란을 몰고 온다. 내 계좌와 사용기록 등을 정부가 파악할 수 있다는 우려로  CBDC 에 대한 거부감도 크다. 이런 상황에서 암호화폐 시장이 커지는 건 새로 안착해야 할  CBDC 에 큰 장애물이다. 중국 내 첫 번째 디지털화폐는 비트코인이 아니라 디지털위안화가 돼야 한다는 것은 중국 정부 입장에서 체제 유지의 문제나 다름없고, 그러기 위해서 경쟁자의 싹을 자를 필요가 있었다는 게 이번 규제의 배경 중 하나다.      문제는 이후다. 류 부총리의 발언이 각 성에 하달되고 구체적인 지침과 단속으로 가시화할 때까지는 시간이 걸린다. 그 이후 나타나는 사회적 양상에 따라 암호화폐 시장은 또 한 번 충격을 받을 수 있다. 둥시먀오(董希淼) 푸단대 금융연구소 겸임연구원은 “(중국 정부가) 향후 비트코인 등 암호화폐의 불법 거래 행위를 타격하는 조치를 내놓을 것”이라고 예상했다. 유동성에 문제가 생길지 모를 또 한 번의 충격이 있을 수 있다는 얘기다. 김회권 기자  khg @ chosun.com ▶네이버 메인에서 [주간조선] 구독하기  ▶주간조선 홈페이지에서 더 많은 기사 보기 -  Copyrights  ⓒ 조선뉴스프레스 - 주간조선, 무단 전재 및 재배포 금지 - \\t  // 본문 내용   ', \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    - 비트코인 일주일째 같은 가격.. 곧 방향성 결정날 것 - 바닥권 코인 단기 상승 후 조정 반복되는 시장 - 지금은 단기 혹은 관망으로 대응 필요 *디브리핑은 매일경제, 블록크래프터스, 고위드와 함께하는 디스트리트에서 제공하는 암호화폐 시황입니다. 안녕하세요. 2021 년 6월 3일 오후  12 시, 디브리핑의 문호준입니다. 지난 하루 동안의 암호화폐 주요 시황 살펴보겠습니다. [비트코인]   △비트코인 차트, 출처: 업비트 비트코인은 일주일 가까이 4, 350 만 원 부근에서 횡보를 이어가고 있습니다. 비트코인 도미넌스(시가총액 점유율)는  41.5 %로 지난 5월  24 일 고점을 찍은 뒤 계속 하락하고 있으며, 김치프리미엄(해외보다 높게 형성된 가격)은 4%대로 해외보다 더 많이 하락할 리스크는 많이 없어졌습니다. [주요 코인]   △시가총액  TOP   100  코인, 출처:  Coinmarketcap 시가총액  TOP   100  코인을 보면 전일 엠덱스( MDX ,  -2.92 %)를 비롯한 6개 코인을 제외하고는 모두 상승했습니다. 그 중 거래소 코인인 오케이비( OKB , + 27 %)가 가장 크게 올랐으며, 도지코인( DOGE , + 15 %), 아이오타( IOTA , + 16 %), 아이콘( ICX , + 12 %) 등도 강세를 보였습니다.   △아이오타( IOTA ) 차트, 출처: 업비트 비트코인이 횡보하자 상대적으로 덜 오른 코인들이 짧게 반등하는 순환 패턴이 이어지는 모습입니다.   △최근 1주일 상승률 상위 코인, 출처: 업비트 최근 1주일동안 상승률이 가장 높았던 코인만 보더라도 얼마나 빠르게 순환매가 돌고 있는지 알 수 있습니다. 데일리로 보면 크게 오르는 코인들이 있지만 1주일 기준으로는 크게 오른 코인이 없다는 것은, 단기적으로 오른 코인이 다시 하락하는 순환이 돌고 있기 때문입니다. [총정리] 비트코인은 조만간 횡보를 깨고 반등이나 하락으로 방향을 잡을 것입니다. 반등에 이어 상승장으로 전환할 경우에는 ‘달리는 말에 올라타(오르는 코인을 매수)’는 것이 가능하지만, 지금처럼 횡보하거나, 반등하거나, 하락할 경우에는 바닥권 코인에 대한 단기 투자나 관망이 시장에 대한 가장 합리적인 대응법이라 생각됩니다. 이것으로  2021 년 6월 3일 디브리핑을 마치겠습니다. 감사합니다. [문호준 암호화폐 애널리스트]  r_start //  r_end // ▶ '경제 1위' 매일경제, 네이버에서 구독하세요 ▶ 매경이 전하는 지식레터 '매콤달콤' 받아보세요 ▶ 매경이 알려주는 '취업비법' 한달간 무료 [ⓒ 매일경제 &amp;  mk.co.kr , 무단전재 및 재배포 금지] \\t  // 본문 내용   \", '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    1900 달러 선 재돌파…연초 수준 회복 지난달  26 일 6만 8430 원, 올해 최고치 \"비트코인 급락에 안전자산 선호현상\" \"중장기적으론 박스권에서 움직일 듯\" [서울=뉴시스]홍효식 기자 = 비트코인 등 암호화폐가 반토막 수준으로 급락하는 반면 금값이 올들어 최고치를 기록하고 있는 가운데  30 일 서울 종로구 한국금거래소 종로본점에 골드바가 진열돼 있다. 한국거래소에 따르면  30 일 오전  10 시 기준  1g 당 금 시세는 6만 7750 원을 기록하고 있다.  2021.05.30.   yesphoto @ newsis.com  [서울=뉴시스] 이승주 기자 = 올초 하락세를 이어가던 금값이 반등하더니 최근 올들어 최고치를 기록했다. 비트코인 등 암호화폐 시세가 절반 가까이 급락하자 안전자산으로 분류되는 금으로 투자수요가 돌아서는 것으로 분석된다. 3일 한국거래소에 따르면 전일 국제 금 시세는 종가 기준 온스 당  1916.08 달러를 기록했다. 전일( 1903.63 달러) 대비  0.65 % 오른 수치다.  금 시세는 지난해 역대 최고치를 기록하더니 올들어 하락세가 계속됐다. 특히 지난 1월8일  1907.42 달러를 기록한 뒤  1900 선을 밑돌더니 심지어  1600 달러 대까지 떨어졌다. 하지만 지난달부터 반등세를 이어가면서  1900 선을 재돌파했다. g당으로는 지난 2일 금 시세는 6만 8130 원을 기록했다. 이는 전일(6만 7990 원) 대비  0.21 % 상승한 수치다. 이는 올초 수준을 회복한 것은 물론 지난 1월4일(6만 6910 원)을 상회하는 수치다. 특히 지난달  26 일에는 6만 8430 원까지 올랐는데 이는 올들어 최고치다. 금값은 지난해 8월 역대 최고치인 7만 8440 원까지 올랐다. 전 세계적으로 코로나 19  사태가 진정될 기미가 보이지 않자 투자자들이 안전한 피난처로 여겨지는 금으로 몰려든 것으로 분석된다. 현물 금 가격은 지난해 들어서 8월까지  30 % 넘게 급등했는데, 이는  1979 년 이후 가장 많이 오른 것이다. 당시 투자업계에서는 이같은 상승세가 올해 상반기까지 계속될 것이란 전망이 우세했다. 하지만 금값은 이후 점차 하락해 올초 3월 31 일 기준 6만 1400 원까지 떨어졌다. 이는 올들어 최저치다.  그랬던 금값이 지난달부터 다시 반등하더니 올들어 최고치를 기록한 셈이다. 이에 대해 전규연 하나금융투자 연구원은 \"지지부진하던 금 가격이 4월 이후 반등하더니 5월부터 추세적 상승을 시도하고 있다\"며 \"안정적인 금리 흐름과 달러 약세가 금 가격 상승을 지지하고 있다\"고 분석했다. [서울=뉴시스] 고승민 기자 = 미국 코인베이스의 자사 전문투자자 거래소 \\'코인베이스 프로\\'에 상장된다는 소식에 도지코인이 상승세를 보인 3일 서울 빗썸 강남고객센터 모니터에 암호화폐 시세가 표시돼 있다.  2021.06.03.   kkssmm99 @ newsis.com 투자업계는 이 같은 반등세를 암호화폐 급락에 따른 안전자산 선호 강화로도 풀이했다.  올들어 급등했던 암호화폐는 검은수요일이라 불리는 지난  19 일 이후 하락세다. 대표적인 암호화폐 비트코인은 지난달  14 일 역대 최고치( 8148 만 7000 원)까지 올랐지만 미국 전기자동차 기업 테슬라의 비트코인 결제 중단 소식에 이어 중국과 미국의 규제 움직임 등에 한달여 만에 반토막 수준까지 하락한 셈이다. 게다가 테슬라의 최고경영자( CEO ) 일론 머스크의 일관성 잃은 발언으로 변동성이 커지더니 한때  3000 만원대까지 떨어지면서 투자자들의 원성이 고조됐다.  암호화폐거래소 빗썸에 따르면 이날 오전 8시 19 분 기준 비트코인 가격은  4370 만 2000 원에 거래됐다. 비트코인은 6월들어  4200 만 ~4400 만원대에서 등락을 거듭하고 있다. 역대 최고치의 절반 수준을 조금 웃도는 수준이다. 업비트에선  4372 만 4000 원에 거래 중이다.  나중혁 하나금융투자 연구원은 \"인플레이션에 대한 효율적인 헤지수단으로 인식되면서 지난해 4분기부터 비트코인 신탁으로 자금 유입이 빠르게 전개됐다\"면서 \"이달들어 비트코인 신탁의 자금이 급격히 줄어드는 가운데 금 상품으로는 자금 유입이 늘어났다. 최근 비트코인으로 옮겨갔던 인플레이션 헤지용 금 투자 수요가 돌아오는 것\"이라고 분석했다. 나 연구원은 \"암호화폐 변동성이 확대될수록 금 투자가 확대될 개연성이 높지만 올해 하반기 미 연준의 스탠스 전환을 고려하면 전고점 경신 가능성은 낮다\"며 \"금은 인플레이션 헤지와 안전자산 수요가 늘어나면서 단기적으로 상승한 뒤 중장기적으로 온스 당  1600~1950 달러 박스권 내에서 움직일 것 같다\"고 전망했다. ☞공감언론 뉴시스   joo47 @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t[머니투데이 중기&amp;창업팀 허남이 기자]  SNT ( Super-Net-Technology )는 명품 아울렛인 암호화폐 온라인쇼핑 플랫폼  LUS 와 전략적 사업 협약 ( MOU )을 체결했다.  사진제공= SNT   SNT 는 이번 협약이  LUS 와의 핀 테크 기반 결제 플랫폼에 대한 새로운 전략적 계약으로 간주된다고 말했다. 두 회사의 전략적 계약에는 비즈니스 및 결제 기술에 대한 협력을 수행하는 블록체인의 상호 운용성 향상에 동의하는 것으로 포함된다. 두 회사는 암호화폐 자산 결제 등 다양한 분야에서 블록체인 노하우를 공유하고 협업을 통한 시너지 효과를 기대한다고 전했다. 또한 이번 계약을 통해  SNT 와  LUS 는 기존  LUS  인프라를 기반으로 온라인 브랜드 비즈니스 협력 시스템을 공동 구축할 예정이며, 거기에서 동남아 브랜드 블록체인 시장을 연결하는 시장을 구축할 것이라고 말했다. SNT 는  SNT  지갑과 같은 현재 암호화폐 시장의 핫키를 결합한 몇 안되는 플랫폼 중 하나이기 때문에  DEFI ;  P2P , 쇼핑몰이 시장의 주목을 받고 있다. SNT   LAB 은  Juda   Mall  및  Fintech  결제 시스템과  2021  년 7월 오픈 예정인 블록체인 결제 프로젝트를 결합하기 위한 계약을 체결했으며,  LUS 은 계속해서 자체 사업 영역을 확장하고 있다. 거기에서 사람들이 토큰으로 서비스 비용을 지불할 수 있는 서비스도 제공된다. 그리고 오는 6월  13 일에  SNT 는 글로벌 거래소  SPexchange 에  IEO 로 상장이 된다. SNT   LAB  재단 이현호 대표는 \" LUS  쇼핑과의 협력을 통해 많은 사용자에게 블록체인 기반 결제 서비스를 제공할 수 있게 되었다\"며 \"다양한 기술을 도입하여 사용자에게 더 많은 편의와 혜택을 제공할 것이다\"고 말했다. 또한  LUS  관계자는 \"파트너십을 통해 끊임없이 확장되는 블록체인 기술을 통해 아울렛 시장에 대해 더욱 밝은 미래와 시장을 선보이게 됐다\"고 전했다.  article_split 중기&amp;창업팀 허남이 기자  nyheoo @ ▶부동산 투자는 [부릿지] ▶주식 투자는 [부꾸미TALK] ▶부자되는 뉴스, 머니투데이 구독하기   &lt;저작권자 ⓒ \\'돈이 보이는 리얼타임 뉴스\\' 머니투데이, 무단전재 및 재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    금융위 주무부처 결정 이후 첫 회의 금융위 \"신고 관련 사항 등 논의 예정\" [서울=뉴시스] 박민석 기자 = 금융위원회(뉴시스 DB )  2020.04.23.  *재판매 및  DB  금지 [서울=뉴시스] 최현호 기자 = 금융위원회(금융위)가 국내 암호화폐 거래소들과의 대면회의를 진행한다. 금융위가 암호화폐 주무부처로 지정된 뒤 첫 회의다. 3일 금융위에 따르면 금융정보분석원( FIU )은 이날 오후 4시 은행연합회에서 암호화폐 거래소  20 곳 관계자들과 간담회를 가진다. 이번 간담회는 지난달 금융위가 암호화폐와 관련 사업체 관리 감독 주무부처로 결정된 후 첫 회의다. 이날 간담회는 비공개로 진행된다. 간담회에선 가상자산 사업자 주의사항, 취급금지 가산자산 규정 추진 방향 등을 논의하는 것으로 전해졌다. 금융위 관계자는 \"지난 정부 발표 대책 내용과 신고 관련 사항 정도(를 논의할 예정)\"이라고 말했다. 간담회는 금융위가 주무부처로 결정된 뒤 가상자산사업자들의 납세, 시행령 개정방향 등 관련 문의가 몰리자 긴급히 결정된 것으로 알려졌다. 금융위는 추후 다른 가상자산사업자 등과도 회의를 진행할 예정이다. 다만 금융위 관계자는 \"아직은 구체적인 계획이 없다\"고 밝혔다. ☞공감언론 뉴시스   wrcmania @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    국세청, 잔액 5억 이상 해외 계좌 신고 안내 매월 말일 중 어느 하루라도 초과 시 알려야 이달 말까지 신고 않으면 최대  20 % 과태료 지난  10 년간  1475 억 과태료 ·63 명 형사 고발 [홍콩= AP/ 뉴시스] 홍콩의 홍콩상하이은행( HSBC ) 건물 앞 모습. 이 사진은 기사 내용과 직접적 관련 없음 [세종=뉴시스] 김진욱 기자 = 해외 금융 계좌 신고 기간이 다가왔다. 해외 계좌 잔액 합계가 \\'매월 말일 중 어느 하루\\'라도 5억원을 초과했다면 이달 말까지 반드시 신고해야 한다. 이를 숨겼다가는 미·과소 신고 금액의  20 %를 과태료로 내야 한다. 지난  10 년간 총  1475 억원의 과태료가 부과됐다. 숨긴 금액이  50 억원을 넘으면 형사 처벌도 받을 수 있다. 국세청은 3일 이런 내용의 해외 계좌 신고 의무를 안내했다. 신고 의무자는 거주자(국내에 주소를 뒀거나,  183 일 이상 거소를 둔 개인)·내국 법인이다. 지난해 보유한 해외 계좌 중 거래가 없거나, 같은 해 해지했더라도 기준을 충족한다면 신고해야 한다. 신고 대상에는 예·적금뿐만 아니라 주식(주식예탁증서( DR ) 포함)·채권·펀드·파생상품·보험상품 등이 모두 포함된다. 잔액은 계좌에 보유한 각 자산을 평가하고, 그 금액을 해당 표시 통화의 환율로 바꾼 뒤 자산별 금액을 모두 더해 산출한다. 만약 피상속인 명의의 해외 계좌를 여러 명이 공동으로 상속받았다면 상속인 각자의 상속분만큼만 환산해 더한다. 본인 명의가 아닌 차명 계좌의 경우 명의자(거주자)와 실소유자 모두에게 신고 의무가 있다. 공동명의 계좌라면 명의자 각각 신고해야 한다. 이때 명의자-실소유자, 각 공동명의자는 계좌 잔액 전부를 각자 보유한 것으로 간주하므로 신고 기준 계산에 유의해야 한다. 암호화폐 계좌의 경우 오는  2022 년 1월1일 이후 신고 의무가 생기는 잔액부터 대상에 포함한다. 최초 신고 시기는  2023 년 6월이다. 대상자는 홈택스(\\'신고·납부→일반 신고→해외 금융 계좌 신고\\' 경로)에서 간편하게 전자 신고할 수 있다. 올해부터는 모바일 애플리케이션 손택스로도 신고할 수 있다. 국세청은 코로나 19  예방을 위해 홈택스·손택스 등을 이용한 비대면 신고를 권장했다. 신고 대상 연도 종료일  10 년( 2011 년 1월1일 ~2020 년  12 월 31 일) 전부터 국내에 주소·거소를 둔 기간 합계가 5년 이하인 외국인 거주자, 신고 대상 연도 종료일 1년( 2020 년 1월1일 ~12 월 31 일) 전부터 국내에 거소를 둔 기간 합계가  183 일 이하인 재외국민 등은 신고 의무가 면제된다. 국세청은 이번 신고 기간 이후 외국 과세 당국과의 정보 교환 자료 등을 정밀 분석해 미·과소 신고자 검증에 나설 계획이다. 기간 내 이를 신고하지 않거나, 줄여 신고한 경우 해당 금액의  10~20 %를 과태료로 내야 한다. 미·과소 신고 금액이  20 억원 이하라면 그  10 %를,  20 억 ~50 억원이라면  \\'2 억원+ 20 억원 초과액 ×15 %\\'를,  50 억원 초과라면  \\'6 억 5000 만원+ 50 억원 초과액 ×20 %\\'를 문다. 상한액은  20 억원이다. 미·과소 신고 금액이  50 억원 초과 시 형사 처벌을 받거나, 인적 사항 등이 공개될 수 있다. 국세청은 지난  10 년간 총  63 명을 형사 고발하고, 7명의 명단을 공개한 바 있다. 또 신고 의무 위반자는 자금 출처 소명을 요구받을 수 있다. 미(거짓)소명 시 해당 금액의  20 %만큼 추가 과태료를 물어야 한다. 국세청은 최대  20 억원 규모의 해외 계좌 미신고 포상금제도 운영하고 있다. 과태료 또는 벌금 납부액이  2000 만원 ~2 억원이면 그  15 %를, 2억 ~5 억원이면  \\'3000 만원+2억원 초과액 ×10 %\\'를, 5억원 초과 시  \\'6000 만원+5억원 초과액 ×5 %\\'를 과태료로 준다. 국세청은 \"해외 계좌 신고 의무자에게 최대한의 신고 편의를 제공하고, 신고자 및 그 내용에 관해서는 관련 법률에 따라 비밀을 철저히 유지하겠다\"면서 \"신고 의무자는 자진 신고가 최선의 선택이라는 생각으로 성실하게 신고해 달라\"고 했다. ☞공감언론 뉴시스   str8fwd @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    . *재판매 및  DB  금지 [서울=뉴시스] 유자비 기자 = 암호화폐 거래소 고팍스를 운영하는 스트리미는 임직원의 안전과 코로나 19  백신 접종 독려를 위해 코로나 19  백신을 접종하는 모든 임직원에게 유급 휴가를 제공한다고 3일 밝혔다. 백신유급 휴가 대상자는  1991 년  12 월 31 일 이전 출생자 중 사전접종 예약이 없거나 접종 이력이 없는 모든 임직원에게 적용된다.  백신 휴가제도 시행에 따라 스트리미 임직원들은 백신 접종 당일 유급 휴가가 제공되며 이상 징후 발생시 유급 휴가 1일이 추가 제공된다.\\u2028 스트리미 관계자는 \"임직원의 건강과 안전을 지키는 것이 최우선 원칙\"이라며 \"백신 휴가제도 시행으로 백신 접종률을 높이고 코로나 19  극복에 기여해 일상의 정상화가 하루 빨리 오기를 기대한다\"고 말했다. 한편 스트리미는 지난해 코로나 19  발생 초기부터 전직원 재택근무를 시행하고, 재택근무 기간 중 업무상 불가피하게 출근하는 임직원에게는 교통비를 지급해 왔다. \\u2028 ☞공감언론 뉴시스   jabiu @ newsis.com ▶ 네이버에서 뉴시스 구독하기 ▶ K-Artprice, 유명 미술작품 가격 공개 ▶ 뉴시스 빅데이터 MSI 주가시세표 바로가기 &lt;ⓒ 공감언론 뉴시스통신사. 무단전재-재배포 금지&gt; \\t  // 본문 내용   ', '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    총 3차례 걸쳐  AML  제도 교육 가상자산 거래소 플라이빗 임직원들이 자금세탁방지( AML ) 실무 교육을 받고 있다.  [사진=한국디지털거래소] [아이뉴스 24  허재영 기자] 가상자산(암호화폐) 거래소 플라이빗의 운영사 한국디지털거래소가 전체 임직원을 대상으로 자금세탁방지 업무 전문성을 강화하기 위해 자금세탁방지( AML )에 대한 실무 교육을 실시했다고 3일 밝혔다. 플라이빗은 자금세탁방지 제도를 정확하게 이해함과 동시에 실무 역량 강화를 제고하기 위한 목적으로 총 세 차례에 걸쳐 교육을 진행했다. 이는 가상자산 사업자( VASP )로서 특정금융정보법에 따라  AML  의무를 철저히 준수하기 위한 것이라는 설명이다. 이번 교육 내용은 ▲  AML  제도 개요 ▲ 가상자산 관련 법령 개정 내용 ▲ 자금세탁방지제도 검사감독방향 및 관련 법률 위반 사례 ▲ 자금세탁방지 제도 실무적용 및 관련 고객 응대 방안 등에 대한 주제로 구성됐다. 앞서 플라이빗은 임직원들의 준법의식 및 업무수행 능력을 향상하기 위해 지난 2월  AML  내부통제를 위한 임직원 교육을 실시한 바 있다. 플라이빗 관계자는 \"자금세탁방지 교육을 정기적으로 실시하는 것은 물론 선진화된 자금세탁방지 제도 교육 체계를 수립함으로써 업무를 수행하는 데 필요한 역량과 전문성을 강화시킬 방침\"이라고 말했다. /허재영 기자( huropa@inews24.com) ▶네이버 채널에서 \\'아이뉴스24\\'를 구독해주세요. ▶재밌는 아이뉴스TV 영상보기   ▶아이뉴스24 바로가기 [ⓒ 아이뉴스 24  무단전재 및 재배포 금지]    // 본문 내용   ', \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}        코인베이스 전용 카드 출시와 도지코인 상장 소식에 암호화폐 가격이 들썩이고 있다.                미국 최대 암호화폐 거래소인 코인베이스발 호재로 암호화폐 가격이 들썩이고 있다. 코인베이스가 암호화폐 전용 카드(직불카드) 출시와 함께 도지코인 거래를 허용한다는 소식이 전해지면서다. 코인베이스 입성에 도지코인 몸값은 눈에 띄게 급등했다. 3일 오전  11 시 20 분 현재 코인마켓캡에서 도지코인은  41.4 센트에 거래되고 있다. 오전 7시 한때는 몸값이  43 센트를 넘기기도 했다.  24 시간 전보다  24 % 폭등한 가격이다.       코인베이스가 도지코인의 거래를 허용하면서, 도지코인 가격이  20 % 이상 급등했다.          CNBC  등 외신에 따르면 코인베이스는 3일부터 전문 중개인용 자산거래 플랫폼 ‘코인베이스 프로’에서 도지코인을 거래할 수 있게 한다고 지난 1일(현지시각) 발표했다. 그동안 '장난으로 만든' 도지코인의 거래를 허용하지 않던 코인베이스가 방침을 바꿔 거래를 허용한 것이다.         코인베이스 카드 출시 소식도 암호화폐 시장에는 호재다. 지난 1일 코인베이스에 따르면 코인베이스 카드 이용자들은 애플페이와 구글페이를 통해 결제할 수 있게 됐다. 암호화폐구입도 한층 쉬워질 전망이다. 또 카드 이용자는 비트코인 등 암호화폐 잔액으로 매장에서 물품을 구입하거나 현금인출기( ATM )에서 돈을 인출할 수 있다. 코인베이스는 이번 카드 출시를 기념해 결제 시마다 비트코인 1%씩, 스텔라 4%씩 돌려주는 리워드(보상)도 제공할 계획이다.          코인베이스발 호재로 도지코인을 제외한 주요 암호화폐 가격도 오름세다. 현재( 11 시  20 분) 암호화폐 대장주인 비트코인은 코인마켓캡에서  3733 달러에 거래되고 있다.  24 시간 전보다 3% 가까이 올랐다. 같은 시간 이더리움은  24 시간 전보다  3.1 %, 카르다노는  2.06 % 각각 상승하고 있다.          염지현 기자  yjh @ joongang.co.kr     ▶  그가 들려주는 이야기, 이상언의 '더 모닝' ▶  건강한 주식 맛집, 앤츠랩이 차린 메뉴 ▶  '실검'이 사라졌다, 이슈는 어디서 봐? ⓒ중앙일보( https : / / joongang.co.kr ), 무단 전재 및 재배포 금지 \\t  // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    거래소  20 곳 참여할 듯 [이데일리 이승현 기자] 금융위원회가 가상자산(암호화폐) 사업자 관리 및 감독 주무부처로 지정된 이후 처음으로 가상자산거래소들과 만난다. 3일 금융권에 따르면 금융위 산하 금융정보분석원( FIU )은 이날 오후 4시 서울 중구 은행연합회관에서 ‘가상자산거래소 신고등록 안내 컨설팅(가칭)’ 비공개 간담회를 개최한다. 이 자리에는 정보보호 관리체계( ISMS ) 인증을 얻은 국내 가상자산거래소  20 곳이 참석하는 것으로 알려졌다. 이날 간담회에서  FIU 는 가상자산사업자 관리를 위한 정부 입장을 설명하고 향후 제도개선 방향을 안내할 것으로 전망된다. 앞서 지난달  28 일 정부는 ‘가상자산 거래 관리방안’을 발표하며 가상자산거래소의 조속한 신고를 위해 필요한 보완사항에 대한 컨설팅을 제공하겠다는 계획을 밝혔다. 간담회에선 가상자산 사업자 신고요건과 함께 사업자 취급금지 가상자산 규정, 사업자 시세조종 금지 등에 대한 내용이 논의될 전망이다. 가상자산사업자 신고요건은  ISMS  인증 획득, 실명확인 입출금 계정 개설, 대표·임원이 특정금융정보법·범죄수익은닉규제법·금융관련법령 등 위반 없음 등이다.  금융위는 가상자산사업자 등이 자체 발행한 가상자산에 대해 매매와 교환을 중개 및 알선하는 행위를 금지하고, 사업자의 시세조종행위를 금지하는 방안을 추진하고 있다.  금융위는 특정금융정보법에 따라 가상자산사업자에 대해 신고유예 기한인 9월 말까지 조속한 신고를 유도하고 컨설팅을 제공할 예정이다. 이후에는 신고한 사업자의 관리와 감독에 초점을 맞추기로 했다. 기존 가상자산사업자는 요건을 갖춰 9월  24 일까지  FIU 에 신고를 마쳐야 한다. 3일 오전 서울 강남구 암호화폐 거래소 업비트 라운지 전광판에 비트코인과 알트코인 시세가 표시되고 있다. (사진=연합뉴스) 이승현 ( leesh @ edaily.co.kr ) ▶ #24시간 빠른 #미리보는 뉴스 #eNews+ ▶ 네이버에서 '이데일리 뉴스'를 만나보세요 ▶ 빡침해소, 청춘뉘우스 '스냅타임' ＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지＞    // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    비트코인 등 담보로 원화 대출가상자산 가격 하락 대비 위험 관리 지원 6월말까지 출시 기념 무이자 이벤트 (사진=포블게이트) [이데일리 김국배 기자] 국내 암호화폐 거래소 포블게이트는 핀테크 기업 민트플렉스와 가상 자산 담보 대출 서비스 ‘넥스핀  2.0’ 을 제공한다고 3일 밝혔다. 넥스핀  2.0 은 민트플렉스가 선보인 가상자산 담보 원화 대출 서비스로, 전문가들이 설계한 알고리즘을 기반으로 자체 개발한 리스크 관리시스템( RMS )을 제공한다. 이를 통해 안정적인 대출 원금 정산 서비스와 함께 담보 자산 가치 하락에 따른 위험 관리를 지원받을 수 있다는 게 회사 측 설명이다. 회사 측은 “심사를 거쳐 디지털 자산 가격의 최대  50 %까지만 대출을 지원하며, 디지털 자산 가격이 (대출 당시보다)  45 % 하락하는 시점에는 매도를 진행해 위험을 줄이는 방식”이라고 설명했다. 현재 담보로 지정할 수 있는 가상자산은 비트코인으로, 향후 이더리움을 포함한 글로벌  10 위권 내 가상자산으로 대상을 확대할 예정이다. 포블게이트 고객들은 신용등급, 대출한도 상관없이 원화 대출 서비스를 이용할 수 있으며 대출 기간은 1개월 혹은 3개월 중에 선택할 수 있다.  포블게이트는 신규 서비스 오픈을 기념해 오는  30 일까지 무이자 혜택 이벤트를 진행한다. 이 기간 가입한 회원 중 선착순  100 명에게는  5000 원 상당의 비트코인을 증정하며, 1개월 이상 대출 만기 서비스를 이용하는 고객 중  40 명을 추첨해 첫 달 무이자 혜택을 제공한다. 다만, 무이자 혜택은 최대  200 만원 한도 내에서 적용된다.  200 만원 이상 초과 대출분에 대해선 기본 이자율을 적용한다. 김국배 ( vermeer @ edaily.co.kr ) ▶ #24시간 빠른 #미리보는 뉴스 #eNews+ ▶ 네이버에서 '이데일리 뉴스'를 만나보세요 ▶ 빡침해소, 청춘뉘우스 '스냅타임' ＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지＞    // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    쓰촨성, 채굴 현황파악...단속예고 네이멍구, 지난달 채굴 규제안 발표 중국 중앙정부가 가상자산 채굴 금지령을 내린 이후 지방정부도 단속 움직임에 동참하고 있다. 채굴업자의 탈중국 움직임도 본격화하고 있는 가운데, 일각에선 정부의 단속 하에 본토에서 운영되는 벌어지는 가상자산 채굴 현장이 결국에 모두 폐쇄될 수도 있다는 관측도 제기된다. 3일 관영 글로벌타임스에 따르면 전날 쓰촨성 에너지 규제당국은 가상자산 채굴 실태를 조사하는 좌담회를 열었다. 이날 좌담회의 구체적인 내용은 공개되지 않았으나, 쓰촨성 내 가상자산 채굴 현황에 대한 심도있는 보고가 진행된 것으로 알려졌다. 앞서 중국 국가에너지자원국 쓰촨성 지부는 “중앙 차원의 요청에 따라 쓰촨성 내 가상자산 채굴 관련 상황을 충분히 파악하기 위해 좌담회를 열게 됐다”고 밝힌 바 있다. 쓰촨성은 신장위구르자치구와 함께 중국 내에서 가상자산 채굴이 가장 활발하게 이뤄지는 지역으로 꼽힌다. 풍부한 수자원 덕분에 값 싼 전기를 공급받을 수 있기 때문이다. 이날 좌담회는 사실상 쓰촨성 당국이 가상자산 채굴 현황 파악을 시작으로 대대적인 단속에 나설 것임을 예고한 것으로 해석된다. 글로벌타임스는 “중앙 정부가 비트코인 채굴과 단속을 강화하겠다고 선언한 이후 지방자체단체가 관련 노력을 강화하고 있다”면서 “쓰촨성 관리도 채굴업자에 대한 더 많은 조치를 고심하고 있는 것으로 보인다”고 전했다. 지난달  21 일 중국 국무원 금융안정발전위원회는 류허 부총재 주재 회의에서 가상자산 채굴과 거래 행위에 대한 강력한 단속 의지를 밝혔다. 이에 같은 달  25 일 중국 네이멍구자치구는 가상자산 채굴 행위를 전면 금지하는 이른바 ‘암호화폐 채굴 행위 타격을 위한 8대 조치’ 초안을 발표했다. 규제안에는 가상자산 채굴업자 만이 아니라 땅을 빌려주거나 전기를 제공하는 등 해당 행위에 연루된 이들을 모두 처벌하겠다는 내용이 담겼다. 참여 개인과 기업을 ‘신용 불량 명단’에 올리겠다는 내용도 포함됐다. 전문가는 장기적으로는 중국에서 가상자산 채굴 행위 자체가 사라질 수 있다고 추측했다. 중앙 정부가 명시적으로 채굴장을 모두 폐쇄해야 한다고 밝히지는 않았으나, 이미 가상자산 시장에서는 중국 내 채굴 행위에 대한 비관론이 확산되고 있다는 설명이다. 디지털르네상스재단의 상무이자 비트코인 투자자인 카오인은 “많은 채굴업자들이 중국 정부의 강경 입장을 감지하고 캐나다 등 (채굴에) 우호적인 국가로 이전하고 있다”고 밝혔다. 손미정 기자 ▶환경적 대화기구 '헤럴드에코' ▶밀리터리 전문 콘텐츠 ‘헤밀’ ▶헤럴드경제 네이버 채널 구독 -  Copyrights  ⓒ 헤럴드경제 &amp;  heraldbiz.com , 무단 전재 및 재배포 금지 - \\t  // 본문 내용   \", \"   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t[머니투데이 더리더 홍세미 편승민 임윤희 기자] [[심층리포트-청년·초선 돌풍 어디까지]] start_block ━ 심층리포트① 여야, 초선 등 신예 정치인 목소리 커져…대선 향배 가를 수도 ━ end_block 젊은 정치인이 대세로 떠오르던 시절이 있었다. 김영삼 전 대통령( YS )이  1971 년 제7대 대통령 선거에 출마할 때 내건 슬로건은 ‘ 40 대 기수론’이다. 정권교체를 위해  40 대의 젊은 지도자가 필요하다는 것이다. ‘젊은 신민당’ 이미지를 내세운  YS  논리에 가세해 당시  45 세였던 김대중 전 대통령( DJ )과  48 세였던 이철승 전 의원이 대선에 뛰어들었다. 당시 신민당의 총재였던 유진산 전 총재는 이들을 향해 ‘입에서 아직 젖 비린내가 난다’는 의미인 ‘구상유취(口尙乳臭)’라고 비유하며 폄하했다. 2021 년 정치권도 당시와 비슷한 일이 벌어지고 있다. 국민의힘 전당대회에 나선 중진 의원이 신예 정치인을 두고 ‘예쁜 스포츠카’, ‘동네 뒷산’으로 비유했다. 국민의힘 전당대회에 출마한 나경원 후보는 지난달  24 일  CBS  라디오 ‘김현정의 뉴스쇼’에 출연, “이번 당 대표는 사실 멋지고 예쁜 스포츠카를 끌고 갈 수 있는 자리가 아니라 짐을 잔뜩 실은 화물트럭을 끌고 좁은 골목길을 가야 한다”고 말했다. 전당대회에 출마한 김웅 의원(초선·서울 송파갑), 이준석 전 미래통합당(국민의힘 전신) 최고위원, 김은혜 의원(초선·경기 성남분당갑) 등을 ‘예쁜 스포츠카’에 빗댄 것이다. 당대표에 출마하는 주호영 전 원내대표는 지난달  11 일  CBS  라디오 ‘김현정의 뉴스쇼’에서 ‘김웅 의원, 이준석 전 최고위원 등 젊은 초선급의 약진이 눈에 띈다’는 진행자 말에 “동네 뒷산만 다녀선 안 된다”며 “에베레스트를 오를 수 없다”고 했다. 그는 “설악산과 지리산 등 ‘중간 산’도 다닌 사람이 원정대장을 맡아야 한다”고 말했다. ▲국민의힘 이준석 당 대표 후보가 5월  25 일 서울 마포구 누리꿈스퀘어에서 열린 국민의힘 제1차 전당대회 비전스토리텔링 PT 에서 발표를 하고 있다./사진=뉴시스 ◇이준석 당대표 여론조사 1위…“野 쇄신 인물”  vs . “지나가는 바람” 국민의힘 당대표 후보로 나선 중진 의원들이 신예 정치인을 향해 연달아 견제구를 날리는 것은 여론이 이들에게 반응해서다. 우선  4.5  재보궐선거에서  20 대가 국민의힘을 지지한 게 승리의 요인으로 꼽힌다. 지난  4.7  보궐선거 방송 3사 출구조사에 따르면  20 대  55.3 %가 오세훈 국민의힘 후보를 찍었다. 이번 국민의힘 전당대회를 앞두고 이준석 전 최고위원이 당대표 여론조사 1위를 기록했다. 한길리서치가 쿠키뉴스 의뢰로 지난달  22 일 전국  1000 명을 대상으로 실시한 국민의힘 당 대표 지지도 여론조사에서 이 전 최고위원은  30.1 %로  17.4 %를 기록한 나경원 전 의원을  12.7 %p 앞섰다. 뒤를 주호영 의원이  9.3 %, 김웅 의원이  5.0 %, 김은혜 의원이  4.9 %, 홍문표 의원이  3.7 %, 윤영석 의원이  3.3 %, 조경태 의원이  2.8 %를 기록, 한자릿수 지지율을 보였다(포본오차는  95 % 신뢰수준에 ± 3.1 %포인트·자세한 내용은 중앙선거여론조사심의위원회 홈페이지 참조). 서울과학고와 하버드대를 졸업한 이 전 최고위원은 각종 방송 패널로 출연하며 인지도를 높였다.  26 살이던  2011 년 그는 새누리당 최연소 비상대책위원으로 발탁된 ‘박근혜 키즈’였다. 하지만 박 전 대통령을 포함, 당 지도부를 향해 쓴소리를 마다하지 않으면서 주목을 받았다.  2017 년 박 전 대통령 탄핵 사태 직후 새누리당을 탈당해 바른정당-바른미래당-새로운보수당을 거쳤다. 보수 정당의 합리적 보수 포지션으로  10 년 동안 꾸준히 길을 걸어왔다. 또  SNS 를 활용해 주요 정치인이면 피했을 주제인 젠더 이슈, 여성 징병제, 암호화폐 등과 같은 민감한 주제에 대해 가감 없는 의견을 밝혔다. 기성 정치인에 대한 실망, 그리고 쇄신·변화를 바라는 야권 지지자들의 바람이 이 전 최고위원을 향한 기대로 표출되고 있다는 분석이다. 국민의힘이 ‘도로 새누리당’으로 되지 않기 위한 ‘변화의 인물’로 떠올랐다는 것. 그러나  20 대 남성 표심 몰이에 집중하면서 젠더 갈등을 부추기는 ‘노이즈 마케팅’을 활용해 인지도를 높였다는 비판도 있다. 이 전 최고위원은  4·7  재보선 이후 ‘여성할당제 폐지’를 내세우며 남녀 편가르기 논란의 중심에 섰다. 이와 더불어 이 전 최고위원에 대한 당 안팎의 해석은 엇갈린다. 국민의힘 복당을 선언한 홍 의원은 지난달  25 일 자신의  SNS 에 이 전 최고위원을 겨냥, “한때 지나가는 바람”이라며 “안타까운 몸부림으로 국민들이 보고 있다”고 했다.  이어 “대선을 불과  10 개월 앞둔 이 중차대한 시점에 또다시 실험 정당이 될 수는 없다”고 썼다.  이에 대해 하태경 의원은  SNS 를 통해 “홍준표 의원님, 보수의  2030 세대 확장 훼방 놓지 마십시오”라며 “보수에서는 꿈조차 꾸기 어려웠던  2030 세대 확장의 희망을 현실로 만들어낸 후배 정치인에게 박수를 보내도 모자랄 판에, 새로운 지지층을 지나가는 바람이라고 폄하하고 있다”고 지적했다. ▲더불어민주당  21 대 초선의원들이 4월 9일 오후 국회 소통관에서 재보선 결과에 대한 초선의원들의 공동 입장문 발표하고 있다./사진=뉴시스 ◇與 초선, 쇄신안 밝혔지만…문자폭탄으로 위축 민주당에서도 초선 의원들이 모임 ‘더민초’를 만들며 목소리를 내기 시작했다. 민주당 오영환, 이소영, 전용기, 장경태, 장철민 의원 등 초선 5인은  4.7  재보선 참패 직후 ‘조국 사태’ 등 자체 패인 등을 담은 입장을 내놓으면서 당의 쇄신 필요성을 강조했다.  또 문재인 대통령이 임혜숙·박준영·노형욱 장관 후보자에 대한 청문 보고서 재송부 요청을 한 다음 날인 지난달  12 일 ‘더민초’ 소속 의원  40 여 명이 화상 회의를 열고 “장관 후보자 가운데 최소 한 명 이상은 낙마시켜야 한다”고 밝혔다. 청와대도 이내 “무겁게 받아들인다”며 재고에 들어갔고, 박준영 해수부 장관 후보자가 끝내 자진 사퇴했다.  민주당 초선의원들이 모임을 만들고 목소리를 내고 있지만 당의 변화나 돌풍으로 이어질지는 미지수다.  21 대 국회는 어느 때보다 초선이 많다.  300 명 가운데 절반을 넘는  152 명에 이른다. 민주당의  174 명 중 절반에 가까운  81 명이 초선이다. 수는 많지만 존재감이 약하다는 게 중론이다.  특히 초선 5인이 민주당 자성 목소리를 내자 당 강성 지지자들의 ‘문자 폭탄’을 받아 이들의 활동이 더욱 위축될 수 있다는 의견도 나온다. 이들은 당내 주류인 친문 세력을 비판하는 모습으로 확산되자 당내 강성 지지자들로부터 ‘초선5적’, ‘초선족’으로 비판을 받으며 파장을 일으켰다. 이들은 지난달  11 일 다시 성명서를 내고 “ 2030  청년 세대가 느낀 실망감을 기대감으로 바꾸기 위해 저희가 고민하고 노력해야 하듯 민주당은 다양한 세대와 계층의 국민 목소리를 잘 듣고 더 잘 담아내는 정당이 돼야 한다”고 강조했다.  초선 의원들의 목소리를 당 지도부가 귀담아 듣지 않는 것도 문제라고 지적된다. 재보선 후 4차례 전체모임을 갖고 ‘쇄신위 구성’과 ‘성 비위 사건에 대한 진정성 있는 사과’, ‘당내 민주주의 강화’ 등을 요구했지만 당헌·당규 재개정 등 초기 문제제기는 반영되지 않았다. 최창렬 용인대학교 교수는 “초선 5인이 지난 재보궐 이후 내놓은 반성문과 혁신안이 당 지도부에게 바로 제압당했다”며 “그런 쇄신안을 받지 않는다는 것은 민주당은 여전히 자신들의 진영에 갇혀 있다는 것”이라고 말했다.  최 교수는 “국민의힘 당대표 여론조사에서 이준석이 1위한 것은 소위 ‘수구정당’이라고 불렸던 당이 변하고 있다는 상징”이라며 “송영길 당대표가 되고 나서도 부동산 정책이나 특별하게 개혁한다는 인식을 주지 않고 있다. 민주당이 개혁 메시지를 주지 않으면 변할 수 없다”고 했다. ▲송영길 더불어민주당 대표가 5월  25 일 서울 영등포구 무중력지대 영등포에서 열린 국민소통·민심경청 프로젝트 ‘서울·부산 청년과의 간담회’에서 발언하고 있다./사진=뉴시스 ◇초선 활동 ·2030 표심 중요한 이유 그럼에도 이들의 ‘반란’이 여의도 정치권에 적잖은 충격을 주고 있는 것은 사실이다. 초선들은 통상 당의 쇄신·개혁 역할을 맡았다. 계파나 기득권에서 상대적으로 자유로운 초선의원들의 ‘초심’이 당의 변화를 이끄는 동력이 됐다. 민주당의 천·신·정(천정배·신기남·정동영), 한나라당의 남·원·정(남경필·원희룡·정병국)은 대표적인 소장파로 기록된다.  2000 년 천신정은 정풍운동을 주도, 새천년민주당의 기득권이었던 ‘동교동계 원로의 2선 후퇴를 이끌었다. 이들은  2003 년 참여정부 출범과 열린우리당 창당의 주역이다. 한나라당의 남·원·정(남경필·원희룡·정병국)은 소신파로 당 쇄신을 주도,  2004 년 총선을 앞두고 천막당사로 당 승리를 이끌어  2007 년 정권탈환의 기반을 마련했다. 이들이 속한  18 대 국회 한나라당 초선모임인 민본 21 은 이명박정부를 겨냥, 쓴소리와 개혁정책을 쏟아냈다. 이처럼 초선의 쇄신과 개혁 목소리는 향후 정치 판도를 바꿀 수 있다. 특히 현재 정치권의 시곗 바늘은 내년 대선을 향해 있다. 여야의 신예 정치인이  2030 에게 어떤 메시지를 주느냐에 따라 대선 향배가 달라질 수 있다는 목소리도 나온다.  최 교수는 “다음 대선에서는  2030  표심을 잡는 정당이 이길 가능성이 많다”며 “이 세대는 지금 여당이나 야당을 지지한다기보다 중도층인 경우가 더 많다”고 말했다.  이어 “이들은 급격한 변화를 원한다. 이준석이 당대표 1위한 것도 정치권의 변화를 원했기 때문”이라며 “어느 정당이 변화와 개혁 메시지를 먼저 주는지에 따라 민심이 반응 할 것”이라고 밝혔다. 홍세미 기자  semi4094 @ mt.co.kr start_block ━ 초선이 이끄는 선거열차, ‘ 2030’  태워라 ━ end_block [심층리포트②]내년 대선과 지방선거 앞두고 캐스팅보트 쥔  MZ 세대 공략 사활 김종인 국민의힘 비대위원장이 지난해  12 월 6일 오후 서울 영등포구  KNK 디지털타워에서 열린 '청년국민의힘 창당대회'에서 축사를 하고 있다./사진=뉴스1 정치판에 여야를 막론하고 ‘초선 돌풍’이 몰아치고 있다.  21 대 국회의원  300 명 중 초선 의원은 절반이 넘는  151 명( 50.3 %)이다. 더불어민주당은 지난  4.7 재보선 참패 이후  2030 의원들의 반성문에 이어 여당내 초선 모임인 ‘더민초’가 결성됐다. 지난 4월  22 일 더민초는 여당 지도부를 향해 쇄신위원회를 구성하고 근본적이고 지속적인 쇄신안을 마련할 것을 요구했다. 이날 고영인 더민초 운영위원장은 국회 소통관에서 기자회견을 열고 “민심은 언제나 옳다. 저희가 부족했다”며 “국민께서 주신 엄중한 경고, 깊이 새기고 혁신하기 위해 뭉쳤다”고 밝혔다. 더민초는 지속적인 당 쇄신을 위해 △당내 쇄신위원회 구성 △당 지도부의 박원순·오거돈 성폭력 피해자에 대한 진정성 있는 사과 △ 지역위원회별 ‘쓴소리 경청텐트’ 설치와 ‘세대별 심층토론회’를 통한 국민 소통 △ 당이 주도권을 갖는 당정청 관계 △입법·정책 결정에 앞선 의원 간 집단 토론 활성화 등을 요구했다. 지난달 6일 여의도 전국경제인연합회에서 열린 ‘더민초 쓴소리 경청  20 대에 듣는다’ 간담회에서 한  20 대 남성 참석자는 “박근혜 정부 국정농단 사태 당시 정유라 씨 특혜 등에 분노해 촛불집회에 열심히 참석했다”면서 “하지만 윤미향, 조국 사태 등으로  20 대들은 민주당에 엄청나게 실망했다. 코로나 19 가 아니었으면 촛불집회 대상이 민주당이었을 것”이라고 꼬집었다. 또한, 지난달  12 일 더민초는 청와대에 야당이 부적격 판정한 임혜숙 과학기술정보통신부, 박준영 해양수산부, 노형욱 국토교통부 장관 후보자 중 최소한 1명에 대한 부적격 의견을 내야한다고 요구했다. 이후 박준영 후보자는 입장문을 통해 자진사퇴했다. 국민의힘은 차기 당대표를 뽑는 전당대회를 앞두고 있는 가운데 신진세력의 돌풍이 심상치 않다. 지난달  17 일 발표된 국민의힘 차기 당대표 적합도 여론조사에서 이준석 전 미래통합당 최고위원은  20.4 % 지지를 얻으며 선두에 서는 기염을 토했다. 여론조사기관  PNR 이 머니투데이 더 300 과 미래한국연구소 의뢰로 실시한 조사(표본오차  95 % 신뢰수준에 ± 3.1 %포인트)결과, 이 전 최고위원은  20.4 % 지지율을 보였고 그 뒤를 4선의 나경원 전 의원이  15.5 %로 바짝 쫓았다. 이어 5선 주호영 의원( 12.2 %), 초선 김웅 의원( 8.4 %), 4선 홍문표와 5선 조경태 의원이 각각  4.3 %로 뒤를 이었다. 또한 처음 여론조사 대상에 올랐던 초선 김은혜 의원도  3.5 %라는 의미있는 결과를 얻었다. 여론조사의 자세한 내용은 중앙선거여론조사심의위원회 홈페이지를 참고하면 된다. 당초  1970~1980 년대 초선 및 원외 인사들이 출사표를 낼 때만 해도 당 안팎으로 회의적인 시선이 적지 않았다. 이번에 선출되는 당대표는 내년 대선을 이끌어나가야 하는 중차대한 임무를 맡아야 하기 때문이다. 하지만 당의 영파워는 ‘혁신과 쇄신’을 강조하면서 연일 돌풍을 일으키고 있다. 여론조사 지지율 1위에 오른 이 전 최고위원은 한 인터뷰에서 “내년 대선의 최대 승부처는 ‘ 2030 세대’로 대표되는 젊은 유권자가 될 것”이라며 “당 대표가 되면  2030 세대를 껴안을 방안을 적극 모색하겠다”고 말했다. 이처럼 이 전 최고위원은 특히  MZ 세대로부터 굳건한 지지를 확보하면서 상승세에 더욱 박차를 가하고 있다. ◇ MZ 세대 그들은 누구인가 한국전쟁 이후 태어난  1955 년 ~1963 년생은 ‘베이비붐 세대’,  1960 년대에 태어나  1980 년대 대학을 다니며 민주화 투쟁에 앞장선 세대는 ‘ 386  세대’라 불린다. 이후  1990 년대에는 ‘무언가로 정의할 수 없다’는 의미로 ‘X세대’가 청년층을 가리키는 이름이었다.  요즘 청년세대의 이름은 그럼 무엇이냐?  1980 년 ~1994 년 사이에 태어난 ‘밀레니얼 세대’와  1995 년 이후 태어난 ‘Z세대’를 합쳐  MZ 세대라고 부른다. MZ 세대의 가장 큰 특징은 ‘공정’에 민감하다는 것이다. 노력한 만큼 대가를 받고 기존 사회의 차별을 받는 것을 절대 가만히 두고보지 않는 세대다.   MZ 세대는 직장에서도 당당히 자기 몫을 요구하고, 대기업을 혼쭐내는 세대다. 수직적 조직문화에 익숙한 기성세대와 달리 직장에서 당당하게 목소리를 내는 데 주저하지 않는다. 그렇기에 워라밸(일과 삶의 균형)을 무엇보다 중시하고, 공정한 평가 기준을 요구하면서 기업 문화마저 바꿔나가고 있다. 올해 초  MZ 세대는 대기업 성과급 불만을 직장인 익명게시판인 ‘블라인드’에 게시하며 불공정 사회적 이슈로 키웠고, 생산직 위주 노조와 별도로 최초의 사무직 노조를 결성하기에 이르렀다.  31 살의 직원이 노조를 만드는 데는 불과 일주일밖에 걸리지 않았고, 가입 인원은  4000 명까지 늘었다. 이런 움직임은 다른 대기업들까지 확산되면서, 젊은 층을 중심으로 한 노조 설립이 속속 이어지고 있다. 또한, 이들은 디지털 환경에서 성장한 디지털 네이티브기에 오프라인이 아닌 온라인,  SNS 로 뭉친다. 재테크에도 관심이 많아서 카카오페이, 비트코인과 같은 핀테크 서비스에도 익숙하다. 지난해부터 올해까지 코로나 19 로 인해 불거졌던 동학개미운동, 코인광풍의 주축도 바로  MZ  세대다. 이들의 재테크 전략은 부동산시장까지 번지면서 부동산계의 큰손으로까지 떠오르고 있다. ◇ MZ 세대가 선거판을 흔들다 지난  4.7  재보궐 선거에서  MZ 세대의 표심은 여야의 희비를 갈랐다. 그동안 진보여당의 핵심 지지층으로 여겨졌던  MZ 세대는 재보선에서는 완전히 다른 모습을 보인 것이 여당 참패의 원인이었다. 진보와 보수의 이분법적인 사고를 깨고, 현안별로 소신 있는 목소리를 내고 있는  MZ 세대는 높은 투표율을 보이며 지난 서울, 부산 재보궐 선거의 판세를 뒤흔들었다. 지난 선거 당일 방송3사 출구조사 결과에 따르면 서울  20 대 남성 유권자의  72.5 %는 오세훈 국민의힘 당시 후보에게 투표했다.  30 대 남성 역시  63.8 %가 오 후보에 표를 던졌다고 응답해 박영선 더불어민주당 후보( 32.6 %)에 투표했다는 응답의 2배에 육박했다. 반면  20 대 여성에서는 박 후보가  44.0 %로 오 후보( 40.9 %)보다 지지율이 높게 나왔는데 이는 서울시장 보선이 치러지게 됐던 고 박원순 전 서울시장의 성추문을 남성들은 내로남불로, 여성들은 남성 권력 문제로 받아들였던 것으로 분석됐다. 결국 극심한 취업난과 계속되는 집값 급등으로 내 집 마련이 요원해진 상황 속에서 ‘한국토지주택공사( LH ) 사태’, ‘인천국제공항 사태’ 등 공정성 논란이 계속되자 ‘공정’의 가치를 둔  MZ 세대의 분노가 폭발해버렸다. 송영길 더불어민주당 대표가 지난달  17 일 국회에서 성년의날을 맞아  20 대 청년들과 간담회를 갖기에 앞서 기념촬영을 하고 있다./사진-뉴스1 ◇ MZ 세대, 내년 대선서 ‘캐스팅 보트’로 떠올라 여당의 참패, 야당의 압승으로 끝난  4.7  재보궐 선거에서 가장 주목을 받았던  MZ 세대는 이제 내년 대선의 ‘캐스팅 보트’로 주목받기 시작했다. 불과 4년 전  19 대 대통령 선거에서 문재인 당시 더불어민주당 후보를 당선시킨 주역이  MZ 세대였다. 하지만  4.7  재보궐선거에서 이들은 국민의힘의 손을 들어줬다.  MZ 세대가 이슈에 따라 자기 목소리를 낼 뿐, 특정 정당이나 인물을 지지하지 않는다는 사실을 여실히 보여줬다. 두 번의 선거 결과에서 볼 수 있듯이, 이번 재보선에서  MZ 세대가 국민의힘을 선택했다고 해서 다음 대선에서도 국민의힘에 투표할 것이라는 보장은 없다. 이들은 민주당 지지를 철회했던 것이지 국민의힘을 온전히 지지하게 된 것은 아니기 때문이다. 선거 후 한국리서치·코리아리서치·케이스탯·엠브레인 등 여론조사 전문업체 4곳이 함께 실시한 전국지표조사( NBS )에서 국민의힘이 승리한 주된 요인을 묻는 질문에 “민주당이 잘못해서”라는 답변( 61 %)이 가장 높았다(4월  12~14 일 전국 만  18 세 이상 남녀  1010 명 대상, 표본오차  95 % 신뢰수준에 ± 3.1 %포인트). 또 한 가지 흥미로운 여론조사 결과도 있다. 한국갤럽이 지난 4월  13~15 일 전국 만  18 세 이상  1005 명에게 차기 정치지도자 선호도를 물은 결과,  20 대와  30 대는 가장 선호하는 정치지도자로 여권 대선주자인 이재명 경기지사를 꼽았다. 이 지사는  20 대와  30 대에게 각각  15 %,  16 % 지지를 얻으며 여론조사 전체 1위인 윤석열 전 검찰총장의  2030 세대 지지율(7%,  14 %)을 앞섰다. 이 지사의 경우 기본소득 등의 이슈를 선점하면서 청년 층의 지지를 얻고 있으며, 이 지사 특유의 사이다 화법과 강한 행정 추진력도 지지자들을 끌어들이는 요인이 되고 있다. ◇여야 특명,  MZ 세대를 사로잡아라 여야는 내년  3.9 대선과 6월 지방선거를 앞두고  MZ 세대의 마음을 사로잡기 위해 사활을 걸고 나섰다. 통계청에 따르면  MZ 세대는  2019 년 기준  1696 만 명으로 우리나라 전체 인구의  32 %를 차지한다. 보궐 선거가 끝난 후 당을 재정비한 민주당은 성난 부동산 민심을 의식한 듯 “정부가 실시한 부동산 정책이라도 문제가 있다면 과감히 바꾸겠다”고 밝혔다. 민주당은 부동산특별위원회를 설치하고 관련 정책의 전반적인 검토에 착수했다. 민주당은 당 부동산특위에서 논의 중인 청년·신혼부부 부동산 대출규제 완화가 반전카드가 될 것이라고 기대하고 있다. 무주택 청년·신홍부부에 한해 집값의  90 %까지 대출할 수 있도록 하면 부동산 민심이 돌아설 것이라는 계산이다. 송영길 민주당 대표는 “청년·신혼부부의 경우 집값의 6%만 있으면 자기 집을 가질 수 있는 금융구조를 완성했다”고 강조했다. 국민의힘은 차기 당대표를 뽑는 데 있어 초선 당대표론이 급속히 퍼지고 있다. 일각에서는 국민의힘에 지지를 보낸  2030 세대를 붙잡기 위한 전략이라는 분석이 나왔다. 국민의힘 현역 의원  101 명 중 초선의원은  56 명으로 과반이 넘기에 초선 당대표가 전혀 실현 불가능하지 않다. 지지율 1위를 달리고 있는 이준석 전 최고위원은 “이번에 서울시장 보궐선거에서 보여줬듯이 전통적 보수층에 더해  2030 층을 끌어안지 못하면 선거에 이길 수 없다”며 변화를 추구해야 한다고 강조했다. 한편 지난달  20 일 당 대표 출마를 선언한 나경원 국민의힘 의원은 “경륜과 패기를 넘어선 지혜와 정치력, 결단력의 리더십을 요구한다”며 지지를 호소했다. 나 전 의원은 “ MZ 세대의 현안부터 치매 어르신들의 아픔, 세종시 국회 이전부터 가덕도 신공항 문제, 배달 근로자의 안전부터 기업의 경영 자율성 회복까지 다양한 이슈에 대해 스마트한 답을 내놓을 수 있는 유능한 정당으로 거듭나겠다”고 강조했다. 편승민 기자  carriepyun @ mt.co.kr start_division ━ end_division ‘꼰대정치’ 엎고 세대교체 마중물 될까 [심층리포트③]서열 중심 당내 기득권 걸림돌…민심 어루만질 비전 제시해야 2022 년 대선을 앞두고 당 쇄신을 외치며 존재감을 뽐내고 있는 초선들은 세대교체의 마중물이 될 수 있을까? 이종근 시사평론가는  21 대 국회 초선들의 약진에 대해 “억눌려 있다가 손을 놓으면 굉장히 크게 반등하는 스프링 효과”라고 설명했다. 그러면서 “사회에서 중추적인 역할을 하는  40 대가 정치권에서는 유독  86 세대에 눌려 자기 목소리를 내지 못하고 있었다”고 했다. 최창렬 용인대 교수는 “지나친 선수와 서열 위주의 한국정치 틀이 깨져나가는 조짐으로 봐야 한다”며 “과거의 기득권, 낡은 정치에 대한 국민들의 실증에 대한 반영”이라고 말한다. 그러면서 “과거에는 초·재선들이  40 대 기수론을 앞세워 개혁의 목소리를 많이 냈었는데 언제부터인가 지나치게 숨겨져 있었다. 정상화 과정이라고 본다”고 평가했다. 최 교수가 언급했듯 과거에도 정치권에 초ㆍ재선이 전면에 나서 당내 개혁을 이끌었던 사례는 심심치 않게 찾아볼 수 있다.   2000 년 새천년민주당에서는 당시 ‘천·신·정’(천정배 신기남 정동영)을 필두로 한 초재선 그룹이 당의 실세로 불린 권노갑 민주당 최고위원에게 2선 퇴진을 요구했다. 권 최고위원은 당시 보름 만에 사퇴했다. 소위 ‘보스 중심’ 정당문화에서 이 같은 모습은 일대 파장을 일으켰다. 정풍운동은 당시 민주당 내 주류였던 동교동계의 2선 후퇴를 이끌어내 ‘정치 지형 변화’를 만들었다. 이는 노무현 대통령 당선 및 열린우리당 창당으로까지 이어졌다. 진보당에 개혁을 이끈 ‘정풍운동’이 있었다면 보수당에는 ‘남·원·정 트리오’가 있었다.  1997 년 대선에서 패한 한나라당에는 당 쇄신을 주장하는 소장파가 부상했다.  1999 년에는 ‘미래연대’라는 모임이 만들어졌고,  2000 년  16 대 국회에서 재선한 남경필, 정병국, 원희룡은 미래연대에서 의기투합했다. 세 사람은 ‘남·원·정 트리오’로 불리며 보수정당의 쇄신세력을 대표하는 이름이 됐다. 차떼기 사건으로 보수 정당이 위기에 빠지자  17 대 총선 당시 ‘천막당사’를 가장 먼저 쳤던 것도 이들이다. 2002 년 대선에서 재차 패한 뒤에는 개혁의 선봉에 서며 당을 지탱하는 데 중심 역할을 하며  2007 년 정권탈환의 기반을 닦았다. 남·원·정 트리오 역시 ‘내부 총질’이라는 비난도 받았지만 이들의 따끔한 지도부 비판은 내부 정화작용을 했다. ◇정치 세대교체론의 대명사 영국의 토니 블레어 김종인 전 위원장은 지난달 언론과 인터뷰에서 이달 치러지는 국민의힘 전당대회에 당대표로 출마한 김웅 의원과 이준석 전 최고위원을 향해 “영국 같은 데를 보면 노동당의 토니 블레어의 출현이나 보수당의 캐머런의 출현이나 그 사람들이  30 대에 출현한 사람들”이라고 말했다. 김 전 의원장은 “그런 것을 우리도 한번 생각해볼 필요가 있지 않냐”며 초선 당대표론에 힘을 실어주기도 했다. ‘제3의 길’을 내세우며 등장한 영국의 토니 블레어 총리는 정치판의 세대교체를 언급할 때 단골로 거론되는 인물이다. 영국은 당시에  18 년간 보수당이 장기 집권을 하고 있었고 노동당은 극좌로 흐르며 집권과 멀어지고 있었다. 노동당 당수에 오른 토니 블레어는 ‘신노동당’( New   Labour )이라는 브랜딩을 통해 고든 브라운과 함께 영국 노동당의 우클릭을 주도했다.  90 년대 보수당 정권 시절부터 이어진 노후화된 제조업 탈피 및 금융, 문화 산업 중심으로의 체제 개편을 계승하고 신자유주의적인 정책을 대거 받아들였다. 1997 년부터  2005 년까지 3차례의 총선을 승리로 이끌었으며, 역대 노동당 최장수 내각, 전후 유일하게 영국 총리를  10 년 넘게 역임했다. 이 외에도  39 세 때 보수당대표가 돼 당을 대대적으로 뜯어고친 뒤 5년 후 정권까지 탈환했던 영국의 데이비드 캐머런,  38 세에 기성 정당에 대항해 새로 당을 만들어 이듬해에 정권을 거머쥔 프랑스의 에마뉘엘 마크롱 대통령 등이  30 대 기수로 정치판을 뒤흔든 기록을 가지고 있다. ◇여야 초선들 당심 넘어 시대정신 담은 콘텐츠 제시해야 “민주당 혁신의 주체가 되겠다”고 선언한 더불어민주당의  50 여 명 초선의원들은 민심보다 혹독한 당심을 뛰어넘어야 한다. 국민의힘 역시 전당대회에 출마를 밝힌 초선의원들과 중진 간에 불협화음을 통해 당내 기득권층과의 마찰을 고스란히 드러냈다. 진보당과 보수당의 초선들은 당 쇄신이라는 공통 미션을 가지고 기득권층과 맞붙었다. 전문가들은 초선들이 실질적인 정치 변화를 이뤄내기 위해선 당 권력에도 저항하며 민심에 맞는 지속적인 문제 제기와 구체적 비전 제시에 나서야 한다고 강조한다. 이종근 시사평론가는 세대교체의 가장 큰 걸림돌로 ‘꼰대정치’를 꼽았다. 이 평론가는 “내용을 가지고 비판하는 게 아니라 나이가 몇이야 하는 대응이 바로 꼰대정치”라고 말했다. 이어 “꼰대정치가 사려져야 세대 간에 바람직한 충돌이 일어난다”고 말했다. 그러면서 초선들에게는 “시대정신을 담은 콘텐츠를 제시해야 민심을 얻을 것”이라고 조언했다. 최창렬 용인대 교수는 “국민적 지지와 당심은 다를 수 있기 때문에 초선들이 당원들의 지지를 받는 데 애로점이 있을 것”이라며 “그런 정당문화를 돌파하고 기득권 정치를 타파하기 위해서라도 강한 메시지를 내야 한다”고 강조했다. 또 “젊다는 것만 강조할 것이 아니라 구체적인 부동산 정책이나 빈부 격차의 문제 해법, 백신 공급 같은 국민들이 공분을 사고 있는 문제에 정확한 입장과 대안을 제시해야 한다”고 말했다. 초선들의 가장 큰 걸림돌로 당내 기득권층을 지목하는 목소리가 커지자 일부 중진들이 응원 메시지를 내며 초선에 힘을 실어주고 있다. 보수진영의 원조 소장파인 원희룡 제주도지사는 지난달  24 일 자신의 페이스북에서 “젊은 바람이 전당대회를 흽쓸고 있다”며 “이 바람의 동력은 변화에 대한 열망”이라고 말했다. 원 지사는 또 젊은 돌풍이 중진의 변화도 몰고 올 것이라면서 “중진들까지 변화해야 우리 당이 더 큰 변화로 국민에게 다가갈 수 있다”며 “중진은 그대로 있고 초선만 바뀌어서는 성공으로 평가받지 못한다”고 지적했다. 오세훈 서울시장 역시 국민의힘 전당대회를 위해 열린 토론회를 보고 지난달  23 일 페이스북에 “방금 전 0선, 초선들이 자체적으로 벌인 토론회를 유튜브로 봤다”며 “발랄한 그들의 생각과 격식 파괴, 탈권위적 비전을 접하면서 우리 당의 밝은 미래를 봤다”고 말했다. 특히 “정치권 공식대로 예상 가능한 결과라면 기대감도 매력도 물거품처럼 사라질 것”이라면서 “유쾌한 반란이 손에 땀을 쥐게 하는 게임으로 이어진다면, 기대감을 한껏 자극할 것”이라고 했다. 이어 “유쾌한 반란의 주인공, 그런 대표가 선출되기를 간절히 바란다”고 이들에게 지지의사를 밝혔다. 임윤희 기자  yunis @ mt.co.kr ▶본 기사는 입법국정전문지 더리더( the   Leader ) 6월호에 실린 기사입니다. article_split 홍세미 편승민 임윤희 기자  theleader @ mt.co.kr ▶부동산 투자는 [부릿지] ▶주식 투자는 [부꾸미TALK] ▶부자되는 뉴스, 머니투데이 구독하기   &lt;저작권자 ⓒ '돈이 보이는 리얼타임 뉴스' 머니투데이, 무단전재 및 재배포 금지&gt; \\t  // 본문 내용   \", '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}        지난해 9월 독일 \\'기가팩토리 베를린\\' 공장을 방문한 일론 머스크 테슬라  CEO .  AP =연합            테슬라가 전기차 보급이 가장 빠른 서유럽 시장에서 폴크스바겐에 역전당해 1위 자리를 내줬다. 글로벌 자동차조사업체 슈미트 오토모티브 리서치에 따르면 최근  12 개월( 2020 년 5월 ~2021 년 4월)간 독일을 포함한 서유럽  18 개국에 등록된 테슬라 차량은  10 만 2500 대이다. 테슬라가 이처럼 월 평균 판매량이 1만대 안팎에 머물러 있는 사이 전 세계 자동차시장 1위인 폴크스바겐의 순수전기차( BEV )는  20 만 6400 대가 등록돼 월평균 2만대 가량이 판매됐다.          3일 현지 언론 등에 따르면 테슬라와 폴크스바겐의 판매량은 2년 전인  2019 년과 비교하면 완전히 뒤집힌 결과다. 이 기간 테슬라는  10 만 9700 대, 폴크스바겐  BEV 는 4만 6500 대가 팔렸다. 테슬라는  2019 년 보급형 전기차 모델 3를 유럽 시장에 선보인 이후 시장을 주도했지만, 지난해 폴크스바겐이 전기차 전용 플랫폼( MEB )을 장착한  ID.3 를 내놓으면서 테슬라를 따라잡기 시작했다.         폴크스바겐은 지난 4월 진일보한  ID·4 를 내놓으며, 더 탄력이 붙었다. 리서치는  ID.3 와  ID.4 와 같은 스포츠유틸리티차량( SUV )과 크로스오버가 \"유럽 전기차 시장을 지배하고 있다\"고 덧붙였다. 유럽 소비자는 고급 세단이나 덩치 큰  SUV 보단 실용성 있는 차를 선호하는 편인데, 전기차 보급이 확대되면서 폴크스바겐·르노·피아트의 크로스오버형 전기차 판매가 늘고 있다고 설명했다.           제조사별 유럽 전기차 판매. 그래픽=김영옥 기자  yesok @ joongang.co.kr            또 다른 조사기관  EV 볼륨즈의 최근  12 월간 서유럽시장 전기차 판매 대수는 테슬라가 기존 완성차업체에 밀리고 있다는 점을 보여준다. 이 기간 테슬라는 폴크스바겐( 21 만 6009 대)에 1위를 내준 것은 물론 르노·닛산 얼라이언스( 15 만 6494 대)·스텔란티스( 11 만 2640 대)·현대차그룹( 10 만 9095 대)에 이어 5위( 10 만 3346 대)에 머물렀다.         테슬라 전기차는 최근 중국에서도 신통치 않다. 중국자동차공업협회에 따르면 테슬라 모델 3은 올해( 1~4 월) 중국 시장에서 7만 3296 대를 팔아  SMGW 의 우링홍광 미니( 12 만 5925 대)에 크게 뒤졌다. 우링홍광 미니의  GM 과 상하이차·우링의 합작법인이 만든 초소형 전기차다. 또 중국 시장에서 생산돼 판매되는 모델 Y(2만 1819 대)는  BYD 의 한(2만 7101 대), 장성기차의 오라  R1 (2만 2371 대), 체리차의  eQ1 (1만 8990 대)보다 밀렸다. 한국자동차산업협회 관계자는 \"중국에서 신형 전기차가 대거 출시되며 시장에서 차지하는 테슬라 전기차의 비중이 줄었다\"고 말했다.             올해 중국시장 모델별 전기차 판매. 그래픽=차준홍 기자  cha.junhong @ joongang.co.kr            서유럽과 중국은 가장 큰 전기차 시장이다. 모든 완성차업체가 전기차의 기술력과 마케팅을 쏟아붓는 전장이다. 서유럽은 현대차·기아를 비롯한 기존 완성차업가 앞다퉈 신형 전기차를 출시하고 있고, 중국은 상하이차 ·BYD 등 기존 전기차 강자에 니오·샤오펑·리샹 등 스타트업 등이 각축을 벌이는 중이다. 반면  2010 년 모델 S를 선보인 이후 글로벌 전기차 시장을 선점한 테슬라의 시장점유율은 점차 줄어들고 있다.           테슬라는 \\'오토 파일럿\\'과 같은 반자율 주행, 소프트웨어 실시간 업데이트( SOTA ) 등 기존 완성차업체보다 앞선 기술을 통해 시장을 선점했다. 그러나 \\'단차(차체 이음새의 틈)\\' 등 고질적인 품질 문제, 부실한 사후관리( AS ), 다른 브랜드보다 비싼 가격 등은 단점으로 꼽힌다. 최근엔 일론 머스크 테슬라  CEO 가 트위터로 사업과 관계없는 암호화폐와 관련해 \\'입방정\\'을 떨어 테슬라 브랜드에 대한 전 세계 소비자의 반감이 늘었다.         전문가들은 테슬라의 성패는 지금의 판매 대수보단 \"미래에 있다\"는 시각이다. 고태봉 하이투자증권 리서치센터장은 \"연말 기가팩토리 베를린과 내년 기가팩토리 텍사스가 가동을 시작하면 판매 대수는 늘어날 것\"이라며 \"테슬라는 단순히 차 판매가 아니라 향후 \\'자율주행( Full   Self   Driving )\\' 구독서비스, 차량 공유 등을 통해 이익을 창출하겠다고 한 만큼 마진이 박해도 전기차 보급에 치중할 것\"이라고 말했다. 다만 \"각 국의 규제 등 수많은 난관을 뚫고 실제로 그런 세상을 구현할 지는 지켜봐야 한다\"고 덧붙였다.         기가팩토리 베를린은 지난해 9월, 테슬라가 배터리데이에서 밝힌 \"2만 5000 달러(약  3000 만원) 전기차\" 생산기지로 유력한 곳이기도 하다. 유럽 소비자를 겨냥한 B세그먼트(소형 차) 전기차에 새로운 배터리를 장착할 것으로 관측된다. 테슬라는 배터리데이 당시 \"향후  2~3 년 내\"에 2만 5000 달러 전기차를 선보이겠다고 발표했다. 지난 1월 일론 머스크  CEO 는 자신의 트윗 계정에 연말  \\'AI (인공지능) 데이\\'가 있을 것이라고 예고하기도 했다. 업계는 자율주행 기술 관련 내용이 발표될 것으로 예상했다. 테슬라는  2030 년 전기차  2000 만대를 보급하겠다고 했다. 폭스바겐의 2배 규모다.    김영주 기자  humanest @ joongang.co.kr   ▶  그가 들려주는 이야기, 이상언의 \\'더 모닝\\' ▶  건강한 주식 맛집, 앤츠랩이 차린 메뉴 ▶  \\'실검\\'이 사라졌다, 이슈는 어디서 봐? ⓒ중앙일보( https : / / joongang.co.kr ), 무단 전재 및 재배포 금지 \\t  // 본문 내용   ']print(len(naver_news_title[0]))print(len(naver_news_content[0]))1818크롤링 결과 저장하기.with open(\"naver_news_title.pk\", \"wb\") as f:    pickle.dump(naver_news_title, f)    with open(\"naver_news_content.pk\", \"wb\") as f:    pickle.dump(naver_news_content, f)‘w’ - 쓰기용으로 파일 열기‘r’ - 읽기용으로 파일 열기ex) f = open(‘myfile.txt’,’w’) #파일 열기f.write(‘my text..’) # 파일 쓰기f.close() #파일 닫기파일을 열 때는 기본적으로 with 문을 통해 open() 내장 함수를 호출하는 것이 권장됩니다. with 문을 사용하지 않을 경우, 파일 닫기를 스스로 해줘야 해서 불필요하게 코드가 지저분해지기 때문입니다.",
        "url": "/navernews-crawling"
    }
    ,
    
    "virtualshoping-data": {
        "title": "가상 쇼핑몰 고객 주문 데이터(컬럼,로우) 확인하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  가상 쇼핑몰 고객 주문 데이터 파악하기          현재 상황(데이터로 부터) 파악      모델 수립 혹은 목표 설정      데이터 셋  온라인 리테일 사이트의 2010/12 - 2011/12간의 주문 기록 데이터  약 500,000건의 데이터  데이터 출처: UCI ML Repositoryimport numpy as npimport pandas as pdretail = pd.read_csv('./OnlineRetail.csv')컬럼 확인하기  columns 속성으로 확인  컬럼  invoiceNo: 주문 번호  StockCode: 아이템 아이디  Description: 상품 설명  Quantity: 상품 주문 수량  InvoiceDate: 주문 시각  UnitPrice: 상품 가격(동일한 통화)  CustomerID: 고객 아이디  Country: 고객 거주 지역(국가)retail.columnsIndex(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',       'UnitPrice', 'CustomerID', 'Country'],      dtype='object')데이터 살펴보기  데이터 분석의 가장 첫 단계  데이터를 대략적으로 파악 가능(타입, 저장된 형태)  데이터 cleansing 전략 수립retail.head()                  InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country                  0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      12/1/2010 8:26      2.55      17850.0      United Kingdom              1      536365      71053      WHITE METAL LANTERN      6      12/1/2010 8:26      3.39      17850.0      United Kingdom              2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      12/1/2010 8:26      2.75      17850.0      United Kingdom              3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      12/1/2010 8:26      3.39      17850.0      United Kingdom              4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      12/1/2010 8:26      3.39      17850.0      United Kingdom      retail.info()&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 541909 entries, 0 to 541908Data columns (total 8 columns): #   Column       Non-Null Count   Dtype  ---  ------       --------------   -----   0   InvoiceNo    541909 non-null  object  1   StockCode    541909 non-null  object  2   Description  540455 non-null  object  3   Quantity     541909 non-null  int64   4   InvoiceDate  541909 non-null  object  5   UnitPrice    541909 non-null  float64 6   CustomerID   406829 non-null  float64 7   Country      541909 non-null  object dtypes: float64(2), int64(1), object(5)memory usage: 33.1+ MBretail.describe()                  Quantity      UnitPrice      CustomerID                  count      541909.000000      541909.000000      406829.000000              mean      9.552250      4.611114      15287.690570              std      218.081158      96.759853      1713.600303              min      -80995.000000      -11062.060000      12346.000000              25%      1.000000      1.250000      13953.000000              50%      3.000000      2.080000      15152.000000              75%      10.000000      4.130000      16791.000000              max      80995.000000      38970.000000      18287.000000      Data cleansing  null 데이터 처리  CustomerID  Business 로직에 맞지 않은 데이터 처리  음수의 아이템 수량  가격이 0원retail.isnull().sum()InvoiceNo           0StockCode           0Description      1454Quantity            0InvoiceDate         0UnitPrice           0CustomerID     135080Country             0dtype: int64null customerID 제거pd.notnull(retail['CustomerID']) #null 아닌 값 true 확인하기0         True1         True2         True3         True4         True          ... 541904    True541905    True541906    True541907    True541908    TrueName: CustomerID, Length: 541909, dtype: boolretail[pd.notnull(retail['CustomerID'])] #null이 아닌 값 retail 데이터 프레임에 넣어준다                  InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country                  0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      12/1/2010 8:26      2.55      17850.0      United Kingdom              1      536365      71053      WHITE METAL LANTERN      6      12/1/2010 8:26      3.39      17850.0      United Kingdom              2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      12/1/2010 8:26      2.75      17850.0      United Kingdom              3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      12/1/2010 8:26      3.39      17850.0      United Kingdom              4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      12/1/2010 8:26      3.39      17850.0      United Kingdom              ...      ...      ...      ...      ...      ...      ...      ...      ...              541904      581587      22613      PACK OF 20 SPACEBOY NAPKINS      12      12/9/2011 12:50      0.85      12680.0      France              541905      581587      22899      CHILDREN'S APRON DOLLY GIRL      6      12/9/2011 12:50      2.10      12680.0      France              541906      581587      23254      CHILDRENS CUTLERY DOLLY GIRL      4      12/9/2011 12:50      4.15      12680.0      France              541907      581587      23255      CHILDRENS CUTLERY CIRCUS PARADE      4      12/9/2011 12:50      4.15      12680.0      France              541908      581587      22138      BAKING SET 9 PIECE RETROSPOT      3      12/9/2011 12:50      4.95      12680.0      France      406829 rows × 8 columnsretail = retail[pd.notnull(retail['CustomerID'])]len(retail)406829비지니스 로직에 맞지 않은 데이터 제거  수량, 가격 &gt; 0retail = retail[retail['Quantity'] &gt; 0]retail = retail[retail['UnitPrice'] &gt; 0]len(retail)397884retail.info()&lt;class 'pandas.core.frame.DataFrame'&gt;Int64Index: 397884 entries, 0 to 541908Data columns (total 8 columns): #   Column       Non-Null Count   Dtype  ---  ------       --------------   -----   0   InvoiceNo    397884 non-null  object  1   StockCode    397884 non-null  object  2   Description  397884 non-null  object  3   Quantity     397884 non-null  int64   4   InvoiceDate  397884 non-null  object  5   UnitPrice    397884 non-null  float64 6   CustomerID   397884 non-null  float64 7   Country      397884 non-null  object dtypes: float64(2), int64(1), object(5)memory usage: 27.3+ MBretail.describe()                  Quantity      UnitPrice      CustomerID                  count      397884.000000      397884.000000      397884.000000              mean      12.988238      3.116488      15294.423453              std      179.331775      22.097877      1713.141560              min      1.000000      0.001000      12346.000000              25%      2.000000      1.250000      13969.000000              50%      6.000000      1.950000      15159.000000              75%      12.000000      3.750000      16795.000000              max      80995.000000      8142.750000      18287.000000      데이터 타입 변경  메모리 효율화  올바른 데이터 타입 매칭retail['CustomerID'] = retail['CustomerID'].astype(np.int32)retail.info()&lt;class 'pandas.core.frame.DataFrame'&gt;Int64Index: 397884 entries, 0 to 541908Data columns (total 8 columns): #   Column       Non-Null Count   Dtype  ---  ------       --------------   -----   0   InvoiceNo    397884 non-null  object  1   StockCode    397884 non-null  object  2   Description  397884 non-null  object  3   Quantity     397884 non-null  int64   4   InvoiceDate  397884 non-null  object  5   UnitPrice    397884 non-null  float64 6   CustomerID   397884 non-null  int32   7   Country      397884 non-null  object dtypes: float64(1), int32(1), int64(1), object(5)memory usage: 25.8+ MB  memory usage: 27.3+ MB 에서memory usage: 25.8+ MB 으로 바뀌면서 메모리 사용공간 커짐새로운 컬럼 추가  Quantity * UnitPrice는 고객의 총 지출 비용(CheckoutPrice)retail['CheckoutPrice'] = retail['UnitPrice'] * retail['Quantity']retail.head()                  InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice                  0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      12/1/2010 8:26      2.55      17850      United Kingdom      15.30              1      536365      71053      WHITE METAL LANTERN      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34              2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      12/1/2010 8:26      2.75      17850      United Kingdom      22.00              3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34              4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34      정제 데이터 저장retail.to_csv('./OnlineRetailClean.csv')미니 프로젝트를 통한 데이터 분석의 목표  매출 분석  고객 분석          우수고객 선별      고객 리텐션 분석        push notification 실행 의사 결정 하기",
        "url": "/virtualshoping-data"
    }
    ,
    
    "salesitem2-data": {
        "title": "응용-매출,가장 많이 팔린 아이템 확인하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  아이템별 지표 확인하기  시간별 지역별 판매 지표 확인하기import numpy as npimport pandas as pd# seabornimport seaborn as snsCOLORS = sns.color_palette()%matplotlib inline # 그래프를 노트북 안에 그리기 위해 설정# matplotlib 한글 폰트 출력코드import matplotlib.pyplot as pltimport matplotlibmatplotlib.font_manager._rebuild()from matplotlib import stylefrom matplotlib import font_manager , rcimport platformplatform.platform() #'Windows-10-10.0.19041-SP0' / 시스템 운영체제 확인 가능try :    if platform.sys() == 'windows':        # 윈도우인 경우        font_name = fontmanager.FontProperties(fname=\"c:/windows/Fonts/나눔고딕.ttf\").get_name()        rc('font', family=font_name)    else:        #max 인 경우        rc('font', family='AppleGothic')except:    passmatplotlib.rcParams['axes.unicode_minus'] = False# rcParams 폰트 크기를 지정하기 # 그래프에서 마이너스 기호가 표시되도록 하는 설정입니다. Matplotlib is building the font cache; this may take a moment.plt.rcParams[\"font.family\"] = 'serif'print (plt.rcParams['font.family'] ) #현재 설정 된 폰트 ['sans-serif']이다 ['serif']!conda install fonts-nanum*Collecting package metadata (current_repodata.json): ...working... failedCondaHTTPError: HTTP 000 CONNECTION FAILED for url &lt;https://repo.anaconda.com/pkgs/main/win-64/current_repodata.json&gt;Elapsed: -An HTTP error occurred when trying to retrieve this URL.HTTP errors are often intermittent, and a simple retry will get you on your way.If your current network has https://www.anaconda.com blocked, please filea support request with your network engineering team.'https://repo.anaconda.com/pkgs/main/win-64'#I was able to get rid of the RuntimeWarning by declaring the font usage with:#plt.rcParams[\"font.serif\"] = \"nanumGothic\"# 참조 -https://github.com/matplotlib/matplotlib/issues/17007import matplotlib.pyplot as pltplt.rcParams[\"font.serif\"]= \"nanumGothic\"fig, ax = plt.subplots()ax.set_title('my font')ax.set_xlabel(r'my font $\\alpha\\beta\\gamma$')ax.set_yticks([-1,0,1])plt.show()데이터 로딩  정제된 데이터 사용(OnlineRetailCleanhangle.csv)dtypes = {    '상품 가격': np.float32,    '고객 아이디': np.int32,    '주문 수량': np.int32}# 한글 깨짐 해결 방안#[거의 해결] 해결책 (3) - Excel에서 인코딩 옵션 변경# 파일을 우선 Excel에서 열어줍니다.# 파일 - 다른 이름으로 저장에서 - CSV UTF-8 (쉼표로 분리) 로 변경하여 저장합니다.retail = pd.read_csv('./OnlineRetailCleanhangle.csv',                      dtype=dtypes ,                      encoding = 'utf-8')retail.head()                  Unnamed: 0      주문 번호      아이템 아이디      상품 설명      주문 수량      주문 시각      상품 가격      고객 아이디      고객 거주 지역      총 주문 가격                  0      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      12/1/2010 8:26      2.55      17850      United Kingdom      15.30              1      1      536365      71053      WHITE METAL LANTERN      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34              2      2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      12/1/2010 8:26      2.75      17850      United Kingdom      22.00              3      3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34              4      4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34      날짜 타입 데이터 변환  문자열로 로딩하는 것보다 date/datetime 타입으로 로딩하는 것이 분석에 용이retail['주문 시각'] = pd.to_datetime(retail['주문 시각'], infer_datetime_format=True)# infer_datetime_format=True 날짜시간 포맷 추정해서 파싱하기retail.info() #5  주문 시각       397884 non-null  datetime64[ns]  바꿔짐&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 397884 entries, 0 to 397883Data columns (total 10 columns): #   Column      Non-Null Count   Dtype         ---  ------      --------------   -----          0   Unnamed: 0  397884 non-null  int64          1   주문 번호       397884 non-null  int64          2   아이템 아이디     397884 non-null  object         3   상품 설명       397884 non-null  object         4   주문 수량       397884 non-null  int32          5   주문 시각       397884 non-null  datetime64[ns] 6   상품 가격       397884 non-null  float32        7   고객 아이디      397884 non-null  int32          8   고객 거주 지역    397884 non-null  object         9   총 주문 가격     397884 non-null  float64       dtypes: datetime64[ns](1), float32(1), float64(1), int32(2), int64(2), object(3)memory usage: 25.8+ MB해당 기간 동안의 매출  전체 매출  국가별 매출  월별 매출  요일별 매출  시간별 매출전체 매출total_revenue = retail['총 주문 가격'].sum()total_revenue8911407.904국가별 매출rev_by_countries = retail.groupby('고객 거주 지역').sum()['총 주문 가격'].sort_values(ascending=False) # 내림차순 : ascending=Falserev_by_countries고객 거주 지역United Kingdom          7.308392e+06Netherlands             2.854463e+05EIRE                    2.655459e+05Germany                 2.288671e+05France                  2.090240e+05Australia               1.385213e+05Spain                   6.157711e+04Switzerland             5.644395e+04Belgium                 4.119634e+04Sweden                  3.837833e+04Japan                   3.741637e+04Norway                  3.616544e+04Portugal                3.343989e+04Finland                 2.254608e+04Singapore               2.127929e+04Channel Islands         2.045044e+04Denmark                 1.895534e+04Italy                   1.748324e+04Cyprus                  1.359038e+04Austria                 1.019868e+04Poland                  7.334650e+03Israel                  7.221690e+03Greece                  4.760520e+03Iceland                 4.310000e+03Canada                  3.666380e+03USA                     3.580390e+03Malta                   2.725590e+03Unspecified             2.667070e+03United Arab Emirates    1.902280e+03Lebanon                 1.693880e+03Lithuania               1.661060e+03European Community      1.300250e+03Brazil                  1.143600e+03RSA                     1.002310e+03Czech Republic          8.267400e+02Bahrain                 5.484000e+02Saudi Arabia            1.459200e+02Name: 총 주문 가격, dtype: float64plot = rev_by_countries.plot(kind='bar', color=COLORS[-1], figsize=(20, 10))plot.set_xlabel('고객 거주 지역', fontsize=25)plot.set_ylabel('매출', fontsize=25)plot.set_title('국가별 매출', fontsize=23)plot.set_xticklabels(labels=rev_by_countries.index, rotation=75, fontsize=13)[Text(0, 0, 'United Kingdom'), Text(1, 0, 'Netherlands'), Text(2, 0, 'EIRE'), Text(3, 0, 'Germany'), Text(4, 0, 'France'), Text(5, 0, 'Australia'), Text(6, 0, 'Spain'), Text(7, 0, 'Switzerland'), Text(8, 0, 'Belgium'), Text(9, 0, 'Sweden'), Text(10, 0, 'Japan'), Text(11, 0, 'Norway'), Text(12, 0, 'Portugal'), Text(13, 0, 'Finland'), Text(14, 0, 'Singapore'), Text(15, 0, 'Channel Islands'), Text(16, 0, 'Denmark'), Text(17, 0, 'Italy'), Text(18, 0, 'Cyprus'), Text(19, 0, 'Austria'), Text(20, 0, 'Poland'), Text(21, 0, 'Israel'), Text(22, 0, 'Greece'), Text(23, 0, 'Iceland'), Text(24, 0, 'Canada'), Text(25, 0, 'USA'), Text(26, 0, 'Malta'), Text(27, 0, 'Unspecified'), Text(28, 0, 'United Arab Emirates'), Text(29, 0, 'Lebanon'), Text(30, 0, 'Lithuania'), Text(31, 0, 'European Community'), Text(32, 0, 'Brazil'), Text(33, 0, 'RSA'), Text(34, 0, 'Czech Republic'), Text(35, 0, 'Bahrain'), Text(36, 0, 'Saudi Arabia')]rev_by_countries / total_revenue #비율 확인할 수 있다.고객 거주 지역United Kingdom          0.820116Netherlands             0.032032EIRE                    0.029798Germany                 0.025682France                  0.023456Australia               0.015544Spain                   0.006910Switzerland             0.006334Belgium                 0.004623Sweden                  0.004307Japan                   0.004199Norway                  0.004058Portugal                0.003752Finland                 0.002530Singapore               0.002388Channel Islands         0.002295Denmark                 0.002127Italy                   0.001962Cyprus                  0.001525Austria                 0.001144Poland                  0.000823Israel                  0.000810Greece                  0.000534Iceland                 0.000484Canada                  0.000411USA                     0.000402Malta                   0.000306Unspecified             0.000299United Arab Emirates    0.000213Lebanon                 0.000190Lithuania               0.000186European Community      0.000146Brazil                  0.000128RSA                     0.000112Czech Republic          0.000093Bahrain                 0.000062Saudi Arabia            0.000016Name: 총 주문 가격, dtype: float64그래프 유틸 함수def plot_bar(df, xlabel, ylabel, title, color=COLORS[-7], figsize=(20, 10), rotation=45):    plot = df.plot(kind='bar', color=color, figsize=figsize)    plot.set_xlabel(xlabel, fontsize=25)    plot.set_ylabel(ylabel, fontsize=25)    plot.set_title(title, fontsize=30)    plot.set_xticklabels(labels=df.index, rotation=75 , fontsize=13)                   plot_bar(rev_by_countries, '고객 거주 지역', '매출', '국가별 매출')grouped = retail.groupby('고객 거주 지역')grouped.first()                  Unnamed: 0      주문 번호      아이템 아이디      상품 설명      주문 수량      주문 시각      상품 가격      고객 아이디      총 주문 가격              고객 거주 지역                                                                        Australia      197      536389      22941      CHRISTMAS LIGHTS 10 REINDEER      6      2010-12-01 10:03:00      8.50      12431      51.00              Austria      34293      539330      37449      CERAMIC CAKE STAND + HANGING CAKES      8      2010-12-17 09:38:00      8.50      12370      68.00              Bahrain      181140      552449      22693      GROW A FLYTRAP OR SUNFLOWER IN TIN      24      2011-05-09 13:49:00      1.25      12355      30.00              Belgium      7279      537026      84375      SET OF 20 KIDS COOKIE CUTTERS      12      2010-12-03 16:35:00      2.10      12395      25.20              Brazil      157299      550201      22423      REGENCY CAKESTAND 3 TIER      16      2011-04-15 10:25:00      10.95      12769      175.20              Canada      119191      546533      20886      BOX OF 9 PEBBLE CANDLES      12      2011-03-14 13:53:00      1.95      15388      23.40              Channel Islands      20000      538002      22690      DOORMAT HOME SWEET HOME BLUE      2      2010-12-09 11:48:00      7.95      14932      15.90              Cyprus      29732      538826      85123A      WHITE HANGING HEART T-LIGHT HOLDER      64      2010-12-14 12:58:00      2.55      12370      163.20              Czech Republic      103598      545072      22930      BAKING MOULD HEART MILK CHOCOLATE      18      2011-02-28 08:43:00      2.55      12781      45.90              Denmark      20017      538003      22847      BREAD BIN DINER STYLE IVORY      8      2010-12-09 12:05:00      14.95      12429      119.60              EIRE      1404      536540      22968      ROSE COTTAGE KEEPSAKE BOX      4      2010-12-01 14:05:00      9.95      14911      39.80              European Community      168149      551013      22839      3 TIER CAKE TIN GREEN AND CREAM      1      2011-04-26 10:54:00      14.95      15108      14.95              Finland      34083      539318      84992      72 SWEETHEART FAIRY CAKE CASES      72      2010-12-16 19:09:00      0.55      12348      39.60              France      26      536370      22728      ALARM CLOCK BAKELIKE PINK      24      2010-12-01 08:45:00      3.75      12583      90.00              Germany      1109      536527      22809      SET OF 6 T-LIGHTS SANTA      6      2010-12-01 13:04:00      2.95      12662      17.70              Greece      69007      541932      22699      ROSES REGENCY TEACUP AND SAUCER      24      2011-01-24 11:39:00      2.55      14439      61.20              Iceland      14938      537626      85116      BLACK CANDELABRA T-LIGHT HOLDER      12      2010-12-07 14:57:00      2.10      12347      25.20              Israel      91580      544108      22245      HOOK, 1 HANGER ,MAGIC GARDEN      24      2011-02-16 10:53:00      0.85      12653      20.40              Italy      7214      537022      22791      T-LIGHT GLASS FLUTED ANTIQUE      12      2010-12-03 15:45:00      1.25      12725      15.00              Japan      9783      537218      85016      SET OF 6 VINTAGE NOTELETS KIT      6      2010-12-05 15:46:00      2.55      12763      15.30              Lebanon      72985      542276      82551      LAUNDRY 15C METAL SIGN      12      2011-01-27 10:19:00      1.45      12764      17.40              Lithuania      7986      537081      22409      MONEY BOX BISCUITS DESIGN      12      2010-12-05 12:00:00      1.25      15332      15.00              Malta      217684      555931      22784      LANTERN CREAM GAZEBO      3      2011-06-08 08:31:00      4.95      17828      14.85              Netherlands      385      536403      22867      HAND WARMER BIRD DESIGN      96      2010-12-01 11:27:00      1.85      12791      177.60              Norway      1236      536532      84692      BOX OF 24 COCKTAIL PARASOLS      50      2010-12-01 13:24:00      0.42      12433      21.00              Poland      6608      536971      21733      RED HANGING HEART T-LIGHT HOLDER      32      2010-12-03 13:40:00      2.55      12779      81.60              Portugal      7134      536990      21992      VINTAGE PAISLEY STATIONERY SET      6      2010-12-03 15:14:00      2.95      12793      17.70              RSA      395472      571035      21238      RED RETROSPOT CUP      8      2011-10-13 12:50:00      0.85      12446      6.80              Saudi Arabia      100810      544838      22915      ASSORTED BOTTLE TOP  MAGNETS      12      2011-02-24 10:34:00      0.42      12565      5.04              Singapore      70758      542102      21519      GIN &amp; TONIC DIET GREETING CARD      72      2011-01-25 13:26:00      0.36      12744      25.92              Spain      6421      536944      22383      LUNCH BAG SUKI  DESIGN      70      2010-12-03 12:20:00      1.65      12557      115.50              Sweden      30079      538848      85232B      SET OF 3 BABUSHKA STACKING TINS      240      2010-12-14 13:28:00      4.95      17404      1188.00              Switzerland      5320      536858      22326      ROUND SNACK BOXES SET OF4 WOODLAND      30      2010-12-03 10:36:00      2.95      13520      88.50              USA      164464      550644      22722      SET OF 6 SPICE TINS PANTRY DESIGN      7      2011-04-19 16:19:00      3.95      12733      27.65              United Arab Emirates      89570      543911      21485      RETROSPOT HEART HOT WATER BOTTLE      6      2011-02-14 12:46:00      4.95      17829      29.70              United Kingdom      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      2010-12-01 08:26:00      2.55      17850      15.30              Unspecified      152712      549687      20685      DOORMAT RED RETROSPOT      2      2011-04-11 13:29:00      7.95      12363      15.90      grouped_sr = grouped.size()grouped_sr고객 거주 지역Australia                 1182Austria                    398Bahrain                     17Belgium                   2031Brazil                      32Canada                     151Channel Islands            748Cyprus                     614Czech Republic              25Denmark                    380EIRE                      7236European Community          60Finland                    685France                    8341Germany                   9040Greece                     145Iceland                    182Israel                     248Italy                      758Japan                      321Lebanon                     45Lithuania                   35Malta                      112Netherlands               2359Norway                    1071Poland                     330Portugal                  1462RSA                         57Saudi Arabia                 9Singapore                  222Spain                     2484Sweden                     451Switzerland               1841USA                        179United Arab Emirates        68United Kingdom          354321Unspecified                244dtype: int64grouped_sr.index Index(['Australia', 'Austria', 'Bahrain', 'Belgium', 'Brazil', 'Canada',       'Channel Islands', 'Cyprus', 'Czech Republic', 'Denmark', 'EIRE',       'European Community', 'Finland', 'France', 'Germany', 'Greece',       'Iceland', 'Israel', 'Italy', 'Japan', 'Lebanon', 'Lithuania', 'Malta',       'Netherlands', 'Norway', 'Poland', 'Portugal', 'RSA', 'Saudi Arabia',       'Singapore', 'Spain', 'Sweden', 'Switzerland', 'USA',       'United Arab Emirates', 'United Kingdom', 'Unspecified'],      dtype='object', name='고객 거주 지역')grouped_sr.plot(kind='pie',                 figsize=(15,25),               textprops={'size':10}               )plt.title('국가별 매출', size=50)plt.legend(grouped_sr.index, loc='best')plt.show()  grouped_sr.index 가 많다보니 글씨가 잘 안보인다.grouped_sr.plot.pie(figsize=(17,25),                    shadow = True,                    textprops = {'fontsize' : 14},                    autopct='%1.0f%%') # 파이 조각의 전체 대비 백분율 plt.title('국가별 매출', size=50)plt.legend(grouped_sr.index, loc='best')plt.show()월별 매출retail['주문 시각'].sort_values(ascending=False)397883   2011-12-09 12:50:00397876   2011-12-09 12:50:00397870   2011-12-09 12:50:00397871   2011-12-09 12:50:00397872   2011-12-09 12:50:00                 ...        3        2010-12-01 08:26:001        2010-12-01 08:26:005        2010-12-01 08:26:006        2010-12-01 08:26:000        2010-12-01 08:26:00Name: 주문 시각, Length: 397884, dtype: datetime64[ns]def extract_month(date):    month = str(date.month)    if date.month &lt; 10:        month = '0' + month    return str(date.year) + month rev_by_month = retail.set_index('주문 시각').groupby(extract_month).sum()['총 주문 가격']rev_by_month201012     572713.890201101     569445.040201102     447137.350201103     595500.760201104     469200.361201105     678594.560201106     661213.690201107     600091.011201108     645343.900201109     952838.382201110    1039318.790201111    1161817.380201112     518192.790Name: 총 주문 가격, dtype: float64plot_bar(rev_by_month, '월별', '매출', '월별 매출')요일별 매출rev_by_dow = retail.set_index('주문 시각').groupby(lambda date:date.dayofweek).sum()['총 주문 가격']rev_by_dow  ## dayofweek - [Monday 0 ~ Sunday 6]0    1367146.4111    1700634.6312    1588336.1703    1976859.0704    1485917.4016     792514.221Name: 총 주문 가격, dtype: float64DAY_OF_WEEK = np.array(['월요일', '화요일', '수요일', '목요일', '금요일', '토요일', '일요일'])rev_by_dow.index = DAY_OF_WEEK[rev_by_dow.index]plot_bar(rev_by_dow, '요일', '매출', '요일 별 매출')시간별 매출rev_by_hour = retail.set_index('주문 시각').groupby(lambda date:date.hour).sum()['총 주문 가격']plot_bar(rev_by_hour, '시간', '매출', '시간별 매출')매출 데이터로부터 insight  전체 매출의 82%가 UK에서 발생  11년도의 가장 많은 주문이 발생한 달 11월(12월의 전체 데이터가 반영이 되진 않았음)  11, 12월의 판매량이 압도(블랙프라이데이, 사이버먼데이, 크리스마스 휴일)  일주일중 목요일까지는 성장세를 보이다가, 이후로 하락(토요일에는 주문X)  7시를 시작으로 주문이 시작되어 12시까지 증가세, 15시까지 하락을, 15시 이후 부터 급락)제품별 metrics  Top 10 판매 제품  Top 10 매출 제품top_selling = retail.groupby('아이템 아이디').sum()['주문 수량'].sort_values(ascending=False)[:3]top_selling아이템 아이디23843    8099523166    7791684077    54415Name: 주문 수량, dtype: int32top_revenue = retail.groupby('아이템 아이디').sum()['총 주문 가격'].sort_values(ascending=False)[:10]top_revenue아이템 아이디23843     168469.6022423     142592.9585123A    100603.5085099B     85220.7823166      81416.73POST       77803.9647566      68844.3384879      56580.34M          53779.9323084      51346.20Name: 총 주문 가격, dtype: float64top 3 아이템의 월별 판매량 추이retail.set_index('주문 시각').groupby(['아이템 아이디', extract_month]).sum()[['주문 수량', '총 주문 가격']].loc[top_selling.index]                        주문 수량      총 주문 가격              아이템 아이디                                    23843      201112      80995      168469.60              23166      201101      74215      77183.60              201105      792      869.04              201106      391      458.51              201107      718      826.94              201108      405      486.09              201109      342      397.26              201110      235      283.67              201111      631      708.11              201112      187      203.51              84077      201012      5139      1150.47              201101      1488      385.44              201102      3457      795.17              201103      3888      943.20              201104      10224      2281.44              201105      4944      1249.44              201106      1920      533.76              201107      3600      982.56              201108      2256      654.24              201109      3462      985.70              201110      8174      1953.98              201111      4500      1294.20              201112      1363      376.65      monthly_top3 = retail.set_index('주문 시각').groupby(['아이템 아이디', extract_month]).sum()[['주문 수량', '총 주문 가격']].loc[top_selling.index]plot_bar(monthly_top3['총 주문 가격'], '아이템/월별', '매출', '탑 3 아이템 매출')",
        "url": "/salesitem2-Data"
    }
    ,
    
    "salesitem-data": {
        "title": "매출,가장 많이 팔린 아이템 확인하기",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  아이템별 지표 확인하기  시간별 지역별 판매 지표 확인하기import numpy as npimport pandas as pd# seabornimport seaborn as snsCOLORS = sns.color_palette()%matplotlib inline데이터 로딩  정제된 데이터 사용(retail.csv)dtypes = {    'UnitPrice': np.float32,    'CustomerID': np.int32,    'Quantity': np.int32}retail = pd.read_csv('./OnlineRetailClean.csv', dtype=dtypes)retail.head()                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice                  0      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      12/1/2010 8:26      2.55      17850      United Kingdom      15.30              1      1      536365      71053      WHITE METAL LANTERN      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34              2      2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      12/1/2010 8:26      2.75      17850      United Kingdom      22.00              3      3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34              4      4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      12/1/2010 8:26      3.39      17850      United Kingdom      20.34      날짜 타입 데이터 변환  문자열로 로딩하는 것보다 date/datetime 타입으로 로딩하는 것이 분석에 용이retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'], infer_datetime_format=True)# infer_datetime_format=True 날짜시간 포맷 추정해서 파싱하기retail.info() #5   InvoiceDate    397884 non-null  datetime64[ns]   바꿔짐&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 397884 entries, 0 to 397883Data columns (total 10 columns): #   Column         Non-Null Count   Dtype         ---  ------         --------------   -----          0   Unnamed: 0     397884 non-null  int64          1   InvoiceNo      397884 non-null  int64          2   StockCode      397884 non-null  object         3   Description    397884 non-null  object         4   Quantity       397884 non-null  int32          5   InvoiceDate    397884 non-null  datetime64[ns] 6   UnitPrice      397884 non-null  float32        7   CustomerID     397884 non-null  int32          8   Country        397884 non-null  object         9   CheckoutPrice  397884 non-null  float64       dtypes: datetime64[ns](1), float32(1), float64(1), int32(2), int64(2), object(3)memory usage: 25.8+ MB해당 기간 동안의 매출  전체 매출  국가별 매출  월별 매출  요일별 매출  시간별 매출전체 매출total_revenue = retail['CheckoutPrice'].sum()total_revenue8911407.904국가별 매출rev_by_countries = retail.groupby('Country').sum()['CheckoutPrice'].sort_values()rev_by_countriesCountrySaudi Arabia            1.459200e+02Bahrain                 5.484000e+02Czech Republic          8.267400e+02RSA                     1.002310e+03Brazil                  1.143600e+03European Community      1.300250e+03Lithuania               1.661060e+03Lebanon                 1.693880e+03United Arab Emirates    1.902280e+03Unspecified             2.667070e+03Malta                   2.725590e+03USA                     3.580390e+03Canada                  3.666380e+03Iceland                 4.310000e+03Greece                  4.760520e+03Israel                  7.221690e+03Poland                  7.334650e+03Austria                 1.019868e+04Cyprus                  1.359038e+04Italy                   1.748324e+04Denmark                 1.895534e+04Channel Islands         2.045044e+04Singapore               2.127929e+04Finland                 2.254608e+04Portugal                3.343989e+04Norway                  3.616544e+04Japan                   3.741637e+04Sweden                  3.837833e+04Belgium                 4.119634e+04Switzerland             5.644395e+04Spain                   6.157711e+04Australia               1.385213e+05France                  2.090240e+05Germany                 2.288671e+05EIRE                    2.655459e+05Netherlands             2.854463e+05United Kingdom          7.308392e+06Name: CheckoutPrice, dtype: float64plot = rev_by_countries.plot(kind='bar', color=COLORS[-1], figsize=(20, 10))plot.set_xlabel('Country', fontsize=11)plot.set_ylabel('Revenue', fontsize=11)plot.set_title('Revenue by Country', fontsize=13)plot.set_xticklabels(labels=rev_by_countries.index, rotation=45)[Text(0, 0, 'Saudi Arabia'), Text(1, 0, 'Bahrain'), Text(2, 0, 'Czech Republic'), Text(3, 0, 'RSA'), Text(4, 0, 'Brazil'), Text(5, 0, 'European Community'), Text(6, 0, 'Lithuania'), Text(7, 0, 'Lebanon'), Text(8, 0, 'United Arab Emirates'), Text(9, 0, 'Unspecified'), Text(10, 0, 'Malta'), Text(11, 0, 'USA'), Text(12, 0, 'Canada'), Text(13, 0, 'Iceland'), Text(14, 0, 'Greece'), Text(15, 0, 'Israel'), Text(16, 0, 'Poland'), Text(17, 0, 'Austria'), Text(18, 0, 'Cyprus'), Text(19, 0, 'Italy'), Text(20, 0, 'Denmark'), Text(21, 0, 'Channel Islands'), Text(22, 0, 'Singapore'), Text(23, 0, 'Finland'), Text(24, 0, 'Portugal'), Text(25, 0, 'Norway'), Text(26, 0, 'Japan'), Text(27, 0, 'Sweden'), Text(28, 0, 'Belgium'), Text(29, 0, 'Switzerland'), Text(30, 0, 'Spain'), Text(31, 0, 'Australia'), Text(32, 0, 'France'), Text(33, 0, 'Germany'), Text(34, 0, 'EIRE'), Text(35, 0, 'Netherlands'), Text(36, 0, 'United Kingdom')]rev_by_countries / total_revenue #비율 확인할 수 있다.CountrySaudi Arabia            0.000016Bahrain                 0.000062Czech Republic          0.000093RSA                     0.000112Brazil                  0.000128European Community      0.000146Lithuania               0.000186Lebanon                 0.000190United Arab Emirates    0.000213Unspecified             0.000299Malta                   0.000306USA                     0.000402Canada                  0.000411Iceland                 0.000484Greece                  0.000534Israel                  0.000810Poland                  0.000823Austria                 0.001144Cyprus                  0.001525Italy                   0.001962Denmark                 0.002127Channel Islands         0.002295Singapore               0.002388Finland                 0.002530Portugal                0.003752Norway                  0.004058Japan                   0.004199Sweden                  0.004307Belgium                 0.004623Switzerland             0.006334Spain                   0.006910Australia               0.015544France                  0.023456Germany                 0.025682EIRE                    0.029798Netherlands             0.032032United Kingdom          0.820116Name: CheckoutPrice, dtype: float64그래프 유틸 함수def plot_bar(df, xlabel, ylabel, title, color=COLORS[0], figsize=(20, 10), rotation=45):    plot = df.plot(kind='bar', color=color, figsize=figsize)    plot.set_xlabel(xlabel, fontsize=11)    plot.set_ylabel(ylabel, fontsize=11)    plot.set_title(title, fontsize=13)    plot.set_xticklabels(labels=df.index, rotation=rotation)                   plot_bar(rev_by_countries, 'Country', 'Revenue', 'Revenue by Country')월별 매출retail['InvoiceDate'].sort_values(ascending=False)397883   2011-12-09 12:50:00397876   2011-12-09 12:50:00397870   2011-12-09 12:50:00397871   2011-12-09 12:50:00397872   2011-12-09 12:50:00                 ...        3        2010-12-01 08:26:001        2010-12-01 08:26:005        2010-12-01 08:26:006        2010-12-01 08:26:000        2010-12-01 08:26:00Name: InvoiceDate, Length: 397884, dtype: datetime64[ns]def extract_month(date):    month = str(date.month)    if date.month &lt; 10:        month = '0' + month    return str(date.year) + month rev_by_month = retail.set_index('InvoiceDate').groupby(extract_month).sum()['CheckoutPrice']rev_by_month201012     572713.890201101     569445.040201102     447137.350201103     595500.760201104     469200.361201105     678594.560201106     661213.690201107     600091.011201108     645343.900201109     952838.382201110    1039318.790201111    1161817.380201112     518192.790Name: CheckoutPrice, dtype: float64plot_bar(rev_by_month, 'Month', 'Revenue', 'Revenue by Month')요일별 매출rev_by_dow = retail.set_index('InvoiceDate').groupby(lambda date:date.dayofweek).sum()['CheckoutPrice']rev_by_dow0    1367146.4111    1700634.6312    1588336.1703    1976859.0704    1485917.4016     792514.221Name: CheckoutPrice, dtype: float64DAY_OF_WEEK = np.array(['Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'])rev_by_dow.index = DAY_OF_WEEK[rev_by_dow.index]plot_bar(rev_by_dow, 'DOW', 'Revenue', 'Revenue by DOW')시간별 매출rev_by_hour = retail.set_index('InvoiceDate').groupby(lambda date:date.hour).sum()['CheckoutPrice']plot_bar(rev_by_hour, 'hour', 'revenue', 'revenue by hour')매출 데이터로부터 insight  전체 매출의 82%가 UK에서 발생  11년도의 가장 많은 주문이 발생한 달 11월(12월의 전체 데이터가 반영이 되진 않았음)  11, 12월의 판매량이 압도(블랙프라이데이, 사이버먼데이, 크리스마스 휴일)  일주일중 목요일까지는 성장세를 보이다가, 이후로 하락(토요일에는 주문X)  7시를 시작으로 주문이 시작되어 12시까지 증가세, 15시까지 하락을, 15시 이후 부터 급락)제품별 metrics  Top 10 판매 제품  Top 10 매출 제품top_selling = retail.groupby('StockCode').sum()['Quantity'].sort_values(ascending=False)[:3]top_sellingStockCode23843    8099523166    7791684077    54415Name: Quantity, dtype: int32top_revenue = retail.groupby('StockCode').sum()['CheckoutPrice'].sort_values(ascending=False)[:10]top_revenueStockCode23843     168469.6022423     142592.9585123A    100603.5085099B     85220.7823166      81416.73POST       77803.9647566      68844.3384879      56580.34M          53779.9323084      51346.20Name: CheckoutPrice, dtype: float64top 3 아이템의 월별 판매량 추이retail.set_index('InvoiceDate').groupby(['StockCode', extract_month]).sum()[['Quantity', 'CheckoutPrice']].loc[top_selling.index]                        Quantity      CheckoutPrice              StockCode                                    23843      201112      80995      168469.60              23166      201101      74215      77183.60              201105      792      869.04              201106      391      458.51              201107      718      826.94              201108      405      486.09              201109      342      397.26              201110      235      283.67              201111      631      708.11              201112      187      203.51              84077      201012      5139      1150.47              201101      1488      385.44              201102      3457      795.17              201103      3888      943.20              201104      10224      2281.44              201105      4944      1249.44              201106      1920      533.76              201107      3600      982.56              201108      2256      654.24              201109      3462      985.70              201110      8174      1953.98              201111      4500      1294.20              201112      1363      376.65      monthly_top3 = retail.set_index('InvoiceDate').groupby(['StockCode', extract_month]).sum()[['Quantity', 'CheckoutPrice']].loc[top_selling.index]plot_bar(monthly_top3['CheckoutPrice'], 'Product/Month', 'Revenue', 'Revenue of top 3 items')",
        "url": "/salesitem-Data"
    }
    ,
    
    "pushnotification-data": {
        "title": "데이터 기반으로 의사결정하기-푸쉬 노티피케이션 타임",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  푸쉬 노티피케이션 타임 의사 결정 하기푸쉬 노티피케이션 이란?push notification은 단적으로 설명한다면 서버에서 발생한 Event를 특정 클라이언트에게 Event 발생 사실을 통지하는 기술입니다. 주변에서 볼 수 있는 가장 흔히 볼 수 있는 사례가 SNS application의 메시지 수신 알림입니다.import numpy as npimport pandas as pd# seabornimport seaborn as snsCOLORS = sns.color_palette()%matplotlib inlinedef plot_bar(df, xlabel, ylabel, title, figsize=(20, 10), color=COLORS[-1], rotation=45):    plot = df.plot(kind='bar', color=color, figsize=figsize)    plot.set_xlabel(xlabel, fontsize=10)    plot.set_ylabel(ylabel, fontsize=10)    plot.set_title(title, fontsize=12)    plot.set_xticklabels(labels=df.index, rotation=rotation)dtypes = {    'UnitPrice': np.float32,    'CustomerID': np.int32,    'Quantity': np.int32}retail = pd.read_csv('./OnlineRetailClean.csv', dtype=dtypes)retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'], infer_datetime_format=True)retail.head()                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice                  0      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      2010-12-01 08:26:00      2.55      17850      United Kingdom      15.30              1      1      536365      71053      WHITE METAL LANTERN      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34              2      2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      2010-12-01 08:26:00      2.75      17850      United Kingdom      22.00              3      3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34              4      4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34      쿠폰 발송을 할때, push를 언제 보내는게 좋을까?  고객에게 쿠폰 발송을 한다고 기획하고, 회의를 한다고 가정해보겠습니다.  A: 쿠폰을 언제보내는게 좋을까요?  B: 아침에 출퇴근 시간에 보내는게 좋을까요?  C: 점심 먹고 졸린데 그때 보내보죠?  D: 흠 자기전에 스마트폰 많이 하던데 그때는 어떨까요?  A: 그러면 평균 시간을 내볼까요?      K: 아 데이터를 확인해보는게 맞지 않을까요? 언제 고객이 주로 주문을 하는지?    위에서 처럼 실제로 회의를 하다보면 의사결정이 본인/주변의 경험에 의해서 이뤄지는 것을 많이 볼 수 있습니다.  주문이 이뤄지는 시간을 고려하지 않고 막무가내로 보낸다면 아무 의미가 없고, 추후 같은 이벤트 발생시에도 판단 근거가 없게 됨  현상태에서는 가장 많이 주문이 일어나는 시점에서 하는 것이 가장 직관적인 판단                            데이터로 파악                                      가설 제시                                      가설 검증                                      1-3 반복                      시간(hour, minute)과 주로 관련되기 때문에 역시 InvoiceDate가 중요한 featureorder_by_hour = retail.set_index('InvoiceDate').groupby(lambda date: date.hour).count()order_by_hour                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      UnitPrice      CustomerID      Country      CheckoutPrice                  6      1      1      1      1      1      1      1      1      1              7      379      379      379      379      379      379      379      379      379              8      8690      8690      8690      8690      8690      8690      8690      8690      8690              9      21944      21944      21944      21944      21944      21944      21944      21944      21944              10      37997      37997      37997      37997      37997      37997      37997      37997      37997              11      49084      49084      49084      49084      49084      49084      49084      49084      49084              12      72065      72065      72065      72065      72065      72065      72065      72065      72065              13      64026      64026      64026      64026      64026      64026      64026      64026      64026              14      54118      54118      54118      54118      54118      54118      54118      54118      54118              15      45369      45369      45369      45369      45369      45369      45369      45369      45369              16      24089      24089      24089      24089      24089      24089      24089      24089      24089              17      13071      13071      13071      13071      13071      13071      13071      13071      13071              18      2928      2928      2928      2928      2928      2928      2928      2928      2928              19      3321      3321      3321      3321      3321      3321      3321      3321      3321              20      802      802      802      802      802      802      802      802      802      order_by_hour = retail.set_index('InvoiceDate').groupby(lambda date: date.hour).count()['CustomerID']order_by_hour6         17       3798      86909     2194410    3799711    4908412    7206513    6402614    5411815    4536916    2408917    1307118     292819     332120      802Name: CustomerID, dtype: int64plot_bar(order_by_hour, 'hour', '# orders', 'Order by hour')def half_an_hour(date):    minute = ':00'    if date.minute &gt; 30:        minute = ':30'    hour = str(date.hour)    if date.hour &lt; 10:        hour = '0' + hour        return hour + minuteorder_by_hour_half = retail.set_index('InvoiceDate').groupby(half_an_hour).count()['CustomerID']order_by_hour_half06:00        107:30      37908:00     314508:30     554509:00     936409:30    1258010:00    1695010:30    2104711:00    1892511:30    3015912:00    3717412:30    3489113:00    3113113:30    3289514:00    2695814:30    2716015:00    2422715:30    2114216:00    1431616:30     977317:00     888917:30     418218:00     171518:30     121319:00     153419:30     178720:00      802Name: CustomerID, dtype: int64order_by_hour_half / order_by_hour_half.sum()06:00    0.00000307:30    0.00095308:00    0.00790408:30    0.01393609:00    0.02353409:30    0.03161710:00    0.04260010:30    0.05289711:00    0.04756411:30    0.07579812:00    0.09342912:30    0.08769113:00    0.07824113:30    0.08267514:00    0.06775314:30    0.06826115:00    0.06089015:30    0.05313616:00    0.03598016:30    0.02456217:00    0.02234117:30    0.01051118:00    0.00431018:30    0.00304919:00    0.00385519:30    0.00449120:00    0.002016Name: CustomerID, dtype: float64plot_bar(order_by_hour_half, 'half an hour', '# orders', 'order by half an hour')개인화된 push notification  아마존을 필두로, 개인화(personalization)하여 맞춤으로 사용자마다 최적의 솔루션을 찾는것이 트렌드가 됨  사용자별로 소비의 패턴이 다를 수 있기 때문에, 가장 많이 구매한 시간대를 찾아서 해당 시간대에 쿠폰을 발송!사용자별 각 시간별 주문 량 계산하기order_count_by_hour = retail.set_index('InvoiceDate').groupby(['CustomerID', lambda date: date.hour]).count()['StockCode']order_count_by_hour #12346 ID 는 10 시에 1건 , 12347  ID는 8 시에 22건 CustomerID    12346       10     112347       8     22            10    24            12    47            13    18                  ..18283       15     1            16    56            19    8718287       9      3            10    67Name: StockCode, Length: 11205, dtype: int64order_count_by_hour.loc[12347] #2시에 가장 많은 주문을 함8     2210    2412    4713    1814    6015    11Name: StockCode, dtype: int64사용자별 최대 주문 시간 계산하기  가장 많은 주문량을 보인 시간을 계산order_count_by_hour.groupby('CustomerID').idxmax() #idxmax 함수는 최댓값을 가진 index를 반환한다CustomerID12346    (12346, 10)12347    (12347, 14)12348    (12348, 19)12349     (12349, 9)12350    (12350, 16)            ...     18280     (18280, 9)18281    (18281, 10)18282    (18282, 13)18283    (18283, 14)18287    (18287, 10)Name: StockCode, Length: 4338, dtype: objectidx = order_count_by_hour.groupby('CustomerID').idxmax() #idxmax 함수는 최댓값을 가진 index를 반환한다해당 시간 indexingresult = order_count_by_hour.loc[idx]resultCustomerID    12346       10      112347       14     6012348       19     1712349       9      7312350       16     17                 ... 18280       9      1018281       10      718282       13      718283       14    20118287       10     67Name: StockCode, Length: 4338, dtype: int64result.reset_index()                  CustomerID      level_1      StockCode                  0      12346      10      1              1      12347      14      60              2      12348      19      17              3      12349      9      73              4      12350      16      17              ...      ...      ...      ...              4333      18280      9      10              4334      18281      10      7              4335      18282      13      7              4336      18283      14      201              4337      18287      10      67      4338 rows × 3 columnsresult.reset_index().groupby('level_1').groups #시간대별로 그룹화하기{7: [73, 269, 319, 344, 375, 893, 1667, 2317], 8: [46, 58, 87, 126, 172, 179, 187, 260, 278, 279, 282, 292, 306, 347, 399, 429, 496, 503, 526, 533, 549, 552, 651, 671, 747, 755, 784, 792, 800, 803, 806, 821, 838, 877, 883, 920, 944, 947, 951, 954, 1008, 1093, 1106, 1120, 1138, 1172, 1173, 1217, 1251, 1397, 1422, 1424, 1436, 1472, 1512, 1616, 1621, 1666, 1668, 1678, 1687, 1734, 1759, 1761, 1774, 1791, 1815, 1827, 1846, 1859, 1895, 1900, 1903, 1996, 2018, 2023, 2054, 2085, 2108, 2117, 2167, 2172, 2253, 2380, 2383, 2403, 2404, 2417, 2427, 2462, 2464, 2643, 2749, 2776, 2781, 2896, 2936, 2949, 3021, 3130, ...], 9: [3, 9, 26, 30, 33, 35, 37, 48, 60, 66, 75, 84, 86, 90, 100, 106, 107, 121, 127, 135, 138, 142, 144, 146, 154, 159, 181, 199, 230, 240, 264, 265, 267, 277, 280, 286, 294, 298, 328, 333, 336, 342, 343, 352, 362, 366, 385, 402, 421, 459, 470, 475, 478, 482, 483, 509, 517, 519, 574, 603, 615, 630, 636, 642, 644, 691, 701, 706, 707, 746, 749, 752, 764, 770, 781, 783, 818, 825, 829, 844, 859, 874, 887, 925, 934, 950, 969, 981, 992, 998, 1003, 1004, 1016, 1032, 1038, 1045, 1050, 1053, 1063, 1082, ...], 10: [0, 11, 21, 27, 28, 41, 42, 45, 49, 51, 55, 61, 77, 93, 94, 103, 104, 105, 110, 113, 122, 132, 137, 140, 147, 150, 155, 156, 165, 168, 169, 174, 178, 182, 186, 195, 205, 206, 208, 216, 217, 222, 231, 233, 242, 251, 252, 255, 263, 275, 276, 287, 288, 290, 293, 301, 310, 314, 322, 331, 337, 339, 341, 348, 359, 360, 361, 363, 364, 365, 379, 381, 407, 437, 439, 441, 443, 450, 464, 465, 468, 471, 481, 499, 500, 511, 516, 529, 541, 553, 560, 563, 570, 578, 584, 586, 590, 591, 595, 596, ...], 11: [29, 32, 34, 57, 99, 102, 111, 124, 139, 148, 163, 171, 176, 188, 207, 220, 223, 228, 234, 246, 253, 254, 256, 266, 272, 311, 313, 315, 324, 326, 330, 346, 349, 355, 356, 380, 393, 400, 419, 423, 424, 427, 430, 431, 449, 458, 462, 485, 487, 515, 521, 528, 542, 545, 550, 559, 567, 569, 575, 605, 616, 635, 648, 650, 654, 658, 664, 677, 678, 680, 692, 693, 694, 702, 712, 729, 744, 748, 763, 765, 771, 778, 793, 798, 812, 819, 824, 828, 831, 837, 843, 846, 851, 856, 866, 868, 869, 873, 875, 903, ...], 12: [12, 20, 22, 36, 50, 62, 64, 67, 72, 74, 81, 116, 120, 123, 145, 151, 158, 160, 164, 189, 191, 193, 200, 203, 209, 226, 237, 238, 241, 243, 244, 245, 249, 259, 270, 271, 284, 297, 305, 308, 317, 327, 332, 335, 350, 357, 367, 371, 376, 377, 388, 390, 391, 397, 398, 403, 404, 414, 415, 418, 428, 432, 435, 436, 440, 451, 460, 473, 477, 488, 489, 490, 492, 495, 504, 510, 525, 540, 565, 568, 577, 582, 585, 594, 598, 599, 611, 612, 613, 622, 624, 625, 631, 634, 643, 649, 653, 655, 666, 675, ...], 13: [7, 8, 14, 16, 18, 23, 43, 44, 52, 59, 70, 71, 76, 82, 83, 97, 98, 108, 112, 114, 115, 119, 143, 149, 166, 167, 183, 190, 198, 201, 202, 204, 212, 213, 225, 227, 232, 236, 239, 257, 258, 262, 300, 303, 312, 329, 340, 351, 353, 368, 369, 372, 374, 382, 383, 384, 394, 396, 406, 416, 417, 422, 438, 445, 448, 452, 455, 456, 466, 474, 493, 505, 506, 512, 534, 535, 537, 548, 551, 556, 561, 581, 601, 609, 610, 614, 617, 623, 632, 639, 647, 659, 660, 668, 669, 676, 681, 684, 685, 687, ...], 14: [1, 5, 25, 31, 38, 40, 54, 56, 69, 78, 79, 85, 88, 95, 96, 101, 109, 118, 125, 129, 130, 131, 141, 152, 162, 173, 175, 177, 196, 197, 215, 219, 221, 247, 273, 281, 291, 295, 296, 318, 325, 334, 354, 358, 389, 395, 401, 405, 408, 412, 413, 425, 433, 457, 461, 463, 480, 486, 491, 494, 501, 507, 520, 522, 524, 530, 538, 539, 555, 557, 562, 572, 573, 579, 583, 588, 589, 618, 626, 627, 640, 641, 645, 646, 661, 663, 665, 696, 697, 699, 720, 725, 726, 735, 745, 760, 761, 799, 801, 809, ...], 15: [13, 15, 17, 24, 65, 68, 91, 92, 117, 134, 136, 161, 170, 180, 184, 194, 211, 214, 218, 229, 235, 250, 268, 274, 285, 299, 304, 307, 309, 338, 345, 373, 378, 386, 392, 409, 410, 411, 434, 444, 446, 467, 476, 479, 497, 498, 502, 513, 514, 527, 531, 532, 536, 544, 564, 566, 576, 592, 600, 602, 607, 619, 620, 621, 629, 638, 674, 689, 705, 714, 734, 739, 740, 777, 787, 789, 791, 796, 804, 814, 823, 827, 832, 855, 857, 861, 882, 888, 900, 902, 935, 938, 941, 952, 953, 962, 972, 977, 979, 982, ...], 16: [4, 10, 19, 39, 53, 128, 133, 157, 192, 210, 224, 248, 302, 316, 323, 370, 387, 420, 442, 447, 454, 469, 472, 484, 518, 523, 543, 546, 554, 558, 580, 587, 604, 628, 657, 662, 672, 682, 704, 788, 794, 833, 834, 847, 850, 908, 930, 940, 964, 970, 999, 1029, 1036, 1048, 1067, 1096, 1107, 1115, 1116, 1144, 1174, 1177, 1189, 1219, 1224, 1239, 1270, 1273, 1279, 1288, 1314, 1322, 1331, 1343, 1355, 1359, 1366, 1377, 1380, 1468, 1473, 1477, 1484, 1488, 1490, 1500, 1506, 1526, 1564, 1566, 1574, 1585, 1638, 1676, 1692, 1772, 1799, 1820, 1834, 1848, ...], 17: [6, 63, 89, 153, 185, 261, 283, 289, 321, 426, 508, 547, 571, 593, 652, 670, 703, 719, 722, 754, 836, 845, 907, 936, 1019, 1088, 1140, 1188, 1240, 1296, 1379, 1489, 1540, 1578, 1588, 1590, 1603, 1628, 1640, 1642, 1679, 1739, 1742, 1889, 1906, 1940, 2058, 2156, 2169, 2274, 2279, 2340, 2374, 2408, 2443, 2515, 2566, 2568, 2583, 2594, 2602, 2621, 2644, 2661, 2853, 2856, 2886, 2928, 2948, 2978, 2995, 3004, 3069, 3102, 3141, 3173, 3185, 3226, 3230, 3277, 3323, 3401, 3404, 3425, 3443, 3461, 3462, 3466, 3512, 3543, 3559, 3598, 3639, 3659, 3677, 3690, 3716, 3727, 3736, 3739, ...], 18: [80, 320, 453, 637, 767, 862, 879, 1128, 1326, 1378, 1498, 1519, 1624, 1652, 1758, 1768, 1844, 2879, 3198, 3467, 3511, 3537, 3767, 3802, 3820, 3837, 4072, 4077, 4079, 4273], 19: [2, 47, 667, 1589, 1591, 1639, 1730, 1776, 1928, 2044, 2448, 2548, 2876, 3002, 3047, 3261, 3274, 3479, 3556, 3652, 3685, 3789, 3812, 4324], 20: [1646, 1943, 3804, 3838, 4050, 4110]}  시간대별로 어떤 고객이 가장많은 주문을 했는지 확인가능",
        "url": "/pushnotification-Data"
    }
    ,
    
    "marketing-data": {
        "title": "마케팅 데이터 분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)Domain Knowledge 2 : 광고성과지표온라인 광고 클릭률(CTR)광고 클릭률은 클릭수를 광고가 보여진 횟수(노출, Impression)로 나눈 것을 의미하며, 백분율로 나타낸다.예를 들어 방문자에게 배너 광고가 100번 보여지고(100번 노출) 한 번의 클릭이 발생한다면, 그 광고의 클릭률은 1%가 된다.cpmCPM은 1000회 노출당 비용을 의미하는 ‘cost per 1000 impressions’의 약자입니다. CPM 광고를 게재하는 광고주는 광고가 1000회 게재될 때 지급하려는 금액을 설정하고 광고를 게재할 특정 광고 게재위치를 선택하고 광고가 게재될 때마다 비용을 지급합니다.cpc광고 클릭에 대해 광고주가 지불하는 평균 금액입니다. 평균 클릭당비용(평균 CPC)은 총 클릭 비용을 총 클릭수로 나누어 계산합니다.평균 CPC는 광고 클릭 1회에 대해 청구되는 실제 비용인 실제 클릭당비용(실제 CPC)을 기반으로 합니다. 평균 CPC는 광고 클릭 1회당 지불할 의사가 있는 최대 금액인 최대 클릭당비용(최대 CPC)과 다를 수 있습니다.다음은 평균 CPC를 계산하는 방법의 예입니다. 광고 클릭이 2회 발생하여 각각 200원, 400원의 비용이 발생했다면 광고 클릭에 따른 총 비용은 600원이 됩니다. 600원(총 비용)을 2(총 클릭수)로 나누면 평균 CPC인 300원이 산출됩니다.cpa광고로부터의 전환에 대해 광고주에게 청구되는 평균 금액입니다. 평균 전환당비용(CPA)은 총 전환 비용을 총 전환수로 나눈 값입니다.가령 특정 광고에서 2개의 전환이 발생해 하나는 2천 원, 다른 하나는 4천 원의 비용이 소요된 경우 전체 전환에 대한 평균 CPA는 3천 원이 됩니다.평균 CPA는 실제 CPA(광고로부터의 전환에 대해 청구되는 실제 금액)를 기준으로 합니다. 실제 CPA는 타겟 CPA(타겟 CPA 입찰 사용 시 광고주가 원하는 평균 CPA로 설정한 금액)와 다를 수 있습니다.캠페인 그룹 내의 모든 캠페인에 대한 평균 CPA 타겟을 설정하려면 실적 타겟을 사용합니다.imp=10000 #노출수 clk=100 #클릭수conv=10 #구매수cost=100000  #광고비용# ctrctr = clk/imp*100#ctr 출력ctr1.0# cpmcpm=cost/imp*1000#cpm 출력cpm10000.0# cpccpc=cost/clk#cpc 출력cpc1000.0# cpa cpa=cost/conv#cpa 출력cpa10000.0Matplotlib- 시각화 라이브러리# 데이터 분석과정과 시각화  머신러닝의 과정          데이터 수집      데이터 전처리      데이터 탐색 ★      모델 선택      모델 평가 및 적용      # 시각화의 필요성  대량의 데이터 파악 가능  데이터의 패턴 파악 가능import matplotlib.pyplot as pltimport pandas as pdfrom pandas import DataFramefrom pandas import Series# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlibfrom matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   import pandas as pdfrom pandas import DataFramefrom pandas import Seriesdf=pd.read_excel('naverreport.xls',skiprows=[0]) #skiprows = [행1,행2,..] 를 이용하면 지정한 행을 제외한 나머지 행만 보여준다.df                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903              ...      ...      ...      ...      ...      ...      ...      ...              1376      올인원 패키지 : 업무자동화_3. 엑셀      엑셀셀서식      24016      0.0      0.000000      0.000000      0              1377      올인원 패키지 : 업무자동화_3. 엑셀      MATCH      32287      0.0      0.000000      0.000000      0              1378      마케팅KPI수립      LTV      32602      0.0      0.000000      0.000000      0              1379      data_camp_rmp_8      DECISION      60844      0.0      0.000000      0.000000      0              1380      4. 웹의 동작      REST      61193      0.0      0.000000      0.000000      0      1381 rows × 7 columns((((df['노출수'].sort_values())/1000).reset_index()).drop('index',axis=1)).plot(figsize=[13,5])plt.yticks([0,2000,4000,6000,8000,10000],[0,'2,000,000','4,000,000','6,000,000','8,000,000','10,000,000'])plt.title('노출수 plot',fontsize=20)plt.show()  시각화 라이브러리 matplotlib  matplotlib은 pandas의 데이터프레임, 시리즈 자료구조와 함께 사용 가능  따라서 데이터 처리와 동시에 시각화도 함께 진행할 수 있음  아나콘다(anaconda)를 설치했다면 별도의 설치과정이 필요 없음# matplotlib importimport matplotlib.pyplot as plt# pandas, DataFrame, Series importimport pandas as pdfrom pandas import DataFramefrom pandas import Series# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlibfrom matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   # 데이터프레임 시각화#데이터프레임 변수 생성dict_data={\"철수\":[1,2,3,4],\"영희\":[2,3,4,5],\"민수\":[3,4,5,6],\"수진\":[4,5,6,7]}df=DataFrame(dict_data)df                  철수      영희      민수      수진                  0      1      2      3      4              1      2      3      4      5              2      3      4      5      6              3      4      5      6      7      # 차트 그리기# 선그래프 df.plot()plt.show()# 막대그래프df.plot.bar()plt.show()# 가로막대그래프df.plot.barh()plt.show()# 히스토그램df.plot.hist()plt.show()# 히스토그램 구간설정df.plot.hist(bins=range(1,9,1))# 1부터 9미만 범위 안에 하나씩 증가한다plt.show()# 차트에 옵션 추가하기# 기본 막대그래프df.plot.bar()plt.show()# 그래프 크기 설정df.plot.bar(figsize=[10,6])#x축,y축plt.show()# 제목설정df.plot.bar(figsize=[11,7])plt.title('예제')plt.show()# 제목 폰트 크기 설정df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.show()# x축 이름 설정df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel')plt.show()# x축 이름 및 폰트크기 설정df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.show()# y축 이름 및 폰트 크기 설정 df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.ylabel('ylabel',fontsize=16)plt.show()# x축 눈금설정# 설정할 눈금의 위치, 눈금의 이름, 폰트사이즈, 각도df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.ylabel('ylabel',fontsize=16)plt.xticks([0,1,2,3],['첫째','둘째','셋째','넷째'],fontsize=10,rotation=0) #rotation으로 정상적인 각도로 출력할 수 있다.plt.show()# y축 눈금설정df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.ylabel('ylabel',fontsize=16)plt.xticks([0,1,2,3],['첫째','둘째','셋째','넷째'],fontsize=10,rotation=0) #rotation으로 정상적인 각도로 출력할 수 있다.plt.yticks([1,3,5,7],['첫째','셋째','다섯째','일곱번째'])plt.show()# x축 범위설정df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.ylabel('ylabel',fontsize=16)plt.xticks([0,1,2,3],['첫째','둘째','셋째','넷째'],fontsize=10,rotation=0) #rotation으로 정상적인 각도로 출력할 수 있다.plt.yticks([1,3,5,7],['첫째','셋째','다섯째','일곱번째'])plt.xlim([-1,4]) #x축 범위 설정plt.show()# y축 범위설정df.plot.bar(figsize=[11,7])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.ylabel('ylabel',fontsize=16)plt.xticks([0,1,2,3],['첫째','둘째','셋째','넷째'],fontsize=10,rotation=0) #rotation으로 정상적인 각도로 출력할 수 있다.plt.yticks([1,3,5,7],['첫째','셋째','다섯째','일곱번째'])plt.xlim([-1,4]) #x축 범위 설정plt.ylim([-1,8]) #y축 범위 설정plt.show()# 시리즈 시각화# 데이터프레임 열 = 시리즈df['철수']0    11    22    33    4Name: 철수, dtype: int64# 선그래프df['철수'].plot()plt.show()# 막대그래프df['철수'].plot.bar()plt.show()# 가로막대그래프df['철수'].plot.barh()plt.show()# 히스토그램(구간설정)df['철수'].plot.hist(bins=range(1,6,1))plt.show()# 차트에 옵션 추가하기df['철수'].plot.bar()plt.show()df['철수'].plot.bar(figsize=[10,6])plt.title('예제',fontsize=18)plt.xlabel('xlabel',fontsize=16)plt.ylabel('ylabel',fontsize=16)plt.xticks([0,1,2,3],['첫째','둘째','셋째','넷째'],fontsize=10,rotation=0) #rotation으로 정상적인 각도로 출력할 수 있다.plt.yticks([1,3,5,7],['첫째','셋째','다섯째','일곱번째'])plt.xlim([-1,4]) #x축 범위 설정plt.ylim([-1,8]) #y축 범위 설정plt.show()",
        "url": "/marketing-Data"
    }
    ,
    
    "keyword-data": {
        "title": "키워드 데이터 분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)패스트캠퍼스 키워드 데이터 분석import pandas as pd from pandas import DataFramefrom pandas import Seriesimport seaborn as snsimport matplotlib.pyplot as plt# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlibfrom matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   df=pd.read_excel('naverreport.xls')df.head()                  캠페인보고서(2019.02.01.~2019.04.30.),ftasia      Unnamed: 1      Unnamed: 2      Unnamed: 3      Unnamed: 4      Unnamed: 5      Unnamed: 6                  0      광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              1      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      261.549448      2512444              2      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      295.974808      2384965              3      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4841.66358      1568699              4      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174      df=pd.read_excel('naverreport.xls',skiprows=[0])df.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903      키워드 기준 groupgrouped = df.groupby('키워드')grouped&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000124B3781EE0&gt;grouped.count()                  광고그룹      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                      -      8      8      8      8      8      8              10억건물      1      1      1      1      1      1              11번가상품등록      1      1      1      1      1      1              11번가입점      1      1      1      1      1      1              11번가판매자      1      1      1      1      1      1              ...      ...      ...      ...      ...      ...      ...              회계      1      1      1      1      1      1              회계책      1      1      1      1      1      1              회사분위기      1      1      1      1      1      1              회사소개서      1      1      1      1      1      1              후위표기법      1      1      1      1      1      1      1112 rows × 6 columnsgrouped.mean()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                -      510444.5      2636.7      0.516004      388.533776      848233.375              10억건물      1976.0      2.4      0.121457      1283.333333      3080.000              11번가상품등록      1034.0      1.2      0.116054      2667.500000      3201.000              11번가입점      1580.0      1.2      0.075949      522.500000      627.000              11번가판매자      4948.0      3.6      0.072757      275.000000      990.000              ...      ...      ...      ...      ...      ...              회계      3269.0      0.0      0.000000      0.000000      0.000              회계책      3742.0      0.0      0.000000      0.000000      0.000              회사분위기      3599.0      1.2      0.033343      64.166667      77.000              회사소개서      5592.0      0.0      0.000000      0.000000      0.000              후위표기법      1516.0      0.0      0.000000      0.000000      0.000      1112 rows × 5 columnsgrouped.median()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                -      114258.5      608.4      0.428236      317.072650      301988.5              10억건물      1976.0      2.4      0.121457      1283.333333      3080.0              11번가상품등록      1034.0      1.2      0.116054      2667.500000      3201.0              11번가입점      1580.0      1.2      0.075949      522.500000      627.0              11번가판매자      4948.0      3.6      0.072757      275.000000      990.0              ...      ...      ...      ...      ...      ...              회계      3269.0      0.0      0.000000      0.000000      0.0              회계책      3742.0      0.0      0.000000      0.000000      0.0              회사분위기      3599.0      1.2      0.033343      64.166667      77.0              회사소개서      5592.0      0.0      0.000000      0.000000      0.0              후위표기법      1516.0      0.0      0.000000      0.000000      0.0      1112 rows × 5 columnsgrouped.sum()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                -      4083556      21093.6      4.128033      3108.270211      6785867              10억건물      1976      2.4      0.121457      1283.333333      3080              11번가상품등록      1034      1.2      0.116054      2667.500000      3201              11번가입점      1580      1.2      0.075949      522.500000      627              11번가판매자      4948      3.6      0.072757      275.000000      990              ...      ...      ...      ...      ...      ...              회계      3269      0.0      0.000000      0.000000      0              회계책      3742      0.0      0.000000      0.000000      0              회사분위기      3599      1.2      0.033343      64.166667      77              회사소개서      5592      0.0      0.000000      0.000000      0              후위표기법      1516      0.0      0.000000      0.000000      0      1112 rows × 5 columnsdf_group=grouped.sum()df_group                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                -      4083556      21093.6      4.128033      3108.270211      6785867              10억건물      1976      2.4      0.121457      1283.333333      3080              11번가상품등록      1034      1.2      0.116054      2667.500000      3201              11번가입점      1580      1.2      0.075949      522.500000      627              11번가판매자      4948      3.6      0.072757      275.000000      990              ...      ...      ...      ...      ...      ...              회계      3269      0.0      0.000000      0.000000      0              회계책      3742      0.0      0.000000      0.000000      0              회사분위기      3599      1.2      0.033343      64.166667      77              회사소개서      5592      0.0      0.000000      0.000000      0              후위표기법      1516      0.0      0.000000      0.000000      0      1112 rows × 5 columns#클릭률(ctr) = 클릭수 / 노출수#데이터전처리 - 데이터프레임의 열 단위 수치연산df_group['클릭률(%)']=df_group['클릭수']/df_group['노출수']df_group.head()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                10억건물      1976      2.4      0      1283      3080              11번가상품등록      1034      1.2      0      2668      3201              11번가입점      1580      1.2      0      522      627              11번가판매자      4948      3.6      0      275      990              1인미디어      37024      31.2      0      1828      57035      # 평균클릭비용 칼럼 반올림처리(round), 소수점 제거(astype(int)df_group['평균클릭비용(VAT포함,원)']=round(df_group['평균클릭비용(VAT포함,원)'],0)df_group['평균클릭비용(VAT포함,원)']=df_group['평균클릭비용(VAT포함,원)'].astype(int)df_group.head()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                -      4083556      21093.6      0.005165      3108      6785867              10억건물      1976      2.4      0.001215      1283      3080              11번가상품등록      1034      1.2      0.001161      2668      3201              11번가입점      1580      1.2      0.000759      522      627              11번가판매자      4948      3.6      0.000728      275      990      df_group['클릭률(%)']=round(df_group['클릭률(%)'],0)df_group['클릭률(%)']=df_group['클릭률(%)'].astype(int)df_group.head()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                -      4083556      21093.6      0      3108      6785867              10억건물      1976      2.4      0      1283      3080              11번가상품등록      1034      1.2      0      2668      3201              11번가입점      1580      1.2      0      522      627              11번가판매자      4948      3.6      0      275      990      df_group.drop(['-'],inplace=True)df_group                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                10억건물      1976      2.4      0      1283      3080              11번가상품등록      1034      1.2      0      2668      3201              11번가입점      1580      1.2      0      522      627              11번가판매자      4948      3.6      0      275      990              1인미디어      37024      31.2      0      1828      57035              ...      ...      ...      ...      ...      ...              회계      3269      0.0      0      0      0              회계책      3742      0.0      0      0      0              회사분위기      3599      1.2      0      64      77              회사소개서      5592      0.0      0      0      0              후위표기법      1516      0.0      0      0      0      1111 rows × 5 columns데이터 시각화df_group['클릭수'].plot()plt.xticks(fontsize=5) #x라벨 size 조절(10억건물등...)plt.show()imp=df_group['노출수']clk=df_group['클릭수']result = df_group[(imp&gt;imp.quantile(0.95))&amp;(clk&gt;clk.quantile(0.95))]result                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                HTML      10540218      894.0      0      2602      1241867              가상화폐      91369      2838.0      0      283      803770              글씨체      106648      216.0      0      425      91806              마블      907619      228.0      0      265      60533              마케팅      392941      241.2      0      3431      280742              바이럴마케팅      3095998      261.6      0      220      57563              블록체인      347748      3117.6      0      4914      975172              스케치      300594      168.0      0      1959      182864              에프터이펙트      113863      282.0      0      8629      270996              엑셀      2043217      541.2      0      2081      668206              영상편집      140077      372.0      0      7585      862763              인디자인      187745      562.8      0      5824      246026              일러스트      1238949      358.8      0      8992      1713129              일러스트레이터      250333      783.6      0      5623      280170              컴퓨터활용능력      139729      1534.8      0      239      367147              컴퓨터활용능력1급      94757      1191.6      0      237      282018              컴퓨터활용능력2급      88751      1282.8      0      234      300058              코딩      562162      271.2      0      3243      879560              파이썬      418986      272.4      0      6070      978450              펀드      157068      208.8      0      468      53097              포토샵      3731749      3218.4      0      5167      1527383              폰트      478588      474.0      0      396      187693              프리미어프로      340821      171.6      0      2775      255299      bar = result['클릭수'].plot.bar(grid=True)plt.xticks(fontsize=8) #x라벨 size 조절(10억건물등...)bar.set_xlabel(\"키워드\")plt.show()",
        "url": "/keyword-Data"
    }
    ,
    
    "kde-data": {
        "title": "응용-데이터 기반으로 의사결정 및 kde 밀도 그래프",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  푸쉬 노티피케이션 타임 의사 결정 하기  Matplotlib - 밀도 그래프 : kde관찰값을 사용해서 추정되는 연속된 확률 분포를 그린다.일반적인 과정은 kernel 메서드를 잘 섞어 이 분포를 근사하는 방법이나 이보다 단순한 정규분포이다.그래서 밀도 그래프는 KDE(Kernel Density Estimate : 커넬 밀도 추정)그래프라고도 알려져 있다.plot.kdeplot(kind=’kde’)import numpy as npimport pandas as pd# seabornimport seaborn as snsimport matplotlib.pyplot as pltimport matplotlib.colors #pip install colormap 설치COLORS = sns.color_palette(\"RdBu\", 10)sns.palplot(COLORS)%matplotlib inlinedef plot_bar(df, xlabel, ylabel, title, figsize=(5, 6), color=COLORS[-0], rotation=35):    plot = df.plot(kind='kde', color='k', figsize=figsize)    plot.set_xlabel(xlabel, fontsize=10)    plot.set_ylabel(ylabel, fontsize=10)    plot.set_title(title, fontsize=12)    plot.set_xticklabels(labels=df.index, rotation=rotation)  kind 옵션:line: 선 그래프bar: 바 그래프barh: 수평 바 프래프hist: 히스토르램kde: 커널 밀도 그래프hexbin: 고밀도 산점도 그래프box: 박스 플롯area: 면적 그래프pie: 파이 그래프scatter: 산점도 그래프dtypes = {    'UnitPrice': np.float32,    'CustomerID': np.int32,    'Quantity': np.int32}retail = pd.read_csv('./OnlineRetailClean.csv', dtype=dtypes)retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'], infer_datetime_format=True)retail.head()                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice                  0      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      2010-12-01 08:26:00      2.55      17850      United Kingdom      15.30              1      1      536365      71053      WHITE METAL LANTERN      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34              2      2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      2010-12-01 08:26:00      2.75      17850      United Kingdom      22.00              3      3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34              4      4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34      쿠폰 발송을 할때, push를 언제 보내는게 좋을까?  고객에게 쿠폰 발송을 한다고 기획하고, 회의를 한다고 가정해보겠습니다.  A: 쿠폰을 언제보내는게 좋을까요?  B: 아침에 출퇴근 시간에 보내는게 좋을까요?  C: 점심 먹고 졸린데 그때 보내보죠?  D: 흠 자기전에 스마트폰 많이 하던데 그때는 어떨까요?  A: 그러면 평균 시간을 내볼까요?      K: 아 데이터를 확인해보는게 맞지 않을까요? 언제 고객이 주로 주문을 하는지?    위에서 처럼 실제로 회의를 하다보면 의사결정이 본인/주변의 경험에 의해서 이뤄지는 것을 많이 볼 수 있습니다.  주문이 이뤄지는 시간을 고려하지 않고 막무가내로 보낸다면 아무 의미가 없고, 추후 같은 이벤트 발생시에도 판단 근거가 없게 됨  현상태에서는 가장 많이 주문이 일어나는 시점에서 하는 것이 가장 직관적인 판단                            데이터로 파악                                      가설 제시                                      가설 검증                                      1-3 반복                      시간(hour, minute)과 주로 관련되기 때문에 역시 InvoiceDate가 중요한 featureorder_by_hour = retail.set_index('InvoiceDate').groupby(lambda date: date.hour).count()order_by_hour                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      UnitPrice      CustomerID      Country      CheckoutPrice                  6      1      1      1      1      1      1      1      1      1              7      379      379      379      379      379      379      379      379      379              8      8690      8690      8690      8690      8690      8690      8690      8690      8690              9      21944      21944      21944      21944      21944      21944      21944      21944      21944              10      37997      37997      37997      37997      37997      37997      37997      37997      37997              11      49084      49084      49084      49084      49084      49084      49084      49084      49084              12      72065      72065      72065      72065      72065      72065      72065      72065      72065              13      64026      64026      64026      64026      64026      64026      64026      64026      64026              14      54118      54118      54118      54118      54118      54118      54118      54118      54118              15      45369      45369      45369      45369      45369      45369      45369      45369      45369              16      24089      24089      24089      24089      24089      24089      24089      24089      24089              17      13071      13071      13071      13071      13071      13071      13071      13071      13071              18      2928      2928      2928      2928      2928      2928      2928      2928      2928              19      3321      3321      3321      3321      3321      3321      3321      3321      3321              20      802      802      802      802      802      802      802      802      802      order_by_hour = retail.set_index('InvoiceDate').groupby(lambda date: date.hour).count()['CustomerID']order_by_hour6         17       3798      86909     2194410    3799711    4908412    7206513    6402614    5411815    4536916    2408917    1307118     292819     332120      802Name: CustomerID, dtype: int64plot_bar(order_by_hour, 'hour', '# orders', 'Order by hour')&lt;ipython-input-2-3b6cb782caa3&gt;:6: UserWarning: FixedFormatter should only be used together with FixedLocator  plot.set_xticklabels(labels=df.index, rotation=rotation)def half_an_hour(date):    minute = ':00'    if date.minute &gt; 30:        minute = ':30'    hour = str(date.hour)    if date.hour &lt; 10:        hour = '0' + hour        return hour + minuteorder_by_hour_half = retail.set_index('InvoiceDate').groupby(half_an_hour).count()['CustomerID']order_by_hour_half06:00        107:30      37908:00     314508:30     554509:00     936409:30    1258010:00    1695010:30    2104711:00    1892511:30    3015912:00    3717412:30    3489113:00    3113113:30    3289514:00    2695814:30    2716015:00    2422715:30    2114216:00    1431616:30     977317:00     888917:30     418218:00     171518:30     121319:00     153419:30     178720:00      802Name: CustomerID, dtype: int64order_by_hour_half / order_by_hour_half.sum()06:00    0.00000307:30    0.00095308:00    0.00790408:30    0.01393609:00    0.02353409:30    0.03161710:00    0.04260010:30    0.05289711:00    0.04756411:30    0.07579812:00    0.09342912:30    0.08769113:00    0.07824113:30    0.08267514:00    0.06775314:30    0.06826115:00    0.06089015:30    0.05313616:00    0.03598016:30    0.02456217:00    0.02234117:30    0.01051118:00    0.00431018:30    0.00304919:00    0.00385519:30    0.00449120:00    0.002016Name: CustomerID, dtype: float64plot_bar(order_by_hour_half, 'half an hour', '# orders', 'order by half an hour')&lt;ipython-input-2-3b6cb782caa3&gt;:6: UserWarning: FixedFormatter should only be used together with FixedLocator  plot.set_xticklabels(labels=df.index, rotation=rotation)개인화된 push notification  아마존을 필두로, 개인화(personalization)하여 맞춤으로 사용자마다 최적의 솔루션을 찾는것이 트렌드가 됨  사용자별로 소비의 패턴이 다를 수 있기 때문에, 가장 많이 구매한 시간대를 찾아서 해당 시간대에 쿠폰을 발송!사용자별 각 시간별 주문 량 계산하기order_count_by_hour = retail.set_index('InvoiceDate').groupby(['CustomerID', lambda date: date.hour]).count()['StockCode']order_count_by_hour #12346 ID 는 10 시에 1건 , 12347  ID는 8 시에 22건 CustomerID    12346       10     112347       8     22            10    24            12    47            13    18                  ..18283       15     1            16    56            19    8718287       9      3            10    67Name: StockCode, Length: 11205, dtype: int64order_count_by_hour.loc[12347] #2시에 가장 많은 주문을 함8     2210    2412    4713    1814    6015    11Name: StockCode, dtype: int64사용자별 최대 주문 시간 계산하기  가장 많은 주문량을 보인 시간을 계산order_count_by_hour.groupby('CustomerID').idxmax() #idxmax 함수는 최댓값을 가진 index를 반환한다CustomerID12346    (12346, 10)12347    (12347, 14)12348    (12348, 19)12349     (12349, 9)12350    (12350, 16)            ...     18280     (18280, 9)18281    (18281, 10)18282    (18282, 13)18283    (18283, 14)18287    (18287, 10)Name: StockCode, Length: 4338, dtype: objectidx = order_count_by_hour.groupby('CustomerID').idxmax() #idxmax 함수는 최댓값을 가진 index를 반환한다해당 시간 indexingresult = order_count_by_hour.loc[idx]resultCustomerID    12346       10      112347       14     6012348       19     1712349       9      7312350       16     17                 ... 18280       9      1018281       10      718282       13      718283       14    20118287       10     67Name: StockCode, Length: 4338, dtype: int64result.reset_index()                  CustomerID      level_1      StockCode                  0      12346      10      1              1      12347      14      60              2      12348      19      17              3      12349      9      73              4      12350      16      17              ...      ...      ...      ...              4333      18280      9      10              4334      18281      10      7              4335      18282      13      7              4336      18283      14      201              4337      18287      10      67      4338 rows × 3 columnsresult.reset_index().groupby('level_1').groups #시간대별로 그룹화하기{7: [73, 269, 319, 344, 375, 893, 1667, 2317], 8: [46, 58, 87, 126, 172, 179, 187, 260, 278, 279, 282, 292, 306, 347, 399, 429, 496, 503, 526, 533, 549, 552, 651, 671, 747, 755, 784, 792, 800, 803, 806, 821, 838, 877, 883, 920, 944, 947, 951, 954, 1008, 1093, 1106, 1120, 1138, 1172, 1173, 1217, 1251, 1397, 1422, 1424, 1436, 1472, 1512, 1616, 1621, 1666, 1668, 1678, 1687, 1734, 1759, 1761, 1774, 1791, 1815, 1827, 1846, 1859, 1895, 1900, 1903, 1996, 2018, 2023, 2054, 2085, 2108, 2117, 2167, 2172, 2253, 2380, 2383, 2403, 2404, 2417, 2427, 2462, 2464, 2643, 2749, 2776, 2781, 2896, 2936, 2949, 3021, 3130, ...], 9: [3, 9, 26, 30, 33, 35, 37, 48, 60, 66, 75, 84, 86, 90, 100, 106, 107, 121, 127, 135, 138, 142, 144, 146, 154, 159, 181, 199, 230, 240, 264, 265, 267, 277, 280, 286, 294, 298, 328, 333, 336, 342, 343, 352, 362, 366, 385, 402, 421, 459, 470, 475, 478, 482, 483, 509, 517, 519, 574, 603, 615, 630, 636, 642, 644, 691, 701, 706, 707, 746, 749, 752, 764, 770, 781, 783, 818, 825, 829, 844, 859, 874, 887, 925, 934, 950, 969, 981, 992, 998, 1003, 1004, 1016, 1032, 1038, 1045, 1050, 1053, 1063, 1082, ...], 10: [0, 11, 21, 27, 28, 41, 42, 45, 49, 51, 55, 61, 77, 93, 94, 103, 104, 105, 110, 113, 122, 132, 137, 140, 147, 150, 155, 156, 165, 168, 169, 174, 178, 182, 186, 195, 205, 206, 208, 216, 217, 222, 231, 233, 242, 251, 252, 255, 263, 275, 276, 287, 288, 290, 293, 301, 310, 314, 322, 331, 337, 339, 341, 348, 359, 360, 361, 363, 364, 365, 379, 381, 407, 437, 439, 441, 443, 450, 464, 465, 468, 471, 481, 499, 500, 511, 516, 529, 541, 553, 560, 563, 570, 578, 584, 586, 590, 591, 595, 596, ...], 11: [29, 32, 34, 57, 99, 102, 111, 124, 139, 148, 163, 171, 176, 188, 207, 220, 223, 228, 234, 246, 253, 254, 256, 266, 272, 311, 313, 315, 324, 326, 330, 346, 349, 355, 356, 380, 393, 400, 419, 423, 424, 427, 430, 431, 449, 458, 462, 485, 487, 515, 521, 528, 542, 545, 550, 559, 567, 569, 575, 605, 616, 635, 648, 650, 654, 658, 664, 677, 678, 680, 692, 693, 694, 702, 712, 729, 744, 748, 763, 765, 771, 778, 793, 798, 812, 819, 824, 828, 831, 837, 843, 846, 851, 856, 866, 868, 869, 873, 875, 903, ...], 12: [12, 20, 22, 36, 50, 62, 64, 67, 72, 74, 81, 116, 120, 123, 145, 151, 158, 160, 164, 189, 191, 193, 200, 203, 209, 226, 237, 238, 241, 243, 244, 245, 249, 259, 270, 271, 284, 297, 305, 308, 317, 327, 332, 335, 350, 357, 367, 371, 376, 377, 388, 390, 391, 397, 398, 403, 404, 414, 415, 418, 428, 432, 435, 436, 440, 451, 460, 473, 477, 488, 489, 490, 492, 495, 504, 510, 525, 540, 565, 568, 577, 582, 585, 594, 598, 599, 611, 612, 613, 622, 624, 625, 631, 634, 643, 649, 653, 655, 666, 675, ...], 13: [7, 8, 14, 16, 18, 23, 43, 44, 52, 59, 70, 71, 76, 82, 83, 97, 98, 108, 112, 114, 115, 119, 143, 149, 166, 167, 183, 190, 198, 201, 202, 204, 212, 213, 225, 227, 232, 236, 239, 257, 258, 262, 300, 303, 312, 329, 340, 351, 353, 368, 369, 372, 374, 382, 383, 384, 394, 396, 406, 416, 417, 422, 438, 445, 448, 452, 455, 456, 466, 474, 493, 505, 506, 512, 534, 535, 537, 548, 551, 556, 561, 581, 601, 609, 610, 614, 617, 623, 632, 639, 647, 659, 660, 668, 669, 676, 681, 684, 685, 687, ...], 14: [1, 5, 25, 31, 38, 40, 54, 56, 69, 78, 79, 85, 88, 95, 96, 101, 109, 118, 125, 129, 130, 131, 141, 152, 162, 173, 175, 177, 196, 197, 215, 219, 221, 247, 273, 281, 291, 295, 296, 318, 325, 334, 354, 358, 389, 395, 401, 405, 408, 412, 413, 425, 433, 457, 461, 463, 480, 486, 491, 494, 501, 507, 520, 522, 524, 530, 538, 539, 555, 557, 562, 572, 573, 579, 583, 588, 589, 618, 626, 627, 640, 641, 645, 646, 661, 663, 665, 696, 697, 699, 720, 725, 726, 735, 745, 760, 761, 799, 801, 809, ...], 15: [13, 15, 17, 24, 65, 68, 91, 92, 117, 134, 136, 161, 170, 180, 184, 194, 211, 214, 218, 229, 235, 250, 268, 274, 285, 299, 304, 307, 309, 338, 345, 373, 378, 386, 392, 409, 410, 411, 434, 444, 446, 467, 476, 479, 497, 498, 502, 513, 514, 527, 531, 532, 536, 544, 564, 566, 576, 592, 600, 602, 607, 619, 620, 621, 629, 638, 674, 689, 705, 714, 734, 739, 740, 777, 787, 789, 791, 796, 804, 814, 823, 827, 832, 855, 857, 861, 882, 888, 900, 902, 935, 938, 941, 952, 953, 962, 972, 977, 979, 982, ...], 16: [4, 10, 19, 39, 53, 128, 133, 157, 192, 210, 224, 248, 302, 316, 323, 370, 387, 420, 442, 447, 454, 469, 472, 484, 518, 523, 543, 546, 554, 558, 580, 587, 604, 628, 657, 662, 672, 682, 704, 788, 794, 833, 834, 847, 850, 908, 930, 940, 964, 970, 999, 1029, 1036, 1048, 1067, 1096, 1107, 1115, 1116, 1144, 1174, 1177, 1189, 1219, 1224, 1239, 1270, 1273, 1279, 1288, 1314, 1322, 1331, 1343, 1355, 1359, 1366, 1377, 1380, 1468, 1473, 1477, 1484, 1488, 1490, 1500, 1506, 1526, 1564, 1566, 1574, 1585, 1638, 1676, 1692, 1772, 1799, 1820, 1834, 1848, ...], 17: [6, 63, 89, 153, 185, 261, 283, 289, 321, 426, 508, 547, 571, 593, 652, 670, 703, 719, 722, 754, 836, 845, 907, 936, 1019, 1088, 1140, 1188, 1240, 1296, 1379, 1489, 1540, 1578, 1588, 1590, 1603, 1628, 1640, 1642, 1679, 1739, 1742, 1889, 1906, 1940, 2058, 2156, 2169, 2274, 2279, 2340, 2374, 2408, 2443, 2515, 2566, 2568, 2583, 2594, 2602, 2621, 2644, 2661, 2853, 2856, 2886, 2928, 2948, 2978, 2995, 3004, 3069, 3102, 3141, 3173, 3185, 3226, 3230, 3277, 3323, 3401, 3404, 3425, 3443, 3461, 3462, 3466, 3512, 3543, 3559, 3598, 3639, 3659, 3677, 3690, 3716, 3727, 3736, 3739, ...], 18: [80, 320, 453, 637, 767, 862, 879, 1128, 1326, 1378, 1498, 1519, 1624, 1652, 1758, 1768, 1844, 2879, 3198, 3467, 3511, 3537, 3767, 3802, 3820, 3837, 4072, 4077, 4079, 4273], 19: [2, 47, 667, 1589, 1591, 1639, 1730, 1776, 1928, 2044, 2448, 2548, 2876, 3002, 3047, 3261, 3274, 3479, 3556, 3652, 3685, 3789, 3812, 4324], 20: [1646, 1943, 3804, 3838, 4050, 4110]}  시간대별로 어떤 고객이 가장많은 주문을 했는지 확인가능",
        "url": "/kde-Data"
    }
    ,
    
    "goodcustomer-data": {
        "title": "우수고객 선별하기(가장 소비를 많이 한 고객),고객 코호트 분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)학습목표  소비 우수고객 찾기  고객 retentionfrom datetime import datetimeimport numpy as npimport pandas as pdimport seaborn as snsfrom matplotlib import pyplot as plt%matplotlib inline  seaborn은 matplotlib 처럼 그래프를 그리는 기능이다(matplotlib으로 그래프 그리는 꿀팁이 궁금하다면?). matplotlip으로도 대부분의 시각화는 가능하지만 아래와 같은 이유들로 seaborn을 더 선호하는 추세이다.  seaborn에서만 제공되는 통계 기반 plot  특별하게 꾸미지 않아도 깔끔하게 구현되는 기본 color  더 아름답게 그래프 구현이 가능한 palette 기능            pandas 데이터프레임과 높은 호환성      hue 옵션으로 bar 구분이 가능하며, xtick, ytick, xlabel, ylabel, legend 등이 추가적인 코딩 작업없이 자동으로 세팅된다.      dtypes = {    'UnitPrice': np.float32,    'CustomerID': np.int32,    'Quantity': np.int32}retail = pd.read_csv('./OnlineRetailClean.csv', dtype=dtypes)retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'], infer_datetime_format=True) #      infer_datetime_format=True 날짜시간 포맷 추정해서 파싱하기retail.head()                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice                  0      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      2010-12-01 08:26:00      2.55      17850      United Kingdom      15.30              1      1      536365      71053      WHITE METAL LANTERN      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34              2      2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      2010-12-01 08:26:00      2.75      17850      United Kingdom      22.00              3      3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34              4      4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34      우수 고객 확인  구매 횟수 기준  지불 금액 기준retail.groupby('CustomerID').count()['Quantity'].sort_values(ascending=False)CustomerID17841    784714911    567514096    511112748    459514606    2700         ... 17846       113017       113099       113106       112346       1Name: Quantity, Length: 4338, dtype: int64retail.groupby('CustomerID').sum()['CheckoutPrice'].sort_values(ascending=False)CustomerID14646    280206.0218102    259657.3017450    194550.7916446    168472.5014911    143825.06           ...    16878        13.3017956        12.7516454         6.9014792         6.2016738         3.75Name: CheckoutPrice, Length: 4338, dtype: float64사용자 retention 분석  월간 사용자 cohort를 바탕으로 월별 재구매율(retention) 분석하기  heatmap으로 한눈에 재구매율을 파악 가능-사용자 기준으로 최초 구매한 월(month) 연산하기  Month : 구매월(일(day)을 무시)  MonthStarted: 사용자가 최초 구매한 달def get_month_as_datetime(date):    return datetime(date.year, date.month, 1) #년,월,일 retail['Month'] = retail['InvoiceDate'].apply(get_month_as_datetime)  # Month 컬럼 생성됨retail.head()                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice      Month                  0      0      536365      85123A      WHITE HANGING HEART T-LIGHT HOLDER      6      2010-12-01 08:26:00      2.55      17850      United Kingdom      15.30      2010-12-01              1      1      536365      71053      WHITE METAL LANTERN      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34      2010-12-01              2      2      536365      84406B      CREAM CUPID HEARTS COAT HANGER      8      2010-12-01 08:26:00      2.75      17850      United Kingdom      22.00      2010-12-01              3      3      536365      84029G      KNITTED UNION FLAG HOT WATER BOTTLE      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34      2010-12-01              4      4      536365      84029E      RED WOOLLY HOTTIE WHITE HEART.      6      2010-12-01 08:26:00      3.39      17850      United Kingdom      20.34      2010-12-01      retail.groupby('CustomerID')['Month']&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x000001F01E170610&gt;month_group = retail.groupby('CustomerID')['Month']retail['MonthStarted'] = month_group.transform(np.min)retail.tail() #최초로 이용한 달 검색                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice      Month      MonthStarted                  397879      541904      581587      22613      PACK OF 20 SPACEBOY NAPKINS      12      2011-12-09 12:50:00      0.85      12680      France      10.20      2011-12-01      2011-08-01              397880      541905      581587      22899      CHILDREN'S APRON DOLLY GIRL      6      2011-12-09 12:50:00      2.10      12680      France      12.60      2011-12-01      2011-08-01              397881      541906      581587      23254      CHILDRENS CUTLERY DOLLY GIRL      4      2011-12-09 12:50:00      4.15      12680      France      16.60      2011-12-01      2011-08-01              397882      541907      581587      23255      CHILDRENS CUTLERY CIRCUS PARADE      4      2011-12-09 12:50:00      4.15      12680      France      16.60      2011-12-01      2011-08-01              397883      541908      581587      22138      BAKING SET 9 PIECE RETROSPOT      3      2011-12-09 12:50:00      4.95      12680      France      14.85      2011-12-01      2011-08-01      기준이 되는 월과 실제 구매 월의 차이 계산하기  각 구매가 최초 구매로 부터 얼마의 월이 지났는지 연산  MonthPassed : 최초 구매월로부터의 월 차이retail['MonthPassed'] = (retail['Month'].dt.year - retail['MonthStarted'].dt.year) * 12 + \\    (retail['Month'].dt.month - retail['MonthStarted'].dt.month)retail.tail()                  Unnamed: 0      InvoiceNo      StockCode      Description      Quantity      InvoiceDate      UnitPrice      CustomerID      Country      CheckoutPrice      Month      MonthStarted      MonthPassed                  397879      541904      581587      22613      PACK OF 20 SPACEBOY NAPKINS      12      2011-12-09 12:50:00      0.85      12680      France      10.20      2011-12-01      2011-08-01      4              397880      541905      581587      22899      CHILDREN'S APRON DOLLY GIRL      6      2011-12-09 12:50:00      2.10      12680      France      12.60      2011-12-01      2011-08-01      4              397881      541906      581587      23254      CHILDRENS CUTLERY DOLLY GIRL      4      2011-12-09 12:50:00      4.15      12680      France      16.60      2011-12-01      2011-08-01      4              397882      541907      581587      23255      CHILDRENS CUTLERY CIRCUS PARADE      4      2011-12-09 12:50:00      4.15      12680      France      16.60      2011-12-01      2011-08-01      4              397883      541908      581587      22138      BAKING SET 9 PIECE RETROSPOT      3      2011-12-09 12:50:00      4.95      12680      France      14.85      2011-12-01      2011-08-01      4      기준 월, MonthPassed를 기준으로 고객 카운팅  기준이 되는 월과 그 월로부터 지난 기간의 고객 수를 계산def get_unique_no(x):    return len(np.unique(x))cohort_group = retail.groupby(['MonthStarted', 'MonthPassed'])cohort_df = cohort_group['CustomerID'].apply(get_unique_no).reset_index() #reset_index 함수로 index 없애기cohort_df.head()                  MonthStarted      MonthPassed      CustomerID                  0      2010-12-01      0      885              1      2010-12-01      1      324              2      2010-12-01      2      286              3      2010-12-01      3      340              4      2010-12-01      4      321      테이블 피벗  pivot 함수를 이용하여 index는 MonthStarted, columns을 MonthPassed로 변경하여 테이블 변경  첫번째 column을 기준으로 100분위 연산cohort_df = cohort_df.pivot(index='MonthStarted', columns='MonthPassed')cohort_df.head()                  CustomerID              MonthPassed      0      1      2      3      4      5      6      7      8      9      10      11      12              MonthStarted                                                                                                2010-12-01      885.0      324.0      286.0      340.0      321.0      352.0      321.0      309.0      313.0      350.0      331.0      445.0      235.0              2011-01-01      417.0      92.0      111.0      96.0      134.0      120.0      103.0      101.0      125.0      136.0      152.0      49.0      NaN              2011-02-01      380.0      71.0      71.0      108.0      103.0      94.0      96.0      106.0      94.0      116.0      26.0      NaN      NaN              2011-03-01      452.0      68.0      114.0      90.0      101.0      76.0      121.0      104.0      126.0      39.0      NaN      NaN      NaN              2011-04-01      300.0      64.0      61.0      63.0      59.0      68.0      65.0      78.0      22.0      NaN      NaN      NaN      NaN      customer_cohort = cohort_df.div(cohort_df.iloc[:, 0], axis=0) * 100#df.iloc[ ]는 row와 column의 이름을 그대로 쓰는 것이 아니라 각 row와 column의 인덱스 값으로 인덱싱하는 방법이다.customer_cohort.head()                  CustomerID              MonthPassed      0      1      2      3      4      5      6      7      8      9      10      11      12              MonthStarted                                                                                                2010-12-01      100.0      36.610169      32.316384      38.418079      36.271186      39.774011      36.271186      34.915254      35.367232      39.548023      37.401130      50.282486      26.553672              2011-01-01      100.0      22.062350      26.618705      23.021583      32.134293      28.776978      24.700240      24.220624      29.976019      32.613909      36.450839      11.750600      NaN              2011-02-01      100.0      18.684211      18.684211      28.421053      27.105263      24.736842      25.263158      27.894737      24.736842      30.526316      6.842105      NaN      NaN              2011-03-01      100.0      15.044248      25.221239      19.911504      22.345133      16.814159      26.769912      23.008850      27.876106      8.628319      NaN      NaN      NaN              2011-04-01      100.0      21.333333      20.333333      21.000000      19.666667      22.666667      21.666667      26.000000      7.333333      NaN      NaN      NaN      NaN      customer_cohort = customer_cohort.round(decimals=2)customer_cohort                  CustomerID              MonthPassed      0      1      2      3      4      5      6      7      8      9      10      11      12              MonthStarted                                                                                                2010-12-01      100.0      36.61      32.32      38.42      36.27      39.77      36.27      34.92      35.37      39.55      37.40      50.28      26.55              2011-01-01      100.0      22.06      26.62      23.02      32.13      28.78      24.70      24.22      29.98      32.61      36.45      11.75      NaN              2011-02-01      100.0      18.68      18.68      28.42      27.11      24.74      25.26      27.89      24.74      30.53      6.84      NaN      NaN              2011-03-01      100.0      15.04      25.22      19.91      22.35      16.81      26.77      23.01      27.88      8.63      NaN      NaN      NaN              2011-04-01      100.0      21.33      20.33      21.00      19.67      22.67      21.67      26.00      7.33      NaN      NaN      NaN      NaN              2011-05-01      100.0      19.01      17.25      17.25      20.77      23.24      26.41      9.51      NaN      NaN      NaN      NaN      NaN              2011-06-01      100.0      17.36      15.70      26.45      23.14      33.47      9.50      NaN      NaN      NaN      NaN      NaN      NaN              2011-07-01      100.0      18.09      20.74      22.34      27.13      11.17      NaN      NaN      NaN      NaN      NaN      NaN      NaN              2011-08-01      100.0      20.71      24.85      24.26      12.43      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN              2011-09-01      100.0      23.41      30.10      11.37      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN              2011-10-01      100.0      24.02      11.45      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN              2011-11-01      100.0      11.15      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN              2011-12-01      100.0      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      heatmap 출력하기  seaborn의 heatmap 함수로 visualization!xticks = np.arange(0, 13)yticks = ['2010/12', '2011/01', '2011/02', '2011/03', '2011/04', '2011/05', '2011/06', '2011/07', '2011/08', '2011/09', '2011/10', '2011/11', '2011/12']plt.figure(figsize = (15, 8))sns.heatmap(customer_cohort,             annot=True,             xticklabels=xticks,            yticklabels=yticks,             fmt='.1f')&lt;AxesSubplot:xlabel='None-MonthPassed', ylabel='MonthStarted'&gt;",
        "url": "/goodcustomer-Data"
    }
    ,
    
    "customer-data": {
        "title": "고객 데이터 분석 프로젝트",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)고객 데이터 분석데이터 출처 : UCI Machine Learning Repository[링크주소 및 다운로드]https://archive.ics.uci.edu/ml/datasets/bank+marketingMoro, S., Cortez, P., &amp; Rita, P. (2014). A data-driven approach to predict the success of bank telemarketing. Decision Support Systems, 62, 22-31  해외의 은행이 진행한 마케팅 데이터  아웃바운드 텔레마케팅으로 마케팅 캠페인을 진행bank client data:1 - age (numeric)2 - job : type of job (categorical: ‘admin.’,’blue-collar’,’entrepreneur’,’housemaid’,’management’,’retired’,’self-employed’,’services’,’student’,’technician’,’unemployed’,’unknown’)3 - marital : marital status (categorical: ‘divorced’,’married’,’single’,’unknown’; note: ‘divorced’ means divorced or widowed)4 - education (categorical: ‘basic.4y’,’basic.6y’,’basic.9y’,’high.school’,’illiterate’,’professional.course’,’university.degree’,’unknown’)5 - default: has credit in default? (categorical: ‘no’,’yes’,’unknown’)6 - housing: has housing loan? (categorical: ‘no’,’yes’,’unknown’)7 - loan: has personal loan? (categorical: ‘no’,’yes’,’unknown’)related with the last contact of the current campaign:8 - contact: contact communication type (categorical: ‘cellular’,’telephone’) 9 - month: last contact month of year (categorical: ‘jan’, ‘feb’, ‘mar’, …, ‘nov’, ‘dec’)10 - day_of_week: last contact day of the week (categorical: ‘mon’,’tue’,’wed’,’thu’,’fri’)11 - duration: last contact duration, in seconds (numeric). other attributes:12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)14 - previous: number of contacts performed before this campaign and for this client (numeric)15 - poutcome: outcome of the previous marketing campaign (categorical: ‘failure’,’nonexistent’,’success’)social and economic context attributes16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)17 - cons.price.idx: consumer price index - monthly indicator (numeric) 18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric) 19 - euribor3m: euribor 3 month rate - daily indicator (numeric)20 - nr.employed: number of employees - quarterly indicator (numeric)Output variable:21 - y - has the client subscribed a term deposit? (binary: ‘yes’,’no’)import pandas as pdfrom pandas import Seriesfrom pandas import DataFrameimport matplotlib.pyplot as plt# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlibfrom matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   데이터불러오기파일명 : bank-additional-full.csv#window 방법1 : \\\\#engine='python' - 에러 반환시, 디렉토리 혹은 파일명에 한글이 있을 경우 추가df=pd.read_csv('bankadditionalfull.csv')#head()df.head()                  age;\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"                  0      56;\"housemaid\";\"married\";\"basic.4y\";\"no\";\"no\";...              1      57;\"services\";\"married\";\"high.school\";\"unknown...              2      37;\"services\";\"married\";\"high.school\";\"no\";\"ye...              3      40;\"admin.\";\"married\";\"basic.6y\";\"no\";\"no\";\"no...              4      56;\"services\";\"married\";\"high.school\";\"no\";\"no...        엑셀로 데이터를 열었을 때의 화면  콜론으로 구분된 데이터#window#sep = ';'df=pd.read_csv('bankadditionalfull.csv',                 engine='python',sep=';')df.head()                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  0      56      housemaid      married      basic.4y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              1      57      services      married      high.school      unknown      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              2      37      services      married      high.school      no      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              3      40      admin.      married      basic.6y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              4      56      services      married      high.school      no      no      yes      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no      5 rows × 21 columns# 데이터탐색  학습목표 :          데이터 탐색과정에서 사용되는 함수를 살펴보고 실전 사례를 통해 사용법을 익힌다.      #head - 데이터의 첫 5행, default : 5행df.head()                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  0      56      housemaid      married      basic.4y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              1      57      services      married      high.school      unknown      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              2      37      services      married      high.school      no      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              3      40      admin.      married      basic.6y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              4      56      services      married      high.school      no      no      yes      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no      5 rows × 21 columnsdf.head(10)                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  0      56      housemaid      married      basic.4y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              1      57      services      married      high.school      unknown      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              2      37      services      married      high.school      no      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              3      40      admin.      married      basic.6y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              4      56      services      married      high.school      no      no      yes      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              5      45      services      married      basic.9y      unknown      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              6      59      admin.      married      professional.course      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              7      41      blue-collar      married      unknown      unknown      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              8      24      technician      single      professional.course      no      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              9      25      services      single      high.school      no      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no      10 rows × 21 columns#tail - 데이터의 끝 5행, default : 5행df.tail()                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  41183      73      retired      married      professional.course      no      yes      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      yes              41184      46      blue-collar      married      professional.course      no      no      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      no              41185      56      retired      married      university.degree      no      yes      no      cellular      nov      fri      ...      2      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      no              41186      44      technician      married      professional.course      no      no      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      yes              41187      74      retired      married      professional.course      no      yes      no      cellular      nov      fri      ...      3      999      1      failure      -1.1      94.767      -50.8      1.028      4963.6      no      5 rows × 21 columnsdf.tail(10)                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  41178      62      retired      married      university.degree      no      no      no      cellular      nov      thu      ...      2      6      3      success      -1.1      94.767      -50.8      1.031      4963.6      yes              41179      64      retired      divorced      professional.course      no      yes      no      cellular      nov      fri      ...      3      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      no              41180      36      admin.      married      university.degree      no      no      no      cellular      nov      fri      ...      2      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      no              41181      37      admin.      married      university.degree      no      yes      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      yes              41182      29      unemployed      single      basic.4y      no      yes      no      cellular      nov      fri      ...      1      9      1      success      -1.1      94.767      -50.8      1.028      4963.6      no              41183      73      retired      married      professional.course      no      yes      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      yes              41184      46      blue-collar      married      professional.course      no      no      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      no              41185      56      retired      married      university.degree      no      yes      no      cellular      nov      fri      ...      2      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      no              41186      44      technician      married      professional.course      no      no      no      cellular      nov      fri      ...      1      999      0      nonexistent      -1.1      94.767      -50.8      1.028      4963.6      yes              41187      74      retired      married      professional.course      no      yes      no      cellular      nov      fri      ...      3      999      1      failure      -1.1      94.767      -50.8      1.028      4963.6      no      10 rows × 21 columns결측치 확인# 결측치 확인df.isnull()                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  0      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              1      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              2      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              3      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              4      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              41183      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              41184      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              41185      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              41186      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False              41187      False      False      False      False      False      False      False      False      False      False      ...      False      False      False      False      False      False      False      False      False      False      41188 rows × 21 columns# 결측치 확인 - 열단위df.isnull().sum()age               0job               0marital           0education         0default           0housing           0loan              0contact           0month             0day_of_week       0duration          0campaign          0pdays             0previous          0poutcome          0emp.var.rate      0cons.price.idx    0cons.conf.idx     0euribor3m         0nr.employed       0y                 0dtype: int64#shape - dataframe의 크기(행, 열의 수)df.shape(41188, 21)#describe() - 열에 대한 기술통계량#데이터의 수, 평균, 표준편차, 최소값, 1사분위수, 2사분위수, 3사분위수, 최대값df.describe()                  age      duration      campaign      pdays      previous      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed                  count      41188.00000      41188.000000      41188.000000      41188.000000      41188.000000      41188.000000      41188.000000      41188.000000      41188.000000      41188.000000              mean      40.02406      258.285010      2.567593      962.475454      0.172963      0.081886      93.575664      -40.502600      3.621291      5167.035911              std      10.42125      259.279249      2.770014      186.910907      0.494901      1.570960      0.578840      4.628198      1.734447      72.251528              min      17.00000      0.000000      1.000000      0.000000      0.000000      -3.400000      92.201000      -50.800000      0.634000      4963.600000              25%      32.00000      102.000000      1.000000      999.000000      0.000000      -1.800000      93.075000      -42.700000      1.344000      5099.100000              50%      38.00000      180.000000      2.000000      999.000000      0.000000      1.100000      93.749000      -41.800000      4.857000      5191.000000              75%      47.00000      319.000000      3.000000      999.000000      0.000000      1.400000      93.994000      -36.400000      4.961000      5228.100000              max      98.00000      4918.000000      56.000000      999.000000      7.000000      1.400000      94.767000      -26.900000      5.045000      5228.100000      #columns - 칼럼명 반환df.columnsIndex(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],      dtype='object')#unique() - 열의 고유값#educationdf['education'].unique()array(['basic.4y', 'high.school', 'basic.6y', 'basic.9y',       'professional.course', 'unknown', 'university.degree',       'illiterate'], dtype=object)#value_counts() - 열의 고유값 빈도#educationdf['education'].value_counts()university.degree      12168high.school             9515basic.9y                6045professional.course     5243basic.4y                4176basic.6y                2292unknown                 1731illiterate                18Name: education, dtype: int64#unique() - 열의 고유값#maritaldf['marital'].unique()array(['married', 'single', 'divorced', 'unknown'], dtype=object)#value_counts() - 열의 고유값 빈도#maritaldf['marital'].value_counts()married     24928single      11568divorced     4612unknown        80Name: marital, dtype: int64데이터 시각화  학습목표 :          현업의 데이터를 사용하여 데이터 시각화를 실습한다.      데이터를 가공,처리하여 시각화를 진행한다.      df['age']0        561        572        373        404        56         ..41183    7341184    4641185    5641186    4441187    74Name: age, Length: 41188, dtype: int64df['age'].plot()plt.show()#x축이 인덱스 순서  age 칼럼 선그래프 그리기(오름차순)          노출수칼럼을 수치 순서대로 오름차순 정렬      정렬된 데이터(시리즈)의 형태대로 인덱스 재생성      #오름차순 정렬#age칼럼 age=df['age'].sort_values()#age변수출력age38274    1737579    1737539    1737140    1737558    17         ..40450    9238921    9427826    9538455    9838452    98Name: age, Length: 41188, dtype: int64#reset_index - 인덱스 재생성, 기존 인덱스를 데이터프레임의 열로 반환age=age.reset_index()#age 변수출력age                  index      age                  0      38274      17              1      37579      17              2      37539      17              3      37140      17              4      37558      17              ...      ...      ...              41183      40450      92              41184      38921      94              41185      27826      95              41186      38455      98              41187      38452      98      41188 rows × 2 columns#drop(axis=1) - 삭제(열 기준)age=age.drop('index',axis=1)#age 변수출력age                  age                  0      17              1      17              2      17              3      17              4      17              ...      ...              41183      92              41184      94              41185      95              41186      98              41187      98      41188 rows × 1 columns#plottingage.plot()plt.show()#값의 오름차순별로 정렬한 그래프#보통 '나이'를 20대,30대,40..대로 나누어 데이터를 확인함#계급간 빈도를 나타내주는 히스토그램df['age'].plot.hist()plt.show()#히스토그램#bins - 계급구간(10,20,30...100)#figsize=[15,8]#xticks(fontsize=15)#yticks(fontsize=15)#plt.title('Histogram of df.age',fontsize=20)df['age'].plot.hist(bins=range(10,101,10),figsize=[15,8])plt.xticks(fontsize=15)plt.yticks(fontsize=15)plt.title('Histogram of df.age',fontsize=20)plt.show()#시각화 예제2 : duration(전화통화시간) 선 그래프 시각화(((df['duration'].sort_values()).reset_index()).drop('index',axis=1)).plot()plt.show()#1. 선그래프로 데이터의 패턴 분석#2. 히스토그램으로 전화통화 시간별 빈도 분석#히스토그램의 계급구간을 설정하기 위한 최소값, 최대값 파악#describe()df['duration'].describe()count    41188.000000mean       258.285010std        259.279249min          0.00000025%        102.00000050%        180.00000075%        319.000000max       4918.000000Name: duration, dtype: float64#bins=range(0,5001,100)df['duration'].plot.hist(bins=range(0,5001,100))plt.show()#히스토그램#bins - 계급구간(0,100,200...5000)#figsize=[15,8]#xticks(fontsize=15)#yticks(fontsize=15)#plt.title('Histogram of df.duration',fontsize=20)df['duration'].plot.hist(bins=range(0,5001,100), figsize=[15,8])plt.xticks(fontsize=15)plt.yticks(fontsize=15)plt.title('Histogram of df.duration',fontsize=20)plt.show()막대그래프, 가로막대그래프#선그래프#maritaldf['marital'].plot()plt.show()#no numeric data to plot---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-36-7df365c79815&gt; in &lt;module&gt;      1 #선그래프      2 #marital----&gt; 3 df['marital'].plot()      4 plt.show()      5 #no numeric data to plot~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py in __call__(self, *args, **kwargs)    953                     data.columns = label_name    954 --&gt; 955         return plot_backend.plot(data, kind=kind, **kwargs)    956     957     __call__.__doc__ = __doc__~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py in plot(data, kind, **kwargs)     59             kwargs[\"ax\"] = getattr(ax, \"left_ax\", ax)     60     plot_obj = PLOT_CLASSES[kind](data, **kwargs)---&gt; 61     plot_obj.generate()     62     plot_obj.draw()     63     return plot_obj.result~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py in generate(self)    276     def generate(self):    277         self._args_adjust()--&gt; 278         self._compute_plot_data()    279         self._setup_subplots()    280         self._make_plot()~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py in _compute_plot_data(self)    439         # no non-numeric frames or series allowed    440         if is_empty:--&gt; 441             raise TypeError(\"no numeric data to plot\")    442     443         self.data = numeric_data.apply(self._convert_to_ndarray)TypeError: no numeric data to plot  숫자데이터가 아니기 때문에 시각화 할 수 없다.#히스토그램df['marital'].plot.hist()#no numeric data to plot---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-38-414b9b3e32cb&gt; in &lt;module&gt;      1 #히스토그램----&gt; 2 df['marital'].plot.hist()      3 #no numeric data to plot~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py in hist(self, by, bins, **kwargs)   1294             &gt;&gt;&gt; ax = df.plot.hist(bins=12, alpha=0.5)   1295         \"\"\"-&gt; 1296         return self(kind=\"hist\", by=by, bins=bins, **kwargs)   1297    1298     def kde(self, bw_method=None, ind=None, **kwargs):~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py in __call__(self, *args, **kwargs)    953                     data.columns = label_name    954 --&gt; 955         return plot_backend.plot(data, kind=kind, **kwargs)    956     957     __call__.__doc__ = __doc__~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py in plot(data, kind, **kwargs)     59             kwargs[\"ax\"] = getattr(ax, \"left_ax\", ax)     60     plot_obj = PLOT_CLASSES[kind](data, **kwargs)---&gt; 61     plot_obj.generate()     62     plot_obj.draw()     63     return plot_obj.result~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py in generate(self)    276     def generate(self):    277         self._args_adjust()--&gt; 278         self._compute_plot_data()    279         self._setup_subplots()    280         self._make_plot()~\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py in _compute_plot_data(self)    439         # no non-numeric frames or series allowed    440         if is_empty:--&gt; 441             raise TypeError(\"no numeric data to plot\")    442     443         self.data = numeric_data.apply(self._convert_to_ndarray)TypeError: no numeric data to plot  숫자데이터가 아니기 때문에 시각화 할 수 없다.#unique()함수를 사용한 age칼럼 고유값 확인 df['age'].unique()#선그래프를 그린 age칼럼 데이터는 수치데이터array([56, 57, 37, 40, 45, 59, 41, 24, 25, 29, 35, 54, 46, 50, 39, 30, 55,       49, 34, 52, 58, 32, 38, 44, 42, 60, 53, 47, 51, 48, 33, 31, 43, 36,       28, 27, 26, 22, 23, 20, 21, 61, 19, 18, 70, 66, 76, 67, 73, 88, 95,       77, 68, 75, 63, 80, 62, 65, 72, 82, 64, 71, 69, 78, 85, 79, 83, 81,       74, 17, 87, 91, 86, 98, 94, 84, 92, 89], dtype=int64)#unique()함수를 사용한 marital칼럼 고유값 확인 df['marital'].unique()#marital칼럼의 데이터는 문자array(['married', 'single', 'divorced', 'unknown'], dtype=object)  막대그래프를 통한 시각화          value_counts      막대그래프 시각화      #1. value_counts() - 문자데이터는 value_counts() 함수를 사용하여 시각화 할 수 있다.#maritalmarital=df['marital'].value_counts()#2. marital변수 막대그래프 시각화marital.plot.bar()plt.show()#2-1. 가로막대그래프 시각화marital.plot.barh()plt.show()df['education'].unique()array(['basic.4y', 'high.school', 'basic.6y', 'basic.9y',       'professional.course', 'unknown', 'university.degree',       'illiterate'], dtype=object)#education 가로막대그래프 한줄 코드#value_counts(),plot.barh()education=df['education'].value_counts()education.plot.barh()plt.show()데이터 분석분석주제 1 :대출이 있는 사람이라면 은행 상품에 잘 가입하지 않을 것이다.  학습목표 :          가설검증과정 코딩 실습하기      groupby활용한 실습 진행하기        분석을 위한 코딩과정 도식화          가입여부에 따라 가입한 그룹과 가입하지 않은 그룹으로 나눈다.      나뉜 데이터를 대출여부에 따라 나눈다.      가입한 그룹 중 대출이 있는 사람의 비중과, 가입하지 않은 그룹 중 대출이 있는 사람의 비중을 비교한다.      # 1. 가입여부에 따라 가입한 그룹과 가입하지 않은 그룹으로 나눈다.#가입여부에 대한 칼럼 : 'y'#unique()df['y'].unique()#groupby사용 - yes, no그룹으로 나뉘게 됨array(['no', 'yes'], dtype=object)# 1. 가입여부에 따라 가입한 그룹과 가입하지 않은 그룹으로 나눈다.#groupby('y')grouped=df.groupby('y')# 1. 가입여부에 따라 가입한 그룹과 가입하지 않은 그룹으로 나눈다.#get_group('yes') - y칼럼이 'yes'인 데이터프레임 추출 - 가입한 그룹만 추출#get_group('no') - y칼럼이 'no'인 데이터프레임 추출 - 가입하지 않은 그룹만 추출yes_group=grouped.get_group('yes')no_group=grouped.get_group('no')# 1. 가입여부에 따라 가입한 그룹과 가입하지 않은 그룹으로 나눈다.#yes_group 출력yes_group.head()                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  75      41      blue-collar      divorced      basic.4y      unknown      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      yes              83      49      entrepreneur      married      university.degree      unknown      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      yes              88      49      technician      married      basic.9y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      yes              129      41      technician      married      professional.course      unknown      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      yes              139      45      blue-collar      married      basic.9y      unknown      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      yes      5 rows × 21 columns# 1-3. 가입여부에 따라 가입한 그룹과 가입하지 않은 그룹으로 나눈다.#no_group 출력no_group.head()                  age      job      marital      education      default      housing      loan      contact      month      day_of_week      ...      campaign      pdays      previous      poutcome      emp.var.rate      cons.price.idx      cons.conf.idx      euribor3m      nr.employed      y                  0      56      housemaid      married      basic.4y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              1      57      services      married      high.school      unknown      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              2      37      services      married      high.school      no      yes      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              3      40      admin.      married      basic.6y      no      no      no      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no              4      56      services      married      high.school      no      no      yes      telephone      may      mon      ...      1      999      0      nonexistent      1.1      93.994      -36.4      4.857      5191.0      no      5 rows × 21 columns#2. 나뉜 데이터(yes_group,no_group)를 대출여부(loan)에 따라 나눈다.#value_countsyes=yes_group['loan'].value_counts()#yes변수 출력yes#yes_group의 대출여부 빈도 출력no         3850yes         683unknown     107Name: loan, dtype: int64#2. 나뉜 데이터(yes_group,no_group)를 대출여부(loan)에 따라 나눈다.#value_countsno=no_group['loan'].value_counts()#no변수 출력no#no_group의 대출여부 빈도 출력no         30100yes         5565unknown      883Name: loan, dtype: int64#3. 가입한 그룹 내 대출이 있는 사람의 비중과, 가입하지 않은 그룹 내 대출이 있는 사람의 비중을 비교한다(yes_group).#비중 : 시리즈 변수 각각의 value를 시리즈의 총합으로 나눔#시리즈는 산술연산자(+,-,*,/,%,**,//)와 함께 사용가능#series/series.sum()yes=yes/yes.sum()#yes 출력yesno         0.829741yes        0.147198unknown    0.023060Name: loan, dtype: float64#3. 가입한 그룹 내 대출이 있는 사람의 비중과, 가입하지 않은 그룹 내 대출이 있는 사람의 비중을 비교한다(no_group).no=no/no.sum()#no 출력nono         0.823574yes        0.152266unknown    0.024160Name: loan, dtype: float64#3. 가입한 그룹 중 대출이 있는 사람의 비중과, 가입하지 않은 그룹 중 대출이 있는 사람의 비중을 비교한다.#concat : 시리즈 혹은 데이터프레임 결합(default-행방향 결합)pd.concat([yes,no],axis=1)# column 합치기#칼럼명이 모두 loan                  loan      loan                  no      0.829741      0.823574              yes      0.147198      0.152266              unknown      0.023060      0.024160      #series.name : 시리즈의 이름 설정yes.name='y_yes'#series.name : 시리즈의 이름 설정no.name='y_no'pd.concat([yes,no],axis=1)#=&gt; 가입한 그룹의 대출 비중이 가입하지 않은 그룹보다 0.005 더 적다.                  y_yes      y_no                  no      0.829741      0.823574              yes      0.147198      0.152266              unknown      0.023060      0.024160      분석주제 2 :같은 상품을 새로운 고객에게 마케팅 하려고한다.연령과 상품가입여부, 직업을 함께 고려할때 마케팅 전략을 변화시켜야 할 그룹은?  학습목표 :          가설검증과정 코딩 실습하기      pivot_table활용한 실습 진행하기        분석조건 : 세 개의 칼럼(age, job, y)을 함께 분석해야 함  pd.pivot_table(‘데이터프레임 변수’,values=집계 대상 칼럼(수치 데이터), index=행 인덱스가 될 칼럼명, columns=열 인덱스가 될 칼럼명, aggfunc=집계함수-sum,mean,min,max,std,var)pivot_table 사용예제#pd.pivot_table('데이터프레임 변수',values=집계 대상 칼럼, index=행 인덱스가 될 칼럼명, columns=열 인덱스가 될 칼럼명, aggfunc=sum)pd.pivot_table(df,values='age',index='y',columns='job',aggfunc='mean')            job      admin.      blue-collar      entrepreneur      housemaid      management      retired      self-employed      services      student      technician      unemployed      unknown              y                                                                                          no      38.219846      39.582057      41.703453      44.705451      42.309707      59.926128      40.176887      38.090236      26.396667      38.600033      39.844828      45.375427              yes      37.968935      39.200627      41.935484      52.650943      42.783537      68.253456      38.006711      36.077399      24.800000      37.746575      39.062500      47.054054      #values,index,columns파라미터를 일일이 쓰지 않고 순서대로 입력하여 실행 가능pd.pivot_table(df,'age','y','job',aggfunc='mean')            job      admin.      blue-collar      entrepreneur      housemaid      management      retired      self-employed      services      student      technician      unemployed      unknown              y                                                                                          no      38.219846      39.582057      41.703453      44.705451      42.309707      59.926128      40.176887      38.090236      26.396667      38.600033      39.844828      45.375427              yes      37.968935      39.200627      41.935484      52.650943      42.783537      68.253456      38.006711      36.077399      24.800000      37.746575      39.062500      47.054054      #멀티 인덱스(multi-index) - 행 인덱스#['y','marital']pd.pivot_table(df,'age',['y','marital'],'job',aggfunc='mean')                  job      admin.      blue-collar      entrepreneur      housemaid      management      retired      self-employed      services      student      technician      unemployed      unknown              y      marital                                                                                          no      divorced      43.098432      42.903704      44.042424      48.806897      46.123288      61.480469      42.871795      41.991984      34.500000      42.173484      42.140351      43.300000              married      40.148663      40.857804      42.477111      44.849218      43.634997      60.019048      42.349148      39.992951      30.484848      40.686245      41.636861      47.532110              single      33.858265      33.409255      35.472527      38.087379      34.070776      53.938272      33.783537      32.159921      26.062500      33.950697      33.536946      38.288136              unknown      34.666667      42.818182      35.500000      40.000000      51.000000      59.750000      39.400000      40.000000      30.000000      33.300000      47.200000      40.166667              yes      divorced      44.878788      42.037736      44.857143      57.000000      46.692308      72.739130      41.875000      43.484848      35.666667      40.738462      47.900000      76.333333              married      41.386503      41.363420      43.090909      54.256757      44.756637      67.033435      41.036585      38.379518      31.250000      41.398438      41.941860      58.750000              single      32.404594      32.652174      35.666667      40.875000      33.285714      67.500000      31.921569      31.024194      24.481061      32.078853      32.062500      30.000000              unknown      42.500000      37.000000      31.000000      NaN      NaN      66.000000      NaN      NaN      NaN      30.000000      NaN      40.666667      #멀티 인덱스(multi-index) - 열 인덱스#['job','contact']pd.pivot_table(df,'age',['y','marital'],['job','contact'],aggfunc='mean')                  job      admin.      blue-collar      entrepreneur      housemaid      management      ...      services      student      technician      unemployed      unknown                    contact      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone      ...      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone              y      marital                                                                                                                                                no      divorced      43.143639      43.019185      42.906907      42.900585      43.301887      45.372881      48.292683      49.476190      44.786164      47.721805      ...      42.028269      41.944444      36.000000      27.000000      42.069034      42.435644      42.253731      41.978723      46.000000      40.600000              married      40.349554      39.800357      41.182477      40.494249      42.213628      42.802273      45.900966      43.342561      43.740678      43.452416      ...      40.483733      39.395833      32.150000      27.923077      40.283568      41.365495      41.452769      41.871369      48.349057      46.758929              single      33.515821      34.646707      32.872838      34.183554      36.181034      34.227273      36.827586      39.711111      33.747405      34.697987      ...      32.360927      31.863081      25.396509      27.742138      33.529248      35.008741      33.252101      33.940476      39.535714      37.161290              unknown      35.000000      31.000000      43.800000      42.000000      40.000000      31.000000      40.000000      NaN      NaN      51.000000      ...      34.500000      42.750000      30.000000      NaN      30.285714      40.333333      46.500000      50.000000      48.333333      32.000000              yes      divorced      45.028302      44.269231      41.500000      43.400000      45.333333      44.000000      59.857143      37.000000      46.297297      54.000000      ...      43.083333      44.555556      35.666667      NaN      40.701754      41.000000      51.000000      40.666667      76.333333      NaN              married      41.362832      41.540230      41.682432      40.608000      44.177419      40.500000      55.375000      50.777778      45.401099      42.090909      ...      38.634921      37.575000      30.333333      34.000000      41.299065      41.904762      42.746479      38.133333      58.181818      60.000000              single      32.117284      34.150000      31.934426      34.897436      35.117647      38.000000      40.769231      41.333333      32.763636      36.875000      ...      30.846154      31.950000      24.174468      26.965517      31.995902      32.657143      32.355556      27.666667      31.000000      28.000000              unknown      42.500000      NaN      37.000000      NaN      31.000000      NaN      NaN      NaN      NaN      NaN      ...      NaN      NaN      NaN      NaN      30.000000      NaN      NaN      NaN      45.000000      32.000000      8 rows × 24 columns#fill-value - 결측치 대체#fill_value=0pd.pivot_table(df,'age',['y','marital'],['job','contact'],aggfunc='mean',fill_value=0)                  job      admin.      blue-collar      entrepreneur      housemaid      management      ...      services      student      technician      unemployed      unknown                    contact      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone      ...      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone      cellular      telephone              y      marital                                                                                                                                                no      divorced      43.143639      43.019185      42.906907      42.900585      43.301887      45.372881      48.292683      49.476190      44.786164      47.721805      ...      42.028269      41.944444      36.000000      27.000000      42.069034      42.435644      42.253731      41.978723      46.000000      40.600000              married      40.349554      39.800357      41.182477      40.494249      42.213628      42.802273      45.900966      43.342561      43.740678      43.452416      ...      40.483733      39.395833      32.150000      27.923077      40.283568      41.365495      41.452769      41.871369      48.349057      46.758929              single      33.515821      34.646707      32.872838      34.183554      36.181034      34.227273      36.827586      39.711111      33.747405      34.697987      ...      32.360927      31.863081      25.396509      27.742138      33.529248      35.008741      33.252101      33.940476      39.535714      37.161290              unknown      35.000000      31.000000      43.800000      42.000000      40.000000      31.000000      40.000000      0.000000      0.000000      51.000000      ...      34.500000      42.750000      30.000000      0.000000      30.285714      40.333333      46.500000      50.000000      48.333333      32.000000              yes      divorced      45.028302      44.269231      41.500000      43.400000      45.333333      44.000000      59.857143      37.000000      46.297297      54.000000      ...      43.083333      44.555556      35.666667      0.000000      40.701754      41.000000      51.000000      40.666667      76.333333      0.000000              married      41.362832      41.540230      41.682432      40.608000      44.177419      40.500000      55.375000      50.777778      45.401099      42.090909      ...      38.634921      37.575000      30.333333      34.000000      41.299065      41.904762      42.746479      38.133333      58.181818      60.000000              single      32.117284      34.150000      31.934426      34.897436      35.117647      38.000000      40.769231      41.333333      32.763636      36.875000      ...      30.846154      31.950000      24.174468      26.965517      31.995902      32.657143      32.355556      27.666667      31.000000      28.000000              unknown      42.500000      0.000000      37.000000      0.000000      31.000000      0.000000      0.000000      0.000000      0.000000      0.000000      ...      0.000000      0.000000      0.000000      0.000000      30.000000      0.000000      0.000000      0.000000      45.000000      32.000000      8 rows × 24 columnspivot_table를 사용한 주제2 분석같은 상품을 새로운 고객에게 마케팅 하려고한다.연령과 상품가입여부, 직업을 함께 고려할때 마케팅 전략을 변화시켜야 할 그룹은?#pivot_tablepivot=pd.pivot_table(df,values='age',index='y',columns='job',aggfunc='mean')#pivot 변수 출력pivot            job      admin.      blue-collar      entrepreneur      housemaid      management      retired      self-employed      services      student      technician      unemployed      unknown              y                                                                                          no      38.219846      39.582057      41.703453      44.705451      42.309707      59.926128      40.176887      38.090236      26.396667      38.600033      39.844828      45.375427              yes      37.968935      39.200627      41.935484      52.650943      42.783537      68.253456      38.006711      36.077399      24.800000      37.746575      39.062500      47.054054      #yes행과 no행의 차 연산(loc인덱서 사용)pivot.loc['yes']-pivot.loc['no']jobadmin.          -0.250911blue-collar     -0.381430entrepreneur     0.232030housemaid        7.945493management       0.473829retired          8.327329self-employed   -2.170175services        -2.012836student         -1.596667technician      -0.853458unemployed      -0.782328unknown          1.678627dtype: float64#diff행 생성(yes행과 no행의 차)pivot.loc['diff']=pivot.loc['yes']-pivot.loc['no']#pivot 변수 출력pivot            job      admin.      blue-collar      entrepreneur      housemaid      management      retired      self-employed      services      student      technician      unemployed      unknown              y                                                                                          no      38.219846      39.582057      41.703453      44.705451      42.309707      59.926128      40.176887      38.090236      26.396667      38.600033      39.844828      45.375427              yes      37.968935      39.200627      41.935484      52.650943      42.783537      68.253456      38.006711      36.077399      24.800000      37.746575      39.062500      47.054054              diff      -0.250911      -0.381430      0.232030      7.945493      0.473829      8.327329      -2.170175      -2.012836      -1.596667      -0.853458      -0.782328      1.678627      #diff 기준으로 내림차순 정렬 #sort_values() - default : 열 기준 오름차순 정렬#axis=1,ascending=False : 행 기준 내림차순 정렬#axis=1 안넣어주면 오류 발생result=pivot.sort_values('diff',axis=1,ascending=False)#result 출력result            job      retired      housemaid      unknown      management      entrepreneur      admin.      blue-collar      unemployed      technician      student      services      self-employed              y                                                                                          no      59.926128      44.705451      45.375427      42.309707      41.703453      38.219846      39.582057      39.844828      38.600033      26.396667      38.090236      40.176887              yes      68.253456      52.650943      47.054054      42.783537      41.935484      37.968935      39.200627      39.062500      37.746575      24.800000      36.077399      38.006711              diff      8.327329      7.945493      1.678627      0.473829      0.232030      -0.250911      -0.381430      -0.782328      -0.853458      -1.596667      -2.012836      -2.170175      #result의 diff행 막대그래프 시각화result.loc['diff'].plot.bar()plt.show()#result의 diff행 막대그래프 시각화#figsize=[15,10]#title('주제2 시각화',fontsize=20)#x축 눈금 - fontsize=16,rotation=45#y축 눈금 - fontsize=16)#xlabel - 'job',fontsize=16#ylabel - 'diff',fontsize=16result.loc['diff'].plot.bar(figsize=[15,10])plt.title('주제2 시각화',fontsize=20)plt.xticks(fontsize=16,rotation=45)plt.yticks(fontsize=16)plt.xlabel('job',fontsize=16)plt.ylabel('diff',fontsize=16)plt.show()  결론 - retired , housemaid 경우는 연령을 높여서 더욱 타겟팅 해야한다",
        "url": "/customer-Data"
    }
    ,
    
    "searchad": {
        "title": "검색광고 데이터 분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)패스트캠퍼스 검색광고 데이터 분석데이터의 구성 :분석목표 :  중점관리 키워드, 저효율 키워드 추출  중점관리 광고그룹, 저효율 광고그룹 추출분석과정 :  데이터 전처리  데이터 탐색  시각화  데이터분석1. 데이터 전처리  학습목표 :          read_excel함수를 사용하여 파이썬에 데이터 불러오기      데이터프레임의 열 단위 수치연산 및 데이터 타입 다루기      import pandas as pdfrom pandas import DataFramefrom pandas import Seriesimport matplotlib.pyplot as plt# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlibfrom matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   # read_excel함수를 사용하여 파이썬에 데이터 불러오기  파이썬의 디렉토리 경로구분자 : 슬래시(/)  운영체제별 디렉토리 경로구분자          Mac의 경우 : 슬래시(/)      윈도우의 경우 : 역슬래시(\\ or ＼)      # window의 경우 경로인식에러 발생df=pd.read_excel('naverreport.xls')# headdf.head()                  캠페인보고서(2019.02.01.~2019.04.30.),ftasia      Unnamed: 1      Unnamed: 2      Unnamed: 3      Unnamed: 4      Unnamed: 5      Unnamed: 6                  0      광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              1      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      261.549448      2512444              2      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      295.974808      2384965              3      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4841.66358      1568699              4      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174      # skiprows 함수 사용으로 불필요한 행 제거# 첫 행 삭제df=pd.read_excel('naverreport.xls',skiprows=[0])# headdf.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903      # skiprows 사용 예제# 원본데이터 가져오기df=pd.read_excel('naverreport.xls')# headdf                  캠페인보고서(2019.02.01.~2019.04.30.),ftasia      Unnamed: 1      Unnamed: 2      Unnamed: 3      Unnamed: 4      Unnamed: 5      Unnamed: 6                  0      광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              1      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      261.549448      2512444              2      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      295.974808      2384965              3      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4841.66358      1568699              4      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              ...      ...      ...      ...      ...      ...      ...      ...              1377      올인원 패키지 : 업무자동화_3. 엑셀      엑셀셀서식      24016      0      0      0      0              1378      올인원 패키지 : 업무자동화_3. 엑셀      MATCH      32287      0      0      0      0              1379      마케팅KPI수립      LTV      32602      0      0      0      0              1380      data_camp_rmp_8      DECISION      60844      0      0      0      0              1381      4. 웹의 동작      REST      61193      0      0      0      0      1382 rows × 7 columns# 하나의 행 제거 df=pd.read_excel('naverreport.xls',skiprows=[1])# headdf.head()                  캠페인보고서(2019.02.01.~2019.04.30.),ftasia      Unnamed: 1      Unnamed: 2      Unnamed: 3      Unnamed: 4      Unnamed: 5      Unnamed: 6                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903      # 여러 행 제거df=pd.read_excel('naverreport.xls',skiprows=[0,2,4])# headdf.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              1      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              2      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903              3      6. 파이썬      파이썬      384522      260.4      0.067720      3705.360983      964876              4      1. 코딩      코딩      562162      271.2      0.048242      3243.215339      879560      (강의 진행을 위한 실습데이터 불러오기)df=pd.read_excel('naverreport.xls',skiprows=[0])df.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903      # 결측치 확인df.isnull()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      False      False      False      False      False      False      False              1      False      False      False      False      False      False      False              2      False      False      False      False      False      False      False              3      False      False      False      False      False      False      False              4      False      False      False      False      False      False      False              ...      ...      ...      ...      ...      ...      ...      ...              1376      False      False      False      False      False      False      False              1377      False      False      False      False      False      False      False              1378      False      False      False      False      False      False      False              1379      False      False      False      False      False      False      False              1380      False      False      False      False      False      False      False      1381 rows × 7 columns# 결측치 확인 - 열단위df.isnull().sum()광고그룹               0키워드                0노출수                0클릭수                0클릭률(%)             0평균클릭비용(VAT포함,원)    0총비용(VAT포함,원)       0dtype: int64# 결측치 확인 - 행단위df.isnull().sum(axis=1)0       01       02       03       04       0       ..1376    01377    01378    01379    01380    0Length: 1381, dtype: int64# 데이터프레임의 열 단위 수치연산 및 데이터 타입 다루기  클릭수(반올림처리, 일의 자리수로 변경)  클릭률  평균클릭비용(VAT포함,원)df=pd.read_excel('naverreport.xls',skiprows=[0])df.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903        클릭수 : 한 번의 클릭이 총 몇 번 이루어졌는지 나타내는 지표=&gt; 반올림처리, 일의 자리수로 변경# 클릭수 열에 round함수 적용clk=round(df['클릭수'],0)clk   #반올림 처리 한것을 확인할 수 있다0       9606.01       8058.02        324.03       1864.04        814.0         ...  1376       0.01377       0.01378       0.01379       0.01380       0.0Name: 클릭수, Length: 1381, dtype: float64# round함수 활용예제숫자 예시 : 9606.14574print(round(9606.14574,-3))print(round(9606.14574,-2))print(round(9606.14574,-1))print(round(9606.14574,0))print(round(9606.14574,1))print(round(9606.14574,2))print(round(9606.14574,3))print(round(9606.14574,4))print(round(9606.14574,5))10000.09600.09610.09606.09606.19606.159606.1469606.14579606.14574# clk변수의 4번째 자료 확인clk[4]814.0# clk변수의 5번째 자료 확인clk[5]260.0# 소수점 제거 = 실수(float) =&gt; 정수(int)로 변경clk.astype(int)0       96061       80582        3243       18644        814        ... 1376       01377       01378       01379       01380       0Name: 클릭수, Length: 1381, dtype: int32# 기존 칼럼데이터 대체df['클릭수']=clk.astype(int)# headdf.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1864      0.268489      630.593475      1175174              4      3. html      HTML      9626374      814      0.008452      1408.435349      1145903        클릭률 : CTR = 클릭수 / 노출수 * 100=&gt; 클릭수가 변경되어 기존 클릭률(%) 열 데이터 변경필요# 데이터프레임의 열은 서로 수치연산 가능 df['클릭수']/df['노출수']*1000       0.4141491       1.0499152       0.0284753       0.2685474       0.008456          ...   1376    0.0000001377    0.0000001378    0.0000001379    0.0000001380    0.000000Length: 1381, dtype: float64df['클릭률(%)']=df['클릭수']/df['노출수']*100# headdf.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1864      0.268547      630.593475      1175174              4      3. html      HTML      9626374      814      0.008456      1408.435349      1145903      # 수치연산 예제1df['노출수']+df['클릭수']0       23290621        7755492       11381643        6959704       9627188         ...   1376      240161377      322871378      326021379      608441380      61193Length: 1381, dtype: int64# head# 수치연산 예제2df['총비용(VAT포함,원)']/df['클릭률(%)']0       6.066524e+061       2.271580e+062       5.509038e+073       4.376048e+064       1.355146e+08            ...     1376             NaN1377             NaN1378             NaN1379             NaN1380             NaNLength: 1381, dtype: float64  평균클릭비용 : 칼럼명에 원 단위로 명시됨 =&gt; 반올림처리, 일의 자리수로 변경df.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1864      0.268547      630.593475      1175174              4      3. html      HTML      9626374      814      0.008456      1408.435349      1145903      # cpc 변수 생성 ,평균클릭비용 int형으로 변경하기cpc=round(df['평균클릭비용(VAT포함,원)'],0)df['평균클릭비용(VAT포함,원)']=cpc.astype(int)# headdf.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606      0.414149      262      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058      1.049915      296      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324      0.028475      4842      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1864      0.268547      631      1175174              4      3. html      HTML      9626374      814      0.008456      1408      1145903      # 판다스를 활용한 데이터 탐색 실습  학습목표 :          데이터 탐색과정에서 사용되는 함수를 살펴보고 실전 사례를 통해 사용법을 익힌다.      import pandas as pdfrom pandas import DataFramefrom pandas import Seriesdf=pd.read_excel('naverreport.xls',skiprows=[0])#head() - 데이터의 첫 부분 출력, default : 첫 5행#데이터의 구성,칼럼명 등 대략적인 데이터 파악df.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903      #head() - 첫 10행df.head(10)                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.0      0.414149      261.549448      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.0      1.049915      295.974808      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.0      0.028475      4841.663580      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.6      0.268489      630.593475      1175174              4      3. html      HTML      9626374      813.6      0.008452      1408.435349      1145903              5      6. 파이썬      파이썬      384522      260.4      0.067720      3705.360983      964876              6      1. 코딩      코딩      562162      271.2      0.048242      3243.215339      879560              7      2. C언어 일반      C언어      271370      153.6      0.056602      5269.257812      809358              8      프로그래밍 전체_파워컨텐츠_블록체인(삭제)      가상화폐      91369      2838.0      3.106086      283.217054      803770              9      AOP 전체_중복키워드_디자인      포토샵      1887822      393.6      0.020849      1913.737297      753247      #tail() - 데이터의 끝 부분 출력, default : 끝 5행df.tail()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  1376      올인원 패키지 : 업무자동화_3. 엑셀      엑셀셀서식      24016      0.0      0.0      0.0      0              1377      올인원 패키지 : 업무자동화_3. 엑셀      MATCH      32287      0.0      0.0      0.0      0              1378      마케팅KPI수립      LTV      32602      0.0      0.0      0.0      0              1379      data_camp_rmp_8      DECISION      60844      0.0      0.0      0.0      0              1380      4. 웹의 동작      REST      61193      0.0      0.0      0.0      0      #tail() - 끝 10행df.tail(10)                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  1371      7. 운영체제      가상머신      16605      0.0      0.0      0.0      0              1372      파이낸스 전체      부동산책      16722      0.0      0.0      0.0      0              1373      ㅍ올인원 패키지 : UX/UI 디자인 입문_연관검색어(삭제)      VD      17504      0.0      0.0      0.0      0              1374      AOP 전체_중복키워드_디자인      포토샵단축키      18818      0.0      0.0      0.0      0              1375      올인원 패키지 : 업무자동화_3. 엑셀      SUMIF      23549      0.0      0.0      0.0      0              1376      올인원 패키지 : 업무자동화_3. 엑셀      엑셀셀서식      24016      0.0      0.0      0.0      0              1377      올인원 패키지 : 업무자동화_3. 엑셀      MATCH      32287      0.0      0.0      0.0      0              1378      마케팅KPI수립      LTV      32602      0.0      0.0      0.0      0              1379      data_camp_rmp_8      DECISION      60844      0.0      0.0      0.0      0              1380      4. 웹의 동작      REST      61193      0.0      0.0      0.0      0      #shape - dataframe의 크기(행, 열의 수)df.shape(1381, 7)#describe() - 각 열에 대한 기술통계량#데이터의 수, 평균, 표준편차, 최소값, 1사분위수, 2사분위수, 3사분위수, 최대값#지수 표기법(Exponential Notation, 10**n)df.describe()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  count      1.381000e+03      1381.000000      1381.000000      1381.000000      1.381000e+03              mean      3.505415e+04      52.530630      0.352871      981.631682      3.791958e+04              std      2.964650e+05      387.502772      1.000468      1372.390031      1.421492e+05              min      1.001000e+03      0.000000      0.000000      0.000000      0.000000e+00              25%      1.814000e+03      1.200000      0.007152      64.166667      7.700000e+01              50%      3.805000e+03      3.600000      0.061031      395.976793      2.123000e+03              75%      1.073400e+04      14.400000      0.237026      1302.812500      1.743500e+04              max      9.626374e+06      9606.000000      13.587402      9362.527778      2.512444e+06      #pandas출력 옵션설정 - float형식으로 수치표기  pd.set_option('display.float_format', '{:.2f}'.format) # 항상 float 형식으로#describe()df.describe()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  count      1381.00      1381.00      1381.00      1381.00      1381.00              mean      35054.15      52.53      0.35      981.63      37919.58              std      296465.03      387.50      1.00      1372.39      142149.16              min      1001.00      0.00      0.00      0.00      0.00              25%      1814.00      1.20      0.01      64.17      77.00              50%      3805.00      3.60      0.06      395.98      2123.00              75%      10734.00      14.40      0.24      1302.81      17435.00              max      9626374.00      9606.00      13.59      9362.53      2512444.00      #columns - 칼럼명 반환df.columnsIndex(['광고그룹', '키워드', '노출수', '클릭수', '클릭률(%)', '평균클릭비용(VAT포함,원)',       '총비용(VAT포함,원)'],      dtype='object')#unique() - 열(시리즈)의 고유값#df['광고그룹']df['광고그룹'].unique()array(['올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵', '올인원 패키지 : 업무자동화_VBA',       'ㅍAOP 전체_중복키워드_디자인(삭제)', '올인원 패키지 : 데이터 분석 입문 온라인_파콘', '3. html',       '6. 파이썬', '1. 코딩', '2. C언어 일반', '프로그래밍 전체_파워컨텐츠_블록체인(삭제)',       'AOP 전체_중복키워드_디자인', '디지털 마케팅 스쿨 13기_대표키워드', '인스타그램 마케팅',       '블록체인 신사업 시작하기', 'AOP 전체_중복키워드_비지니스', '올인원 패키지 : 업무자동화_2. 파이썬',       '올인원 패키지 : 1인 쇼핑몰 시작하기_00.창업_PC', '올인원 패키지 : 영상 제작/편집_6.프리미어프로',       '1. 모바일앱개발_교육', '올인원 패키지 : UX/UI 디자인 입문_연관검색어',       '올인원 패키지 : 데이터 분석 입문(파컨)', 'JavaScript BOOT CAMP', '1. 일반_PC',       'AOP 전체_중복키워드_공통', 'AOP 전체_중복키워드_프로그래밍', '003.퍼포먼스 마케팅',       '2. 프로그래밍', '마케팅 유치원', '올인원 패키지 : 업무자동화_1. 자동화', '올인원 패키지 : 브랜딩',       'ㅍ올인원 패키지 : 브랜딩', '올인원 패키지 : 콘텐츠 마케팅_카피라이팅',       'AOP 전체_중복키워드_데이터사이언스', '8. 시스템 프로그래밍',       'ㅍ올인원 패키지 : UX/UI 디자인 입문_연관검색어(삭제)', '올인원 패키지 : 프로그래밍 첫걸음 시작하기',       '페이스북&amp;인스타그램 마케팅 실전', 'Python &amp; Django를 활용한 웹 서비스_개발자', '5. 자료구조',       'fin_camp_auction_6', '올인원 패키지 : 1인 쇼핑몰_00.창업_MO', '타이포그래피와 편집디자인',       '올인원 패키지 : 디지털 마케팅_1. 디지털 마케팅', 'AOP 전체_중복키워드_마케팅',       '마케터를 위한 데이터 부트캠프', '코딩으로 여행하는 블록체인 서비스',       '올인원 패키지 : 1인 쇼핑몰 시작하기_02.쇼핑몰구축', '상업용 부동산 실무 입문 4기',       '포토샵 유치원_일러스트레이터 유치원', '고객의 마음을 읽는 구글애널리틱스',       '왕초보의 파이썬 웹 프로그래밍 CAMP', '올인원 패키지 : 콘텐츠 마케팅_영상바이럴', '마케팅KPI수립',       '프로그래밍 유치원', 'ㅍAOP 전체_중복키워드_프로그래밍(삭제)', '#000_마케팅 전체_main',       'SEO/SEM 전략', '올인원 패키지 : 투자_파워콘텐츠', 'ㅍAOP 전체_중복키워드_공통(삭제)',       '올인원 패키지 : 콘텐츠 마케팅_대표키워드', '올인원 패키지 : 파이썬 웹 개발_2.프론트엔드기초',       '올인원 패키지 : 업무자동화_4. VBA', '올인원 패키지 : 금융공학/퀀트_01.파이썬기본&amp;자동화',       'TensorFlow로 시작하는 딥러닝 입문', '올인원 패키지 : 업무자동화_3. 엑셀', '002.마케팅 입문',       '올인원 패키지 : 그로스해킹_5.마케팅 분석', '1. 데이터분석입문_일반', 'data_camp_rmp_8',       'ㅍAOP 전체_중복키워드_마케팅(삭제)', '올인원 패키지 : 게임 개발', '마케터를 위한 데이터 해석 실전',       '마케팅 전체', '1. 경영 일반', 'Vue로 구현하는 PWA CAMP', '1. 전체',       '001.데이터분석/ 통계', '5. javascript', 'ㅍ1. 전체',       '올인원 패키지 : 1인 쇼핑몰 시작하기_05.상품촬영', '1. 컴퓨터공학 일반',       '올인원 패키지 : 파이썬 웹 개발_3.FLASK기초', '올인원 패키지 : 디지털 마케팅_2. 페이스북 광고',       '올인원 패키지 : 영상 제작/편집_2.영상제작이론', '대기업을 이기는 브랜딩 전략',       '올인원 패키지 : 영상 제작/편집_9.유튜브/유튜버', '올인원 패키지 : 금융공학/퀀_03.금융공학',       '올인원 패키지 : 리더를 위한 HR/인재경영_1.인재', '내 아이템에 맞는 영상 콘텐츠 기획/제작',       'ㅍAOP 전체_중복키워드_데이터사이언스(삭제)', '올인원 패키지 : 그로스해킹_1.용어',       '1_벤처캐피탈에 대한 이해(벤처캐피탈)', '1. 일반_MO', '002.R',       'PYTHON &amp; DJANGO를 활용한  웹 서비스 개발', '올인원 패키지 : 디지털 마케팅_3. 구글 광고',       '올인원 패키지 : 1인 쇼핑몰 시작하기_06.해외쇼핑몰', 'LaTeX를 활용한 효율적 논문작성 Workshop',       '인디자인 유치원', 'ㅍAOP 전체_중복키워드_비지니스(삭제)', '딥러닝으로 배우는 병렬처리 CAMP',       '올인원 패키지 : 영상 제작/편집_3.촬영 기법/장비1', '올인원 패키지 : FAST MBA_파워컨텐츠_아마존',       '7. 운영체제', '실전 웹/앱 프로젝트 기획', '2_투자유치를 위한 사업계획서 작성(투자유치)',       '올인원 패키지 : 영상 제작/편집_10.패캠강의', '올인원 패키지 : 1인 쇼핑몰 시작하기_01.플랫폼',       '다빈치리졸브와 컬러그레이딩', '파이썬을 통한 금융 데이터 수집과 분석 자동화 16기',       '실전 웹 UX/UI 디자인', '올인원 패키지 : 영상 제작/편집_7.에프터이펙트', '파이썬 텍스트 마이닝',       'data_camp_pcda_3', '5_초기 스타트업 실제 투자사례(창업자)', '1. 모바일앱개발_세부',       'Python &amp; Django를 활용한 웹 서비스_일반', '005.머신러닝',       '올인원 패키지 : 영상 제작/편집_5.일러스트', '구글 광고', '올인원 패키지 : 영상 제작/편집_1.크리에이터',       '딥러닝으로 배우는 병렬처리 CAMP_구버전', '건강한 조직을 만드는 HR 전략 WORKSHOP',       '6.  컴퓨터구조', '003.파이썬', 'fin_camp_modeling_15', 'Apache Spark',       '올인원 패키지 : 금융공학/퀀_02.R활용금융데이터분석', '모바일 앱 UX/UI 디자인',       '001.BASIC DESIGN', '올인원 패키지 : 영상 제작/편집_8.파이널컷 프로',       '1. 앱웹서비스기획_일반', '프로그래밍 전체', '리눅스 인프라',       'OpenCV와 함께하는 컴퓨터 비전 프로그래밍', '서비스 기획 스쿨 5기_구글 연관검색어',       '올인원 패키지 : 금융공학/퀀트_00.일반', '올인원 패키지 : 리더를 위한 HR/인재경영_2.리더십',       '4_벤처캐피탈 투자계약(벤처 투자)', 'fin_camp_rdev_4', '파이낸스 전체',       'typescript 실전 workshop', '비즈니스 전체', '4. css', '영상 콘텐츠 디자인 유치원',       '올인원 패키지 : 디지털 마케팅_5. 태그매니저', '007.빅데이터',       '모바일 앱 GUI 포트폴리오 디자인 LAB', '올인원 패키지 : 디지털 마케팅_8. 검색 마케팅',       'Javascript 정복 프로젝트', '올인원 패키지 : 콘텐츠 마케팅_콘텐츠 제작',       '올인원 패키지 : 디지털 마케팅_트위터광고', '올인원 패키지 : 1인 쇼핑몰 시작하기_04.호스팅사',       '쉽고 재미있는 재무제표 분석 17기', '1_2 대표 경쟁', 'Java 웹 프로그래밍 마스터 4기 : 3개월',       '올인원 패키지 : 그로스해킹_2.그로스해킹', '크리에이티브 전체', '002.UX/UI',       'fin_camp_feasibilitystudy_18', 'Vue.js 정복 CAMP', '4. 웹의 동작',       '머신러닝을 위한 선형대수학', '6_스타트업 M&amp;A에 대한 단상(스타트업)', 'iOS 개발 스쿨 9기_기존 키워드',       '006.딥러닝', 'UX 디자인 실전', '디지털 마케팅', '올인원 패키지 : 리더를 위한 HR/인재경영_5.HR',       '올인원 패키지 : 영상 제작/편집_4.포토샵', '데이터 사이언스 전체',       '올인원 패키지 : 파이썬 웹 개발_4.Django', '올인원 패키지 : 리더를 위한 HR/인재경영_3.온보딩',       '3. 파이썬', '컴퓨터공학으로 풀어낸 블록체인 코어 CAMP', '7_How to 벤처캐피탈',       '3_기업가치평가 방법론', '자율주행 연구를 위한 ROS·SLAM Workshop',       '프론트엔드 개발 스쿨 12기_기존 키워드', '개발자와 협업하는 디자이너를 위한 실무 역량 강화',       '올인원 패키지 : 1인 쇼핑몰 시작하기_03.결제시스템', '웹 프로그래밍 스쿨 10기_기존 키워드',       '올인원 패키지 : 디지털 마케팅_인스타광고', '다함께 DDD 프로젝트', 'fin_camp_rfs_9',       'Hyperledger Fabric 프로젝트 CAMP', 'fin_camp_business_4'],      dtype=object)#len, unique()#df['광고그룹']len(df['광고그룹'].unique())186#unique()#df['키워드']df['키워드'].unique()array(['-', '일러스트', 'HTML', ..., 'MATCH', 'DECISION', 'REST'],      dtype=object)#len, unique()#df['키워드']len(df['키워드'].unique())1112#value_counts() - 열의 고유값 빈도#df['광고그룹']df['광고그룹'].value_counts()올인원 패키지 : 업무자동화_3. 엑셀        93AOP 전체_중복키워드_디자인             57#000_마케팅 전체_main             48ㅍAOP 전체_중복키워드_디자인(삭제)        46타이포그래피와 편집디자인                26                             ..올인원 패키지 : 금융공학/퀀트_00.일반       1컴퓨터공학으로 풀어낸 블록체인 코어 CAMP      1쉽고 재미있는 재무제표 분석 17기           1올인원 패키지 : 데이터 분석 입문(파컨)       1올인원 패키지 : 영상 제작/편집_5.일러스트     1Name: 광고그룹, Length: 186, dtype: int64#value_counts()#df['키워드']df['키워드'].value_counts()-         8구글광고      5GUI       5포토샵       5브랜딩       4         ..SNS홍보     1금융스터디     1ILLUST    1영상학원      1엑셀다중조건    1Name: 키워드, Length: 1112, dtype: int64#sort_values() - 정렬(default : 오름차순)#노출수 기준 정렬df['노출수'].sort_values()1057       1001445        1003597        1005983        1006442        1007         ...   13      14704529       18878220       2319456173     30959984       9626374Name: 노출수, Length: 1381, dtype: int64#sort_values(ascending=False) - 내림차순 정렬#노출수 기준 정렬df['노출수'].sort_values(ascending=False)4       9626374173     30959980       23194569       188782213      1470452         ...   442        1007983        1006597        1005445        10031057       1001Name: 노출수, Length: 1381, dtype: int64#sort_values - 정렬(default : 오름차순)#클릭수 기준 정렬df['클릭수'].sort_values()1380      0.001159      0.001160      0.001161      0.001162      0.00         ...  26     2535.6083     2798.408      2838.001      8058.000      9606.00Name: 클릭수, Length: 1381, dtype: float64#sort_values(ascending=False) 정렬(내림차순)#클릭수df['클릭수'].sort_values(ascending=False)0      9606.001      8058.008      2838.0083     2798.4026     2535.60         ...  1163      0.001162      0.001160      0.001159      0.001380      0.00Name: 클릭수, Length: 1381, dtype: float64시각화를 통한 데이터 탐색 실습  학습목표 :          현업의 데이터를 사용하여 데이터 시각화를 실습한다.      데이터를 가공,처리하여 시각화를 진행한다.        chapter1 - 03. 시각화 라이브러리 matplotlib  시리즈 시각화import pandas as pdfrom pandas import DataFramefrom pandas import Seriesimport matplotlib.pyplot as plt# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlibfrom matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   #노출수 칼럼 시각화#데이터프레임 시각화 &lt;-&gt; 시리즈 시각화#type함수type(df['노출수'])pandas.core.series.Series#plottingdf['노출수'].plot()plt.show()  명확한 패턴이 보일 수 있도록 데이터시각화 진행          as-is : index를 기준으로 출력(그래프의 x축이 시리즈의 인덱스)      to-be : 정렬된 value를 기준으로 출력2-1. 시리즈의 value를 수치 순서대로 오름차순 정렬2-2. 정렬된 데이터의 형태대로 index 재생성 후 시각화      #보충예제 - chapter 1 - 03. 시각화 라이브러리 matplotlib dict_data={\"철수\":[1,2,3,4],\"영희\":[2,3,4,5],\"민수\":[3,4,5,6],\"수진\":[4,5,6,7]}data=DataFrame(dict_data)#철수 칼럼(데이터프레임의 열 = 시리즈 자료구조) 출력data['철수']0    11    22    33    4Name: 철수, dtype: int64#plotting#시리즈의 index가 x축, value가 y축data['철수'].plot()plt.show()#시리즈의 index가 x축, value가 y축df['노출수'].head()0    23194561     7674912    11378403     6941064    9626374Name: 노출수, dtype: int64#plottingdf['노출수'].plot()plt.show()  패턴이 명확하게 드러나도록 데이터시각화 진행          as-is : index를 기준으로 출력(그래프의 x축이 시리즈의 인덱스)      to-be : 정렬된 value를 기준으로 출력2-1. 시리즈의 value를 수치 순서대로 오름차순 정렬2-2. 정렬된 데이터의 형태대로 index 재생성 후 시각화      #2-1. 시리즈의 value를 수치 순서대로 오름차순 정렬#노출수 칼럼, sort_values()imp_sort=df['노출수'].sort_values()#imp_sort 변수 출력imp_sort1057       1001445        1003597        1005983        1006442        1007         ...   13      14704529       18878220       2319456173     30959984       9626374Name: 노출수, Length: 1381, dtype: int64#reset_index() - 인덱스 재생성, 기존 인덱스를 데이터프레임의 열로 반환imp_sort=imp_sort.reset_index()#imp_sort 변수 출력imp_sort                  index      노출수                  0      1057      1001              1      445      1003              2      597      1005              3      983      1006              4      442      1007              ...      ...      ...              1376      13      1470452              1377      9      1887822              1378      0      2319456              1379      173      3095998              1380      4      9626374      1381 rows × 2 columns#drop('삭제할 인덱스명', axis=1) - 삭제(열 기준)imp_sort.drop('index',axis=1)                  노출수                  0      1001              1      1003              2      1005              3      1006              4      1007              ...      ...              1376      1470452              1377      1887822              1378      2319456              1379      3095998              1380      9626374      1381 rows × 1 columns#imp_sort 변수 출력imp_sort#해당 변수의 index 칼럼 미삭제                  index      노출수                  0      1057      1001              1      445      1003              2      597      1005              3      983      1006              4      442      1007              ...      ...      ...              1376      13      1470452              1377      9      1887822              1378      0      2319456              1379      173      3095998              1380      4      9626374      1381 rows × 2 columns#inplace=Trueimp_sort.drop('index',axis=1,inplace=True)#imp_sort 변수 출력, #기존 변수의 index칼럼 삭제 확인imp_sort                  노출수                  0      1001              1      1003              2      1005              3      1006              4      1007              ...      ...              1376      1470452              1377      1887822              1378      2319456              1379      3095998              1380      9626374      1381 rows × 1 columns#imp_sort plottingimp_sort.plot()plt.show()#클릭수칼럼 시각화 #sort_values(),reset_index(),drop('index',axis=1),plot - 한줄 코딩(괄호사용)(((df['클릭수'].sort_values()).reset_index()).drop('index',axis=1)).plot()plt.show()#총비용칼럼 시각화#위 코드에서 칼럼명만 변경(((df['총비용(VAT포함,원)'].sort_values()).reset_index()).drop('index',axis=1)).plot()plt.show()데이터 분석  학습목표 :          파이썬과 판다스를 사용하여 데이터를 처리, 분석할 수 있다.      중점관리키워드 추출  노출수, 클릭수 기준 상위 5%에 해당하는 키워드 추출          95백분위수 찾기(quantile 함수 사용)      95백분위수 이상(상위 5%)의 노출수 추출      상위 5%에 해당하는 키워드 추출      #노출수 칼럼 imp변수에 할당imp=df['노출수']#1. 95백분위수 찾기#quantile - 분위수 출력(default : 2사분위수(중앙값))imp.quantile()3805.0#median - 중앙값imp.median()3805.0#quantile(0) - 최소값print(imp.quantile(0))print(imp.min())1001.01001#quantile(1) - 최대값print(imp.quantile(1))print(imp.max())9626374.09626374#95백분위수 = quantile(0.95)imp.quantile(0.95)82858.0#2. 95백분위수 이상(상위 5%)의 노출수 추출#series[condition]imp=imp[imp&gt;=imp.quantile(0.95)]#imp 출력imp0      23194561       7674912      11378403       6941064      9626374        ...   698     196862741      94933763      82858777     126393780      90041Name: 노출수, Length: 70, dtype: int64  상위 5%에 해당하는 키워드 추출 -기존 상위 노출수 추출과정          as-is : 데이터프레임의 기본숫자인덱스      to-be : 데이터프레임의 인덱스를 ‘키워드’로 재설정      #실습예제 원본#head()df.head()                  광고그룹      키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)                  0      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      -      2319456      9606.00      0.41      261.55      2512444              1      올인원 패키지 : 업무자동화_VBA      -      767491      8058.00      1.05      295.97      2384965              2      ㅍAOP 전체_중복키워드_디자인(삭제)      일러스트      1137840      324.00      0.03      4841.66      1568699              3      올인원 패키지 : 데이터 분석 입문 온라인_파콘      -      694106      1863.60      0.27      630.59      1175174              4      3. html      HTML      9626374      813.60      0.01      1408.44      1145903      #데이터프레임의 인덱스를 키워드로 변경#set_index('키워드')df_index=df.set_index('키워드')#df_index df_index                  광고그룹      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                      -      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      2319456      9606.00      0.41      261.55      2512444              -      올인원 패키지 : 업무자동화_VBA      767491      8058.00      1.05      295.97      2384965              일러스트      ㅍAOP 전체_중복키워드_디자인(삭제)      1137840      324.00      0.03      4841.66      1568699              -      올인원 패키지 : 데이터 분석 입문 온라인_파콘      694106      1863.60      0.27      630.59      1175174              HTML      3. html      9626374      813.60      0.01      1408.44      1145903              ...      ...      ...      ...      ...      ...      ...              엑셀셀서식      올인원 패키지 : 업무자동화_3. 엑셀      24016      0.00      0.00      0.00      0              MATCH      올인원 패키지 : 업무자동화_3. 엑셀      32287      0.00      0.00      0.00      0              LTV      마케팅KPI수립      32602      0.00      0.00      0.00      0              DECISION      data_camp_rmp_8      60844      0.00      0.00      0.00      0              REST      4. 웹의 동작      61193      0.00      0.00      0.00      0      1381 rows × 6 columns#df_index에서 imp변수 생성 및 quantile(0.95)imp=df_index['노출수']#imp 변수 출력, 노출수 상위 5% 키워드 추출imp=imp[imp&gt;=imp.quantile(0.95)]imp키워드-         2319456-          767491일러스트      1137840-          694106HTML      9626374           ...   부동산스터디     196862가상메모리       94933프로모션        82858앱스토어       126393OS          90041Name: 노출수, Length: 70, dtype: int64#df_index에서 클릭수 상위 5% 키워드 추출clk=df_index['클릭수']clk=clk[clk&gt;=clk.quantile(0.95)]#clk 변수 출력, 클릭수 상위 5% 키워드 출력clk키워드-         9606.00-         8058.00일러스트       324.00-         1863.60HTML       813.60            ...  재태크        126.00모스자격증      198.00펀드하는법      248.40채권투자       135.60주식투자하는법    120.00Name: 클릭수, Length: 70, dtype: float64# 중점관리키워드 선별  노출수와 클릭수 모두 95백분위수 이상# 조건이 여러개일  경우  데이터프레임[(조건문)&amp;(조건문)]#df_index에서 imp, clk 변수 생성imp=df_index['노출수']clk=df_index['클릭수']#노출수와 클릭수 모두 상위5%(95백분위수 이상) 추출result=df_index[(imp&gt;=imp.quantile(0.95))&amp;(clk&gt;=clk.quantile(0.95))]#result변수 출력result                  광고그룹      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              키워드                                                      -      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      2319456      9606.00      0.41      261.55      2512444              -      올인원 패키지 : 업무자동화_VBA      767491      8058.00      1.05      295.97      2384965              일러스트      ㅍAOP 전체_중복키워드_디자인(삭제)      1137840      324.00      0.03      4841.66      1568699              -      올인원 패키지 : 데이터 분석 입문 온라인_파콘      694106      1863.60      0.27      630.59      1175174              HTML      3. html      9626374      813.60      0.01      1408.44      1145903              파이썬      6. 파이썬      384522      260.40      0.07      3705.36      964876              코딩      1. 코딩      562162      271.20      0.05      3243.22      879560              C언어      2. C언어 일반      271370      153.60      0.06      5269.26      809358              가상화폐      프로그래밍 전체_파워컨텐츠_블록체인(삭제)      91369      2838.00      3.11      283.22      803770              포토샵      AOP 전체_중복키워드_디자인      1887822      393.60      0.02      1913.74      753247              블록체인      블록체인 신사업 시작하기      200243      236.40      0.12      2721.99      643478              엑셀      AOP 전체_중복키워드_비지니스      1470452      450.00      0.03      1408.66      633897              -      올인원 패키지 : 데이터 분석 입문(파컨)      139717      618.00      0.44      636.45      393327              포토샵      올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵      124068      2535.60      2.04      150.40      381359              컴퓨터활용능력      올인원 패키지 : 업무자동화_VBA      139729      1534.80      1.10      239.21      367147              컴퓨터활용능력2급      올인원 패키지 : 업무자동화_VBA      88751      1282.80      1.45      233.91      300058              컴퓨터활용능력1급      올인원 패키지 : 업무자동화_VBA      94757      1191.60      1.26      236.67      282018              포토샵      ㅍAOP 전체_중복키워드_디자인(삭제)      1021846      157.20      0.02      1625.16      255475              -      올인원 패키지 : 프로그래밍 첫걸음 시작하기      88800      598.80      0.67      351.79      210650              프리미어프로      AOP 전체_중복키워드_디자인      213033      132.00      0.06      1573.50      207702              폰트      타이포그래피와 편집디자인      478588      474.00      0.10      395.98      187693              스케치      AOP 전체_중복키워드_디자인      200487      133.20      0.07      1165.57      155254              포토샵      포토샵 유치원_일러스트레이터 유치원      691814      129.60      0.02      1051.54      136279              글씨체      타이포그래피와 편집디자인      106648      216.00      0.20      425.03      91806              한글폰트      타이포그래피와 편집디자인      82983      206.40      0.25      307.62      63492              마블      ㅍAOP 전체_중복키워드_디자인(삭제)      907619      228.00      0.03      265.50      60533              바이럴마케팅      마케팅 전체      3095998      261.60      0.01      220.04      57563      #index - 중점관리키워드 출력result.indexIndex(['-', '-', '일러스트', '-', 'HTML', '파이썬', '코딩', 'C언어', '가상화폐', '포토샵',       '블록체인', '엑셀', '-', '포토샵', '컴퓨터활용능력', '컴퓨터활용능력2급', '컴퓨터활용능력1급', '포토샵',       '-', '프리미어프로', '폰트', '스케치', '포토샵', '글씨체', '한글폰트', '마블', '바이럴마케팅'],      dtype='object', name='키워드')# 저효율키워드 선별#노출수 선그래프imp_sort.plot()plt.show()#클릭수 선그래프(((df['클릭수'].sort_values()).reset_index()).drop('index',axis=1)).plot()plt.show()#총비용 선그래프(((df['총비용(VAT포함,원)'].sort_values()).reset_index()).drop('index',axis=1)).plot()plt.show()  노출수, 클릭수  기준 상위 5%의 키워드가 아닌데도 불구하고 비용이 많이 쓰이고 있는 키워드          노출수 95백분위수 미만      클릭수 95백분위수 미만      총비용 85백분위수 이상      총비용 95백분위수 미만      ### # 조건이 여러개일  경우  데이터프레임[(조건문)&amp;(조건문)]#df_index로 cost 변수 생성cost=df_index['총비용(VAT포함,원)']# 데이터프레임[(조건문)&amp;(조건문)]result=df_index[(imp&lt;imp.quantile(0.95))&amp;(clk&lt;clk.quantile(0.95))&amp;(cost&gt;=cost.quantile(0.85))&amp;(cost&lt;cost.quantile(0.95))]#index - 저효율키워드 출력result.indexIndex(['온라인마케팅교육', '온라인마케팅', '어플제작비용', '부동산경매', '퍼포먼스마케팅', '블록체인', 'C++',       '게임만드는프로그램', '엑셀배우기', '앱만들기', '영상제작', '쇼핑몰제작', '에프터이펙트', '어플리케이션제작',       '강남빌딩매매', '웹디자인', '디지털마케팅', '포토샵강의', '구글애널리틱스자격증', 'PYTHON', '페이스북광고',       '유튜브마케팅', '게임제작', '부동산투자', '마케팅전략', 'PYTHON', '홈페이지만들기', 'B2B사이트',       'JAVASCRIPT', '파이썬강좌', '인스타그램광고', '동영상제작', 'SEO', '쇼핑몰창업', '인터넷쇼핑몰',       '게임프로그래밍학원', '프로그래밍', '서울빌딩매매', '데이터사이언스', '모바일게임제작', '엑셀학원',       '유튜브크리에이터', '엑셀VBA', '영상편집학원', '텐서플로우', '쇼핑몰홈페이지제작', '엑셀교육', '그로스해킹',       '게임개발', '광고대행사', '통계학원', '모바일앱개발', '안드로이드앱만들기', '파이썬기초', '하이브리드앱',       '온라인마케팅', '인디자인', '검색엔진최적화', '엑셀실무', '인터넷쇼핑몰제작', '상가빌딩매매', '퍼포먼스마케팅',       '쇼핑몰', 'UX디자인', '유니티강좌', 'VBA', '코딩이란', 'SNS마케팅', 'GA자격증', '콘텐츠제작',       '구글애널리틱스', 'UI디자인', '1인미디어', '포토샵자격증', '하이브리드앱', '포토샵자격증', '브랜드네이밍',       '리플렛디자인', '데이터사이언티스트', '유니티3D', '자바스크립트', '일러스트레이터강좌', '데이터분석준전문가',       '유튜브편집', '모션그래픽', '리플렛디자인', 'SPRING', '어도비일러스트레이터', 'SNS광고', '쇼핑몰촬영',       '브랜드마케팅', '데이터분석', 'PHP', 'UXUI', 'SQL', 'UI디자인', '웹크롤링'],      dtype='object', name='키워드')광고그룹 분석  학습목표 :          groupby함수 사용실습      키워드 분석과정에서 진행한 코딩 복습      as-is : 키워드  기준 분석  키워드의 노출수/클릭수/총비용…to-be : 광고그룹 기준 분석  데이터의 구성을 광고그룹 기준으로 변경해야함  광고그룹의 노출수/클릭수/총비용…  groupby 함수 사용#groupby - 전달된 열을 기준으로 전체 데이터를 분류grouped=df.groupby('광고그룹') #텍스트 오름차순으로 정렬됨#해당변수 출력시 객체정보만 출력됨grouped#데이터를 살펴보기 위하여는 집계함수 사용해야 함&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000014193D347F0&gt;#count - 각 광고그룹 데이터의 개수grouped.count()                  키워드      노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                      #000_마케팅 전체_main      48      48      48      48      48      48              001.BASIC DESIGN      9      9      9      9      9      9              001.데이터분석/ 통계      10      10      10      10      10      10              002.R      9      9      9      9      9      9              002.UX/UI      5      5      5      5      5      5              ...      ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      13      13      13      13      13      13              프로그래밍 유치원      8      8      8      8      8      8              프로그래밍 전체      12      12      12      12      12      12              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      3      3      3      3      3      3              프론트엔드 개발 스쿨 12기_기존 키워드      1      1      1      1      1      1      186 rows × 6 columns#mean -각 광고그룹 데이터의 평균grouped.mean()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      14780.15      8.40      0.18      625.09      7243.96              001.BASIC DESIGN      5738.56      6.80      0.23      298.69      2427.33              001.데이터분석/ 통계      3715.00      20.28      0.89      1021.47      19575.60              002.R      13413.78      8.53      0.11      360.04      4796.00              002.UX/UI      3090.80      4.08      0.09      69.93      550.00              ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      72092.69      16.71      0.05      648.33      15781.62              프로그래밍 유치원      5921.62      7.80      0.22      2032.33      23617.00              프로그래밍 전체      90375.00      9.20      0.02      123.88      1626.17              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      65353.33      2344.40      3.64      192.77      431159.67              프론트엔드 개발 스쿨 12기_기존 키워드      2015.00      2.40      0.12      64.17      154.00      186 rows × 5 columns#median - 그룹 데이터의 중앙값grouped.median()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      2765.00      3.60      0.06      765.97      2458.50              001.BASIC DESIGN      5524.00      2.40      0.04      357.50      1023.00              001.데이터분석/ 통계      1813.00      13.80      0.57      1096.80      13464.00              002.R      5184.00      3.60      0.03      119.17      1287.00              002.UX/UI      2649.00      1.20      0.09      73.33      88.00              ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      5763.00      3.60      0.02      852.50      2706.00              프로그래밍 유치원      3748.00      3.00      0.12      1763.82      8002.50              프로그래밍 전체      3455.50      1.20      0.01      130.50      225.50              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      64981.00      2798.40      3.52      239.81      334961.00              프론트엔드 개발 스쿨 12기_기존 키워드      2015.00      2.40      0.12      64.17      154.00      186 rows × 5 columns#std - 그룹 데이터의 표준편차grouped.std()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      43495.11      17.73      0.31      472.87      15854.71              001.BASIC DESIGN      4182.62      9.14      0.47      176.15      3220.04              001.데이터분석/ 통계      4109.84      18.32      0.82      269.59      19127.40              002.R      19333.63      14.71      0.17      371.70      10077.59              002.UX/UI      1996.65      7.18      0.11      69.11      1005.28              ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      188247.58      35.27      0.06      470.85      37543.64              프로그래밍 유치원      6642.34      9.77      0.25      1649.70      37088.92              프로그래밍 전체      200385.15      17.26      0.03      119.98      2801.70              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      25831.51      820.88      0.61      121.02      335034.37              프론트엔드 개발 스쿨 12기_기존 키워드      NaN      NaN      NaN      NaN      NaN      186 rows × 5 columns#var - 그룹 데이터의 분산grouped.var()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      1891824593.19      314.41      0.10      223602.50      251371923.49              001.BASIC DESIGN      17494344.53      83.52      0.22      31027.33      10368671.50              001.데이터분석/ 통계      16890757.78      335.50      0.67      72677.81      365857245.60              002.R      373789206.44      216.52      0.03      138163.90      101557901.50              002.UX/UI      3986602.70      51.55      0.01      4775.52      1010592.00              ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      35437152679.06      1243.79      0.00      221698.50      1409525055.09              프로그래밍 유치원      44120700.55      95.45      0.06      2721526.39      1375588223.43              프로그래밍 전체      40154209477.09      298.04      0.00      14394.51      7849530.33              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      667267044.33      673851.36      0.37      14645.70      112248026722.33              프론트엔드 개발 스쿨 12기_기존 키워드      NaN      NaN      NaN      NaN      NaN      186 rows × 5 columns광고그룹 기준 데이터 전처리#그룹데이터의 합계(sum) - 노출수,클릭수,총비용 칼럼grouped.sum()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      709447      403.20      8.83      30004.14      347710              001.BASIC DESIGN      51647      61.20      2.10      2688.24      21846              001.데이터분석/ 통계      37150      202.80      8.91      10214.73      195756              002.R      120724      76.80      1.00      3240.35      43164              002.UX/UI      15454      20.40      0.45      349.64      2750              ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      937205      217.20      0.66      8428.26      205161              프로그래밍 유치원      47373      62.40      1.80      16258.61      188936              프로그래밍 전체      1084500      110.40      0.29      1486.58      19514              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      196060      7033.20      10.93      578.32      1293479              프론트엔드 개발 스쿨 12기_기존 키워드      2015      2.40      0.12      64.17      154      186 rows × 5 columns#df_group 변수 출력df_group=grouped.sum()df_group# 클릭률, 평균클릭비용 칼럼 전처리 # as-is : 키워드에 대한 클릭률의 총합(sum), 키워드에 대한 평균클릭비용의 총합(sum)# to-be : 광고그룹에 대한 클릭률, 광고그룹에 대한 평균클릭비용                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      709447      403.20      8.83      30004.14      347710              001.BASIC DESIGN      51647      61.20      2.10      2688.24      21846              001.데이터분석/ 통계      37150      202.80      8.91      10214.73      195756              002.R      120724      76.80      1.00      3240.35      43164              002.UX/UI      15454      20.40      0.45      349.64      2750              ...      ...      ...      ...      ...      ...              포토샵 유치원_일러스트레이터 유치원      937205      217.20      0.66      8428.26      205161              프로그래밍 유치원      47373      62.40      1.80      16258.61      188936              프로그래밍 전체      1084500      110.40      0.29      1486.58      19514              프로그래밍 전체_파워컨텐츠_블록체인(삭제)      196060      7033.20      10.93      578.32      1293479              프론트엔드 개발 스쿨 12기_기존 키워드      2015      2.40      0.12      64.17      154      186 rows × 5 columns#클릭률(ctr) = 클릭수 / 노출수#데이터전처리 - 데이터프레임의 열 단위 수치연산df_group['클릭률(%)']=df_group['클릭수']/df_group['노출수']#평균클릭비용(cpc) = 총비용 / 클릭수#데이터전처리 - 데이터프레임의 열 단위 수치연산df_group['평균클릭비용(VAT포함,원)']=df_group['총비용(VAT포함,원)']/df_group['클릭수']#클릭수 칼럼 중 0인 데이터가 존재 =&gt; 평균클릭비용 칼럼 중 결측값이 존재df_group[df_group['클릭수']==0]                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                Hyperledger Fabric 프로젝트 CAMP      1990      0.00      0.00      NaN      0              fin_camp_business_4      2136      0.00      0.00      NaN      0              fin_camp_rfs_9      1928      0.00      0.00      NaN      0              다함께 DDD 프로젝트      3689      0.00      0.00      NaN      0              올인원 패키지 : 디지털 마케팅_인스타광고      1377      0.00      0.00      NaN      0      #fillna - 전달된 값으로 결측값을 대체하는 함수 #평균클릭비용df_group['평균클릭비용(VAT포함,원)']=df_group['평균클릭비용(VAT포함,원)'].fillna(0)df_group[df_group['클릭수']==0]                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                Hyperledger Fabric 프로젝트 CAMP      1990      0.00      0.00      0.00      0              fin_camp_business_4      2136      0.00      0.00      0.00      0              fin_camp_rfs_9      1928      0.00      0.00      0.00      0              다함께 DDD 프로젝트      3689      0.00      0.00      0.00      0              올인원 패키지 : 디지털 마케팅_인스타광고      1377      0.00      0.00      0.00      0      # 평균클릭비용 칼럼 반올림처리(round), 소수점 제거(astype(int)df_group['평균클릭비용(VAT포함,원)']=round(df_group['평균클릭비용(VAT포함,원)'],0)df_group['평균클릭비용(VAT포함,원)']=df_group['평균클릭비용(VAT포함,원)'].astype(int)#head()df_group.head()                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                #000_마케팅 전체_main      709447      403.20      0.00      862      347710              001.BASIC DESIGN      51647      61.20      0.00      357      21846              001.데이터분석/ 통계      37150      202.80      0.01      965      195756              002.R      120724      76.80      0.00      562      43164              002.UX/UI      15454      20.40      0.00      135      2750      데이터 시각화#노출수 칼럼 선그래프df_group['노출수'].plot()plt.show()  명확한 패턴이 보일 수 있도록 데이터시각화 진행          as-is : index를 기준으로 출력(그래프의 x축이 시리즈의 인덱스)      to-be : 정렬된 value를 기준으로 출력2-1. 시리즈의 value를 수치 순서대로 오름차순 정렬2-2. 정렬된 데이터의 형태대로 index 재생성 후 시각화      #노출수 칼럼 선그래프#sort_values(),reset_index(),drop('index',axis=1),plot - 한줄 코딩(괄호사용)(((df_group['노출수'].sort_values()).reset_index()).drop('광고그룹',axis=1)).plot()plt.show()#클릭수 칼럼 선그래프(((df_group['클릭수'].sort_values()).reset_index()).drop('광고그룹',axis=1)).plot()plt.show()#총비용 칼럼 선그래프(((df_group['총비용(VAT포함,원)'].sort_values()).reset_index()).drop('광고그룹',axis=1)).plot()plt.show()# 중점관리 광고그룹 / 저효율 광고그룹  중점관리 광고그룹          상위20%(노출수 80백분위수 이상)      상위10%(클릭수 90백분위수 이상)      #df_group에서 imp, clk 변수 생성imp=df_group['노출수']clk=df_group['클릭수']#조건이 여러개일 경우 #데이터프레임[(조건문)&amp;(조건문)]result=df_group[(imp&gt;=imp.quantile(0.8))&amp;(clk&gt;=clk.quantile(0.9))]#index - 중점관리 광고그룹 출력result.indexIndex(['#000_마케팅 전체_main', '1. 코딩', '3. html', '6. 파이썬', 'AOP 전체_중복키워드_디자인',       'AOP 전체_중복키워드_비지니스', 'ㅍAOP 전체_중복키워드_디자인(삭제)', '마케팅 전체',       '올인원 패키지 : 데이터 분석 입문 온라인_파콘', '올인원 패키지 : 디자인 툴_파워컨텐츠_포토샵',       '올인원 패키지 : 업무자동화_VBA', '타이포그래피와 편집디자인', '프로그래밍 전체_파워컨텐츠_블록체인(삭제)'],      dtype='object', name='광고그룹')  저효율 광고그룹 :  노출수, 클릭수  기준 상위의 키워드가 아닌데도 불구하고 비용이 많이 쓰이고 있는 광고그룹          노출수 80백분위수 미만      클릭수 90백분위수 미만      총비용 60백분위수 이상      총비용 90백분위수 미만      #df_group에서 cost 변수 생성cost=df_group['총비용(VAT포함,원)']#조건이 여러개일 경우 #데이터프레임[(조건문)&amp;(조건문)]result=df_group[(imp&lt;imp.quantile(0.8))&amp;(clk&lt;clk.quantile(0.9))&amp;(cost&gt;=cost.quantile(0.6))&amp;(cost&lt;cost.quantile(0.9))]#index - 저효율 광고그룹 출력result.indexIndex(['001.데이터분석/ 통계', '002.마케팅 입문', '003.퍼포먼스 마케팅', '1. 전체', '2. 프로그래밍',       '5. 자료구조', 'AOP 전체_중복키워드_공통', 'AOP 전체_중복키워드_데이터사이언스',       'AOP 전체_중복키워드_프로그래밍', 'JavaScript BOOT CAMP',       'Python &amp; Django를 활용한 웹 서비스_개발자', 'SEO/SEM 전략',       'TensorFlow로 시작하는 딥러닝 입문', 'fin_camp_auction_6', 'ㅍAOP 전체_중복키워드_공통(삭제)',       'ㅍAOP 전체_중복키워드_마케팅(삭제)', 'ㅍAOP 전체_중복키워드_프로그래밍(삭제)',       'ㅍ올인원 패키지 : UX/UI 디자인 입문_연관검색어(삭제)', 'ㅍ올인원 패키지 : 브랜딩',       '고객의 마음을 읽는 구글애널리틱스', '대기업을 이기는 브랜딩 전략', '마케터를 위한 데이터 부트캠프',       '마케터를 위한 데이터 해석 실전', '마케팅 유치원', '마케팅KPI수립',       '올인원 패키지 : 1인 쇼핑몰 시작하기_02.쇼핑몰구축', '올인원 패키지 : 1인 쇼핑몰_00.창업_MO',       '올인원 패키지 : UX/UI 디자인 입문_연관검색어', '올인원 패키지 : 그로스해킹_5.마케팅 분석',       '올인원 패키지 : 디지털 마케팅_1. 디지털 마케팅', '올인원 패키지 : 브랜딩',       '올인원 패키지 : 업무자동화_1. 자동화', '올인원 패키지 : 업무자동화_4. VBA',       '올인원 패키지 : 영상 제작/편집_9.유튜브/유튜버', '왕초보의 파이썬 웹 프로그래밍 CAMP',       '코딩으로 여행하는 블록체인 서비스', '페이스북&amp;인스타그램 마케팅 실전', '프로그래밍 유치원'],      dtype='object', name='광고그룹')result                  노출수      클릭수      클릭률(%)      평균클릭비용(VAT포함,원)      총비용(VAT포함,원)              광고그룹                                                001.데이터분석/ 통계      37150      202.80      0.01      965      195756              002.마케팅 입문      20372      188.40      0.01      570      107371              003.퍼포먼스 마케팅      10453      164.40      0.02      3152      518177              1. 전체      124351      128.40      0.00      1409      180906              2. 프로그래밍      109531      182.40      0.00      2239      408364              5. 자료구조      40328      46.80      0.00      4317      202037              AOP 전체_중복키워드_공통      4336      66.00      0.02      4624      305195              AOP 전체_중복키워드_데이터사이언스      14439      56.40      0.00      4728      266640              AOP 전체_중복키워드_프로그래밍      7580      39.60      0.01      7432      294316              JavaScript BOOT CAMP      36569      84.00      0.00      5285      443938              Python &amp; Django를 활용한 웹 서비스_개발자      142939      111.60      0.00      2777      309947              SEO/SEM 전략      19245      60.00      0.00      3143      188551              TensorFlow로 시작하는 딥러닝 입문      18280      91.20      0.00      1125      102608              fin_camp_auction_6      80917      272.40      0.00      1850      504064              ㅍAOP 전체_중복키워드_공통(삭제)      3974      25.20      0.01      3922      98835              ㅍAOP 전체_중복키워드_마케팅(삭제)      130583      156.00      0.00      2064      322047              ㅍAOP 전체_중복키워드_프로그래밍(삭제)      4595      22.80      0.00      4790      109219              ㅍ올인원 패키지 : UX/UI 디자인 입문_연관검색어(삭제)      144292      135.60      0.00      2469      334840              ㅍ올인원 패키지 : 브랜딩      45117      219.60      0.00      2220      487443              고객의 마음을 읽는 구글애널리틱스      52694      324.00      0.01      942      305338              대기업을 이기는 브랜딩 전략      22247      62.40      0.00      1573      98175              마케터를 위한 데이터 부트캠프      6326      55.20      0.01      3275      180774              마케터를 위한 데이터 해석 실전      24293      112.80      0.00      1108      125004              마케팅 유치원      19427      144.00      0.01      2094      301532              마케팅KPI수립      108693      75.60      0.00      1747      132099              올인원 패키지 : 1인 쇼핑몰 시작하기_02.쇼핑몰구축      88617      118.80      0.00      3330      395659              올인원 패키지 : 1인 쇼핑몰_00.창업_MO      49629      157.20      0.00      2102      330506              올인원 패키지 : UX/UI 디자인 입문_연관검색어      124692      183.60      0.00      3306      607057              올인원 패키지 : 그로스해킹_5.마케팅 분석      91720      34.80      0.00      3271      113839              올인원 패키지 : 디지털 마케팅_1. 디지털 마케팅      127110      110.40      0.00      3083      340329              올인원 패키지 : 브랜딩      54211      130.80      0.00      2424      317108              올인원 패키지 : 업무자동화_1. 자동화      35935      50.40      0.00      5162      260161              올인원 패키지 : 업무자동화_4. VBA      131560      170.40      0.00      1014      172854              올인원 패키지 : 영상 제작/편집_9.유튜브/유튜버      76996      64.80      0.00      1376      89155              왕초보의 파이썬 웹 프로그래밍 CAMP      58147      102.00      0.00      2348      239448              코딩으로 여행하는 블록체인 서비스      84089      86.40      0.00      2106      181918              페이스북&amp;인스타그램 마케팅 실전      15019      196.80      0.01      2545      500852              프로그래밍 유치원      47373      62.40      0.00      3028      188936      #.plot(kind='barh', grid=True, figsize=(10, 10)) result.plot(kind='barh', grid=True, figsize=(10,10))plt.xticks(fontsize=10)plt.show()",
        "url": "/searchAd"
    }
    ,
    
    "python-basic": {
        "title": "쿠팡 셀러 데이터 분석",
            "author": "SeongJae Yu",
            "category": "",
            "content": "dataframe이 짤라서 보일때 웹페이지를 축소해서 보시길 바랍니다~^^(50%이면 다 보일것입니다)import matplotlib.pyplot as pltfrom matplotlib import stylefrom matplotlib import font_manager, rcimport numpy as npimport pandas as pd#seabornimport seaborn as snsCOLORS = sns.color_palette()%matplotlib inlineprint(plt.rcParams[\"font.family\"])['sans-serif']# matplotlib 한글 폰트 출력코드# 출처 : 데이터공방( https://kiddwannabe.blog.me)import matplotlib from matplotlib import font_manager, rcimport platformtry :     if platform.system() == 'Windows':    # 윈도우인 경우        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()        rc('font', family=font_name)    else:        # Mac 인 경우        rc('font', family='AppleGothic')except :     passmatplotlib.rcParams['axes.unicode_minus'] = False   print(plt.rcParams[\"font.family\"])['Malgun Gothic']coupang = pd.read_excel('coupangdata.xlsx') coupang = pd.DataFrame(coupang)coupang.head()                  묶음배송번호      주문번호      택배사      운송장번호      분리배송 Y/N      분리배송 출고예정일      주문시 출고예정일      출고일(발송일)      주문일      등록상품명      ...      최초등록옵션명      업체상품코드      바코드      결제액      배송비구분      배송비      도서산간 추가배송비      구매수(수량)      옵션판매가(판매단가)      구매자                  0      1863148812      5000087866634      NaN      NaN      NaN      배송중      2020-12-02      NaN      2020-12-01 09:03:21      마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음[무료배송]      ...      001. 파티하는산타[무료배송]      11172108||fed78e0d6d      NaN      3900      무료      0      0      1      3900      최정미              1      1864045159      22000087613050      NaN      NaN      NaN      배송중      2020-12-04      NaN      2020-12-01 15:12:35      다이얼식 비밀번호식 열쇠[무료배송]      ...      003단-소[무료배송]      11568306||7dd580b226      NaN      5440      무료      0      0      1      5440      조경만              2      1864089590      32000087295636      NaN      NaN      NaN      배송중      2020-12-03      NaN      2020-12-01 15:29:09      하오츠 백탕 훠궈소스 마라탕 샹궈 재료 중국식품[무료배송]      ...      하오츠 백탕 훠궈소스 마라탕 샹궈 재료 중국식품[무료배송]      9407748||00      NaN      23160      무료      0      0      4      5790      박순화              3      1864204459      6000088215603      NaN      NaN      NaN      배송중      2020-12-03      NaN      2020-12-01 16:18:17      bob 갤럭시핏2 fit2 3D 곡면엣지 풀커버 PET 보호필름[무료배송]      ...      3D풀커버필름_Fit2/블랙[무료배송]      11201053||317c53cc4f      NaN      9680      무료      0      0      2      4840      김승용              4      1864399502      12000087552145      NaN      NaN      NaN      배송중      2020-12-02      NaN      2020-12-01 17:35:39      아동 성인 남녀공용 어른 겨울 뜨개실 귀마개[무료배송]      ...      00랜덤컬러[무료배송]      11291960||662b48f7d3      NaN      12560      무료      0      0      2      6280      박현기      5 rows × 24 columnsprint(coupang.size)print(len(coupang))726483027# dataframe으로 만들고 '노출상품명(옵션명)' 컬럼 string으로 타입변경#  https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html # 위 사이트 참고coupang['노출상품명(옵션명)'] = coupang['노출상품명(옵션명)'].astype(\"string\")coupang.dtypes묶음배송번호         object주문번호           object택배사            object운송장번호          object분리배송 Y/N       object분리배송 출고예정일     object주문시 출고예정일      object출고일(발송일)       object주문일            object등록상품명          object등록옵션명          object노출상품명(옵션명)     string노출상품ID         object옵션ID           object최초등록옵션명        object업체상품코드         object바코드            object결제액            object배송비구분          object배송비            object도서산간 추가배송비     object구매수(수량)        object옵션판매가(판매단가)    object구매자            objectdtype: object노출상품명(옵션명) 기준 groupgrouped = coupang.groupby('노출상품명(옵션명)')grouped&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000192FDACA860&gt;grouped.count()                  묶음배송번호      주문번호      택배사      운송장번호      분리배송 Y/N      분리배송 출고예정일      주문시 출고예정일      출고일(발송일)      주문일      등록상품명      ...      최초등록옵션명      업체상품코드      바코드      결제액      배송비구분      배송비      도서산간 추가배송비      구매수(수량)      옵션판매가(판매단가)      구매자              노출상품명(옵션명)                                                                                                                                                (사이즈3종) 자세교정 허리 /자가발열 /허리보호대 굽은 [생활플러스] 허리복대 벨트, 00_02사이즈/ XXL      1      1      1      1      1      1      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              (스타몰)도루코 커터날 대형 10개x10팩, 상세페이지 참조      3      3      0      0      0      0      3      0      3      3      ...      3      3      0      3      3      3      3      3      3      3              (오팔스토아)주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445      1      1      1      1      1      1      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              (큐트캣) 앞치마 어깨끈 요리 주방 H형 투포켓, 상세페이지 참조      1      1      0      0      0      0      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              +코코사라+[GTrend]버핏 패턴 지퍼케이스 전기종모음 추가금X, S20+ G986/핑크      1      1      0      0      1      1      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              화이트우드사각휴지케이스[무료배송], 상세페이지 참조      1      1      1      1      1      1      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              화장실 압축기 주름 변기 뚫어펑 뚫어뻥 (15cm 레드), 상세페이지 참조      1      0      1      1      1      1      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              후드방역모자 모자페이스쉴드 후디방역모자 모자투명막 방역모자 방역후드모자 투명막후드모자[무료배송], 02그레이      1      1      0      0      0      0      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              휴대용 접이식방석 카키 등산 낚시 야외방석, 단품      1      1      1      1      1      1      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1              희귀씨앗SY 씨앗10립 메버릭 제라늄 혼합, 상세페이지 참조      1      1      0      0      0      0      1      0      1      1      ...      1      1      0      1      1      1      1      1      1      1      2101 rows × 23 columnsdf_group=grouped.sum()df_group                  묶음배송번호      주문일      등록상품명      등록옵션명      노출상품ID      옵션ID      최초등록옵션명      업체상품코드      바코드      배송비구분      배송비      도서산간 추가배송비      구매수(수량)      구매자              노출상품명(옵션명)                                                                                                      (사이즈3종) 자세교정 허리 /자가발열 /허리보호대 굽은 [생활플러스] 허리복대 벨트, 00_02사이즈/ XXL      1909801673      2020-12-17 14:22:16      [생활플러스] 굽은 허리 자세교정 벨트 /허리보호대 /자가발열 허리복대 (사이즈3종...      00_02사이즈/ XXL[무료배송]      4545101585      72813731763      00_02사이즈/ XXL[무료배송]      11820400||d41294195d      0      무료      0      0      1      이수정              (스타몰)도루코 커터날 대형 10개x10팩, 상세페이지 참조      188810073920288228142277905990      2020-12-10 08:16:422021-01-29 16:59:392021-04-...      도루코 커터날 소형 10개x10팩[무료배송][제프파이썬] 도루코 커터날 소형 10개...      도루코 커터날 소형 10개x10팩[무료배송][제프파이썬] 도루코 커터날 소형 10...      438728853543872885354387288535      727510581877275105818772751058187      도루코 커터날 소형 10개x10팩[무료배송][제프파이썬] 도루코 커터날 소형 10...      9719011||009719011||009719011||00      0      무료무료무료      000      000      4      송진주박정식최미영              (오팔스토아)주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445      1916296697      2020-12-19 19:23:45      주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445[무료배송]      주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445[무료배송]      2092582935      72331080824      주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445[무료배송]      10758488||00      0      무료      0      0      2      정다운              (큐트캣) 앞치마 어깨끈 요리 주방 H형 투포켓, 상세페이지 참조      2339047465      2021-05-16 21:42:34      [jepython]@[세일상품](큐트캣) 앞치마 어깨끈 H형 요리 투포켓 주방jff...      [jepython]@[세일상품](큐트캣) 앞치마 어깨끈 H형 요리 투포켓 주방jff...      5267381501      75689000301      [jepython]@[세일상품](큐트캣) 앞치마 어깨끈 H형 요리 투포켓 주방jff...      13412054||00      0      무료      0      0      1      한지연              +코코사라+[GTrend]버핏 패턴 지퍼케이스 전기종모음 추가금X, S20+ G986/핑크      2116178401      2021-03-02 22:18:53      [제프파이썬+할인점] @전기종모음 추가금X [GTrend]버핏 지퍼케이스 패턴무료배...      [제프파이썬+할인점] @S20+ G986/핑크무료배송상품~!!      4733752280      74000668148      [제프파이썬+할인점] @S20+ G986/핑크무료배송상품~!!      9092143||fbd21ef7c2      0      무료      0      0      1      이은정              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              화이트우드사각휴지케이스[무료배송], 상세페이지 참조      1995359239      2021-01-17 00:35:33      화이트우드사각휴지케이스[무료배송]      화이트우드사각휴지케이스[무료배송]      2360203257      72081048147      화이트우드사각휴지케이스[무료배송]      11190111||00      0      무료      0      0      1      양희중              화장실 압축기 주름 변기 뚫어펑 뚫어뻥 (15cm 레드), 상세페이지 참조      1906632249      2020-12-16 15:03:20      화장실 압축기 주름 변기 뚫어펑 뚫어뻥 (15cm 레드)[무료배송]      화장실 압축기 주름 변기 뚫어펑 뚫어뻥 (15cm 레드)[무료배송]      4602750903      72979440769      화장실 압축기 주름 변기 뚫어펑 뚫어뻥 (15cm 레드)[무료배송]      11987532||00      0      무료      0      0      1      김예지              후드방역모자 모자페이스쉴드 후디방역모자 모자투명막 방역모자 방역후드모자 투명막후드모자[무료배송], 02그레이      1910822764      2020-12-17 20:26:06      후드방역모자 모자페이스쉴드 후디방역모자 모자투명막 방역모자 방역후드모자 투명막후드모...      02그레이[무료배송]      4550562528      72837959103      02그레이[무료배송]      11826092||a244908d03      0      무료      0      0      2      JIN LIANHONG              휴대용 접이식방석 카키 등산 낚시 야외방석, 단품      2044438968      2021-02-04 07:57:40      [제프파이썬] 휴대용 접이식방석 카키 등산 낚시 야외방석[무료배송]      [제프파이썬] 휴대용 접이식방석 카키 등산 낚시 야외방석[무료배송]      4542461867      73186959795      [제프파이썬] 휴대용 접이식방석 카키 등산 낚시 야외방석[무료배송]      12189631||00      0      무료      0      0      1      윤석선              희귀씨앗SY 씨앗10립 메버릭 제라늄 혼합, 상세페이지 참조      2296588774      2021-05-03 09:42:44      [제프파이썬+할인점] @ [jepython][제프파이썬]제라늄 희귀씨앗SY 메버릭 ...      [제프파이썬+할인점] @ [jepython][제프파이썬]제라늄 희귀씨앗SY 메버릭 ...      4924415731      73784185490      [제프파이썬+할인점] @ [jepython][제프파이썬]제라늄 희귀씨앗SY 메버릭 ...      12796989||00      0      무료      0      0      1      이영선      2101 rows × 14 columnsdf_group.head()                  묶음배송번호      주문일      등록상품명      등록옵션명      노출상품ID      옵션ID      최초등록옵션명      업체상품코드      바코드      배송비구분      배송비      도서산간 추가배송비      구매수(수량)      구매자              노출상품명(옵션명)                                                                                                      (사이즈3종) 자세교정 허리 /자가발열 /허리보호대 굽은 [생활플러스] 허리복대 벨트, 00_02사이즈/ XXL      1909801673      2020-12-17 14:22:16      [생활플러스] 굽은 허리 자세교정 벨트 /허리보호대 /자가발열 허리복대 (사이즈3종...      00_02사이즈/ XXL[무료배송]      4545101585      72813731763      00_02사이즈/ XXL[무료배송]      11820400||d41294195d      0      무료      0      0      1      이수정              (스타몰)도루코 커터날 대형 10개x10팩, 상세페이지 참조      188810073920288228142277905990      2020-12-10 08:16:422021-01-29 16:59:392021-04-...      도루코 커터날 소형 10개x10팩[무료배송][제프파이썬] 도루코 커터날 소형 10개...      도루코 커터날 소형 10개x10팩[무료배송][제프파이썬] 도루코 커터날 소형 10...      438728853543872885354387288535      727510581877275105818772751058187      도루코 커터날 소형 10개x10팩[무료배송][제프파이썬] 도루코 커터날 소형 10...      9719011||009719011||009719011||00      0      무료무료무료      000      000      4      송진주박정식최미영              (오팔스토아)주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445      1916296697      2020-12-19 19:23:45      주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445[무료배송]      주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445[무료배송]      2092582935      72331080824      주방 스텐 요리 업소용 파스타 ms 뉴 얼음집게 445[무료배송]      10758488||00      0      무료      0      0      2      정다운              (큐트캣) 앞치마 어깨끈 요리 주방 H형 투포켓, 상세페이지 참조      2339047465      2021-05-16 21:42:34      [jepython]@[세일상품](큐트캣) 앞치마 어깨끈 H형 요리 투포켓 주방jff...      [jepython]@[세일상품](큐트캣) 앞치마 어깨끈 H형 요리 투포켓 주방jff...      5267381501      75689000301      [jepython]@[세일상품](큐트캣) 앞치마 어깨끈 H형 요리 투포켓 주방jff...      13412054||00      0      무료      0      0      1      한지연              +코코사라+[GTrend]버핏 패턴 지퍼케이스 전기종모음 추가금X, S20+ G986/핑크      2116178401      2021-03-02 22:18:53      [제프파이썬+할인점] @전기종모음 추가금X [GTrend]버핏 지퍼케이스 패턴무료배...      [제프파이썬+할인점] @S20+ G986/핑크무료배송상품~!!      4733752280      74000668148      [제프파이썬+할인점] @S20+ G986/핑크무료배송상품~!!      9092143||fbd21ef7c2      0      무료      0      0      1      이은정      df_group.columnsIndex(['묶음배송번호', '주문일', '등록상품명', '등록옵션명', '노출상품ID', '옵션ID', '최초등록옵션명',       '업체상품코드', '바코드', '배송비구분', '배송비', '도서산간 추가배송비', '구매수(수량)', '구매자'],      dtype='object')구매수(수량) 데이터 변환df_group.info()&lt;class 'pandas.core.frame.DataFrame'&gt;Index: 2101 entries, (사이즈3종) 자세교정 허리 /자가발열 /허리보호대 굽은 [생활플러스] 허리복대 벨트, 00_02사이즈/ XXL to 희귀씨앗SY 씨앗10립 메버릭 제라늄 혼합, 상세페이지 참조Data columns (total 14 columns): #   Column      Non-Null Count  Dtype ---  ------      --------------  -----  0   묶음배송번호      2101 non-null   object 1   주문일         2101 non-null   object 2   등록상품명       2101 non-null   object 3   등록옵션명       2101 non-null   object 4   노출상품ID      2101 non-null   object 5   옵션ID        2101 non-null   object 6   최초등록옵션명     2101 non-null   object 7   업체상품코드      2101 non-null   object 8   바코드         2101 non-null   object 9   배송비구분       2101 non-null   object 10  배송비         2101 non-null   object 11  도서산간 추가배송비  2101 non-null   object 12  구매수(수량)     2101 non-null   object 13  구매자         2101 non-null   objectdtypes: object(14)memory usage: 246.2+ KB  12  구매수(수량)     2101 non-null   object 을 int타입으로 변환하기df_group.dtypes묶음배송번호        object주문일           object등록상품명         object등록옵션명         object노출상품ID        object옵션ID          object최초등록옵션명       object업체상품코드        object바코드           object배송비구분         object배송비           object도서산간 추가배송비    object구매수(수량)       object구매자           objectdtype: objectdf_group['구매수(수량)'] = pd.to_numeric(df_group['구매수(수량)'],errors = 'coerce')print(df_group.info())&lt;class 'pandas.core.frame.DataFrame'&gt;Index: 2101 entries, (사이즈3종) 자세교정 허리 /자가발열 /허리보호대 굽은 [생활플러스] 허리복대 벨트, 00_02사이즈/ XXL to 희귀씨앗SY 씨앗10립 메버릭 제라늄 혼합, 상세페이지 참조Data columns (total 14 columns): #   Column      Non-Null Count  Dtype  ---  ------      --------------  -----   0   묶음배송번호      2101 non-null   object  1   주문일         2101 non-null   object  2   등록상품명       2101 non-null   object  3   등록옵션명       2101 non-null   object  4   노출상품ID      2101 non-null   object  5   옵션ID        2101 non-null   object  6   최초등록옵션명     2101 non-null   object  7   업체상품코드      2101 non-null   object  8   바코드         2101 non-null   object  9   배송비구분       2101 non-null   object  10  배송비         2101 non-null   object  11  도서산간 추가배송비  2101 non-null   object  12  구매수(수량)     2100 non-null   float64 13  구매자         2101 non-null   object dtypes: float64(1), object(13)memory usage: 246.2+ KBNone  https://stackoverflow.com/questions/48094854/python-convert-object-to-float12  구매수(수량)     2100 non-null   float64 으로 타입 변경 할 때 위 사이트 참고함노출상품명(옵션명)별 구매수(수량)qua_by_items = df_group.groupby('노출상품명(옵션명)').sum()['구매수(수량)'].sort_values(ascending=False)qua_by_items노출상품명(옵션명)레고 저금통(색상랜덤), 센스넷 1                                                                     70.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 023. 루돌프와산타                                  46.0크리스마스 모음 스티커 마음담아 9종 핸드메이드 산타 귀여운 루돌프 눈사람, 001. 파티하는산타                                  42.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 001. 파티하는산타                                  38.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 012. 크리스마스리스                                 37.0                                                                                        ... 내추럴발란스 전연령 LID 감자 오리고기 포뮬라 드라이 반려견 사료 Large Bite, 11.8kg, 1개                             0.0[제프파이썬+할인점] @리어스텝 범퍼몰딩 엑스원 올뉴투싼 트렁크 발판 메탈무료배송상품~!!, 상세페이지 참조                             0.0[제프파이썬+할인점] @도구 필기 학생 정리 패스트푸드 메모 0.5mm 핑크풋 샤프무료배송상품~!!, 제품선택/감자튀김                       0.0[제프파이썬+할인점] @ [jepython][제프파이썬+할인점] @손가락 마디마사지기 친환경 핑거마사지기무료배송상품~!!jff2021, 상세페이지 참조     0.0[jepython]@[세일상품][제프파이썬+할인점] @어몽어스 소비 AMONG 용돈기입장 1000 습관 US무료배송상품~!!jff2021, 단품(랜덤)     0.0Name: 구매수(수량), Length: 2101, dtype: float64Top 10 판매 제품 확인top_selling = df_group.groupby('노출상품명(옵션명)').sum()['구매수(수량)'].sort_values(ascending=False)[:10]top_selling노출상품명(옵션명)레고 저금통(색상랜덤), 센스넷 1                                                 70.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 023. 루돌프와산타              46.0크리스마스 모음 스티커 마음담아 9종 핸드메이드 산타 귀여운 루돌프 눈사람, 001. 파티하는산타              42.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 001. 파티하는산타              38.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 012. 크리스마스리스             37.0아파트방음문 문방풍 방문틈막이 월동준비 문틈바람[무료배송], 그레이                               35.0bob 갤럭시핏2 fit2 3D 곡면엣지 풀커버 PET 보호필름[무료배송], 단일상품, 3D풀커버필름_Fit2/블랙    32.0마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 045. 싱글벙글산타              27.0[제프파이썬]7cm책철 책철 2600책철 화신책철 50개입 725책철-소무료배송, 상세페이지 참조              21.0화분 자동관수 패트병 공용기 장거리 여행 색상랜덤                                         20.0Name: 구매수(수량), dtype: float64Top 10 판매 제품 데이터 시각화plot = top_selling.plot(kind='bar', color=COLORS[-1], figsize=(20,10))plot.set_xlabel('노출상품명(옵션명)', fontsize=25)plot.set_ylabel('구매수(수량)', fontsize=25)plot.set_title('노출상품명(옵션명)별 구매수(수량)', fontsize=30)plot.set_xticklabels(labels=top_selling.index, rotation=75, fontsize=13)plt.show()노출상품명(옵션명) 중에 많이 나온 단어 빈도 조회# 필요한 모듈 실행import konlpyfrom konlpy.tag import *#wordcloud 사용 from wordcloud import wordcloudfrom collections import Counter #단어에 포함된 각 글자 수 세어준다import nltk #토큰 데이터를 살펴볼 수 있는 라이브러리from subprocess import check_outputfrom wordcloud import WordCloud,STOPWORDS,ImageColorGenerator #wordcloud 라이브러리import matplotlib as mplokt = Okt() # Konlpy를 사용하여 한글 명사 추출 및 빈도 계산             # Okt(Twitter) 클래스를 사용하여 한글 명사 단어 빈도 계산             # 클래스 종류 - Hannanum, Kkma, Komoran, Mecab, Okt(Twitter)kkma = Kkma() #print(okt.morphs(\"도움되셨다면, 공감을 꾸욱 눌러주세요~\"))# morphs는 형태소 단위로 구문 분석을 수행한다 # okt 잘 실행되는지 확인했음['도움', '되셨다면', ',', '공감', '을', '꾸욱', '눌러주세요', '~']노출상품명(옵션명) 컬럼만 데이터 저장data1 = pd.read_excel('coupangdata.xlsx', usecols='L') # Usecols은 엑셀파일의 특정 행만을 데이터로 출력하고 싶을때 사용하는 파라미터print(data1)                                             노출상품명(옵션명)0     마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 001...1                                 다이얼식 비밀번호식 열쇠, 003단-소2        현모양처 무료배송 하오츠 백탕 훠궈소스 마라탕 샹궈 재료 중국식품, 상세페이지 참조3     bob 갤럭시핏2 fit2 3D 곡면엣지 풀커버 PET 보호필름[무료배송], 단일상...4                      아동 성인 남녀공용 어른 겨울 뜨개실 귀마개, 00랜덤컬러...                                                 ...3022  [제프파이썬+할인점] @P36766 튼튼플러스요거얌얌 이츠웰 가공식품 오렌지125g...3023     [제프파이썬+할인점] @그로비타 거북이사료 85g무료배송상품~!!, 상세페이지 참조3024              HOME 밥주걱 홀더 받침대 거치대 가정 식당 HOLDER, 화이트3025              HOME 밥주걱 홀더 받침대 거치대 가정 식당 HOLDER, 화이트3026  [jepython]@[세일상품]영대 은박지 알루미늄 테이프 (48mm7M)jff20...[3027 rows x 1 columns]# morphs = 형태소 , noun = 명사 , pos = 형태소 + 품사#okt()함수를 이용하여 주요 키워드 추출data1.loc[:,'노출상품명(옵션명)']0       마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음, 001...1                                   다이얼식 비밀번호식 열쇠, 003단-소2          현모양처 무료배송 하오츠 백탕 훠궈소스 마라탕 샹궈 재료 중국식품, 상세페이지 참조3       bob 갤럭시핏2 fit2 3D 곡면엣지 풀커버 PET 보호필름[무료배송], 단일상...4                        아동 성인 남녀공용 어른 겨울 뜨개실 귀마개, 00랜덤컬러                              ...                        3022    [제프파이썬+할인점] @P36766 튼튼플러스요거얌얌 이츠웰 가공식품 오렌지125g...3023       [제프파이썬+할인점] @그로비타 거북이사료 85g무료배송상품~!!, 상세페이지 참조3024                HOME 밥주걱 홀더 받침대 거치대 가정 식당 HOLDER, 화이트3025                HOME 밥주걱 홀더 받침대 거치대 가정 식당 HOLDER, 화이트3026    [jepython]@[세일상품]영대 은박지 알루미늄 테이프 (48mm7M)jff20...Name: 노출상품명(옵션명), Length: 3027, dtype: object## 정규식을 이용해 한글,숫자만 추출import reimport iok =0 for i in data1['노출상품명(옵션명)']:    text = re.compile('[ㄱ-ㅎ|\\d\\ㅏ-ㅣ|가-힣]+').findall(i)    data1.loc[k,'노출상품명(옵션명)'] = ' '.join(text).strip()    k+=1data2 = data1.loc[:'노출상품명(옵션명)'] #정규식 처리 결과 ,특수기호와 이모지가 없는 것을 확인할 수 있다.data2                  노출상품명(옵션명)                  0      마음담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드메이드 스티커 9종 모음 001 ...              1      다이얼식 비밀번호식 열쇠 003단 소              2      현모양처 무료배송 하오츠 백탕 훠궈소스 마라탕 샹궈 재료 중국식품 상세페이지 참조              3      갤럭시핏2 2 3 곡면엣지 풀커버 보호필름 무료배송 단일상품 3 풀커버필름 2 블랙              4      아동 성인 남녀공용 어른 겨울 뜨개실 귀마개 00랜덤컬러              ...      ...              3022      제프파이썬 할인점 36766 튼튼플러스요거얌얌 이츠웰 가공식품 오렌지125 무료배송...              3023      제프파이썬 할인점 그로비타 거북이사료 85 무료배송상품 상세페이지 참조              3024      밥주걱 홀더 받침대 거치대 가정 식당 화이트              3025      밥주걱 홀더 받침대 거치대 가정 식당 화이트              3026      세일상품 영대 은박지 알루미늄 테이프 48 7 2021 상세페이지 참조      3027 rows × 1 columns  특수기호가 제거된 것을 확인 할 수 있다#https://hwao-story.tistory.com/3# 위 사이트 참고했음def word_cloud_save(data2):    mpl.rcParams['font.size']=12     mpl.rcParams['savefig.dpi']=100    mpl.rcParams['figure.subplot.bottom']=.1            stopwords = set(STOPWORDS)        wordcloud = WordCloud(                    font_path = 'C:\\Windows\\Fonts\\H2GTRE.TTF',                    background_color = 'white',                    stopwords = stopwords,                    max_words = 200,                    max_font_size=40,                    random_state=42    ).generate(str(data2['노출상품명(옵션명)']))okt = Okt()data2['token_item'] = data2['노출상품명(옵션명)'].apply(okt.morphs) # tokenizedata2['tagging'] = data2['노출상품명(옵션명)'].apply(okt.pos) #tokenize + 형태소 data2['Noun'] = data2['노출상품명(옵션명)'].apply(okt.nouns)# only 명사C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  This is separate from the ipykernel package so we can avoid doing imports untilC:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  after removing the cwd from sys.path.tagging = [j for i in data2['tagging'] for j in i] #리스트로 추출tagging[('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('001', 'Number'), ('파티', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('다이얼', 'Noun'), ('식', 'Suffix'), ('비밀번호', 'Noun'), ('식', 'Suffix'), ('열쇠', 'Noun'), ('003', 'Number'), ('단', 'Noun'), ('소', 'Noun'), ('현모양처', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('하오츠', 'Noun'), ('백탕', 'Noun'), ('훠궈', 'Noun'), ('소스', 'Noun'), ('마라', 'Adjective'), ('탕', 'Noun'), ('샹궈', 'Noun'), ('재료', 'Noun'), ('중국', 'Noun'), ('식품', 'Noun'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('갤럭시', 'Noun'), ('핏', 'Noun'), ('2', 'Number'), ('2', 'Number'), ('3', 'Number'), ('곡면', 'Noun'), ('엣지', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('보호', 'Noun'), ('필름', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('3', 'Number'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('2', 'Number'), ('블랙', 'Noun'), ('아동', 'Noun'), ('성인', 'Noun'), ('남녀', 'Noun'), ('공용', 'Noun'), ('어른', 'Noun'), ('겨울', 'Noun'), ('뜨', 'Verb'), ('개실', 'Verb'), ('귀마개', 'Noun'), ('00', 'Number'), ('랜덤', 'Noun'), ('컬러', 'Noun'), ('멀티', 'Noun'), ('염료', 'Noun'), ('실크', 'Noun'), ('린넨', 'Noun'), ('울', 'Noun'), ('다', 'Adverb'), ('이론', 'Noun'), ('53', 'Number'), ('면', 'Noun'), ('섬유', 'Noun'), ('염색', 'Noun'), ('1321', 'Number'), ('엘리펀트', 'Noun'), ('그레이', 'Noun'), ('대', 'Modifier'), ('용량', 'Noun'), ('식', 'Noun'), ('자재', 'Noun'), ('반찬', 'Noun'), ('소시지', 'Noun'), ('사조', 'Noun'), ('1', 'Number'), ('무료', 'Noun'), ('배송', 'Noun'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('범퍼', 'Noun'), ('케이스', 'Noun'), ('그립', 'Verb'), ('톡', 'Noun'), ('아이폰', 'Noun'), ('글라스', 'Noun'), ('12', 'Number'), ('미러', 'Noun'), ('하트', 'Noun'), ('스마트', 'Noun'), ('톡', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('실버', 'Noun'), ('갤럭시', 'Noun'), ('핏', 'Noun'), ('2', 'Number'), ('2', 'Number'), ('3', 'Number'), ('곡면', 'Noun'), ('엣지', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('보호', 'Noun'), ('필름', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('3', 'Number'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('2', 'Number'), ('블랙', 'Noun'), ('마향', 'Noun'), ('마라', 'Adjective'), ('탕용', 'Noun'), ('소스', 'Noun'), ('100', 'Number'), ('마라샹궈', 'Noun'), ('산초', 'Noun'), ('기름', 'Noun'), ('마', 'Noun'), ('조', 'Modifier'), ('유', 'Noun'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('헤어', 'Noun'), ('쁘띠', 'Noun'), ('명품', 'Noun'), ('머리핀', 'Noun'), ('동백', 'Noun'), ('이', 'Josa'), ('미니', 'Noun'), ('프랑스', 'Noun'), ('핀', 'Noun'), ('집게', 'Noun'), ('핀', 'Noun'), ('2', 'Number'), ('개', 'Noun'), ('1', 'Number'), ('쌍', 'Noun'), ('공효진', 'Noun'), ('동글이', 'Noun'), ('앞머리', 'Noun'), ('00', 'Number'), ('02', 'Number'), ('디자인', 'Noun'), ('에트', 'Noun'), ('로', 'Josa'), ('갤럭시', 'Noun'), ('핏', 'Noun'), ('2', 'Number'), ('2', 'Number'), ('3', 'Number'), ('곡면', 'Noun'), ('엣지', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('보호', 'Noun'), ('필름', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('3', 'Number'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('2', 'Number'), ('블랙', 'Noun'), ('간편한', 'Adjective'), ('시공', 'Noun'), ('주방', 'Noun'), ('욕실', 'Noun'), ('곰팡이', 'Noun'), ('오염', 'Noun'), ('방지', 'Noun'), ('방수', 'Noun'), ('테이프', 'Noun'), ('곰팡이', 'Noun'), ('방수', 'Noun'), ('테이프', 'Noun'), ('오염', 'Noun'), ('방지', 'Noun'), ('욕실', 'Noun'), ('틈새', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('00', 'Number'), ('단', 'Modifier'), ('품', 'Noun'), ('실버', 'Noun'), ('소품', 'Noun'), ('10', 'Number'), ('집게', 'Noun'), ('형', 'Suffix'), ('걸이', 'Noun'), ('고리', 'Noun'), ('걸이', 'Noun'), ('형', 'Suffix'), ('봉', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('92', 'Number'), ('핑코앤', 'Noun'), ('루리', 'Noun'), ('캐릭터', 'Noun'), ('케이스', 'Noun'), ('920', 'Number'), ('무료', 'Noun'), ('배송', 'Noun'), ('03', 'Number'), ('하트', 'Noun'), ('패턴', 'Noun'), ('스마', 'Noun'), ('토', 'Noun'), ('별', 'Modifier'), ('비트', 'Noun'), ('소켓', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('073', 'Number'), ('8', 'Number'), ('45', 'Number'), ('설치', 'Noun'), ('가', 'Josa'), ('간단한', 'Adjective'), ('빨래', 'Noun'), ('줄', 'Noun'), ('15', 'Number'), ('갤럭시', 'Noun'), ('핏', 'Noun'), ('2', 'Number'), ('2', 'Number'), ('3', 'Number'), ('곡면', 'Noun'), ('엣지', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('보호', 'Noun'), ('필름', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('3', 'Number'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('2', 'Number'), ('블랙', 'Noun'), ('나비', 'Noun'), ('다이어리', 'Noun'), ('갤럭시', 'Noun'), ('31', 'Number'), ('315', 'Number'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('01', 'Number'), ('블랙', 'Noun'), ('갤럭시', 'Noun'), ('21', 'Number'), ('쉬움', 'Noun'), ('우레', 'Noun'), ('탄', 'Verb'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('우레', 'Noun'), ('탄', 'Verb'), ('2', 'Number'), ('매', 'Noun'), ('217', 'Number'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('00', 'Number'), ('통합', 'Noun'), ('범퍼', 'Noun'), ('케이스', 'Noun'), ('그립', 'Verb'), ('톡', 'Noun'), ('아이폰', 'Noun'), ('글라스', 'Noun'), ('12', 'Number'), ('미러', 'Noun'), ('하트', 'Noun'), ('스마트', 'Noun'), ('톡', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('실버', 'Noun'), ('갤럭시', 'Noun'), ('31', 'Number'), ('3', 'Number'), ('강화', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('컬러풀', 'Noun'), ('하드', 'Noun'), ('케이스', 'Noun'), ('001', 'Number'), ('1', 'Number'), ('단일', 'Noun'), ('상품', 'Noun'), ('00', 'Number'), ('레드', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('023', 'Number'), ('루돌프', 'Noun'), ('와', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('034', 'Number'), ('연주회', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('045', 'Number'), ('싱글벙글', 'Noun'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('001', 'Number'), ('파티', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('023', 'Number'), ('루돌프', 'Noun'), ('와', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('034', 'Number'), ('연주회', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('045', 'Number'), ('싱글벙글', 'Noun'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('056', 'Number'), ('크리스마스트리', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('067', 'Number'), ('눈사람', 'Noun'), ('과', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('078', 'Number'), ('산타', 'Noun'), ('마을', 'Noun'), ('양말', 'Noun'), ('미끄럼', 'Noun'), ('방지', 'Noun'), ('융털', 'Noun'), ('양말', 'Noun'), ('수면', 'Noun'), ('양말', 'Noun'), ('방한', 'Noun'), ('양말', 'Noun'), ('검정', 'Noun'), ('갤럭시', 'Noun'), ('핏', 'Noun'), ('2', 'Number'), ('2', 'Number'), ('3', 'Number'), ('곡면', 'Noun'), ('엣지', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('보호', 'Noun'), ('필름', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('3', 'Number'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('2', 'Number'), ('블랙', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('012', 'Number'), ('크리스마스', 'Noun'), ('리스', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('023', 'Number'), ('루돌프', 'Noun'), ('와', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('056', 'Number'), ('크리스마스트리', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('078', 'Number'), ('산타', 'Noun'), ('마을', 'Noun'), ('크리스마스', 'Noun'), ('33', 'Number'), ('인테리어', 'Noun'), ('용', 'Noun'), ('루돌프', 'Noun'), ('사슴', 'Noun'), ('장식', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('012', 'Number'), ('크리스마스', 'Noun'), ('리스', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('023', 'Number'), ('루돌프', 'Noun'), ('와', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('067', 'Number'), ('눈사람', 'Noun'), ('과', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('034', 'Number'), ('연주회', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('001', 'Number'), ('파티', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('012', 'Number'), ('크리스마스', 'Noun'), ('리스', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('067', 'Number'), ('눈사람', 'Noun'), ('과', 'Josa'), ('산타', 'Noun'), ('꽃양배추', 'Noun'), ('임', 'Noun'), ('모란', 'Noun'), ('화분', 'Noun'), ('월동', 'Noun'), ('가능', 'Noun'), ('겨울', 'Noun'), ('화단', 'Noun'), ('가꾸기', 'Verb'), ('상세', 'Noun'), ('페이지', 'Noun'), ('참조', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('012', 'Number'), ('크리스마스', 'Noun'), ('리스', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('045', 'Number'), ('싱글벙글', 'Noun'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('056', 'Number'), ('크리스마스트리', 'Noun'), ('알뜰', 'Noun'), ('형', 'Suffix'), ('보풀', 'Noun'), ('먼지', 'Noun'), ('제거', 'Noun'), ('용', 'Noun'), ('롤링', 'Noun'), ('기', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('01', 'Number'), ('리필', 'Noun'), ('2', 'Number'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('001', 'Number'), ('파티', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('더', 'Noun'), ('예뻐진', 'Adjective'), ('너', 'Noun'), ('종이', 'Noun'), ('정밀', 'Noun'), ('아트', 'Noun'), ('공', 'Modifier'), ('예', 'Modifier'), ('칼', 'Noun'), ('컷터', 'Noun'), ('3', 'Number'), ('프린터', 'Noun'), ('후', 'Noun'), ('가공', 'Noun'), ('갤럭시', 'Noun'), ('핏', 'Noun'), ('2', 'Number'), ('2', 'Number'), ('3', 'Number'), ('곡면', 'Noun'), ('엣지', 'Noun'), ('풀', 'Noun'), ('커버', 'Noun'), ('보호', 'Noun'), ('필름', 'Noun'), ('무료', 'Noun'), ('배송', 'Noun'), ('단일', 'Noun'), ('상품', 'Noun'), ('3', 'Number'), ('풀', 'Noun'), ('커버', 'Noun'), ('필름', 'Noun'), ('2', 'Number'), ('블랙', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('056', 'Number'), ('크리스마스트리', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('067', 'Number'), ('눈사람', 'Noun'), ('과', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('078', 'Number'), ('산타', 'Noun'), ('마을', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('012', 'Number'), ('크리스마스', 'Noun'), ('리스', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('023', 'Number'), ('루돌프', 'Noun'), ('와', 'Josa'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('034', 'Number'), ('연주회', 'Noun'), ('하는', 'Verb'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('045', 'Number'), ('싱글벙글', 'Noun'), ('산타', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ('078', 'Number'), ('산타', 'Noun'), ('마을', 'Noun'), ('마음', 'Noun'), ('담아', 'Verb'), ('크리스마스', 'Noun'), ('귀여운', 'Adjective'), ('산타', 'Noun'), ('루돌프', 'Noun'), ('눈사람', 'Noun'), ('핸드', 'Noun'), ('메이드', 'Noun'), ('스티커', 'Noun'), ('9', 'Number'), ('종', 'Noun'), ('모음', 'Noun'), ...]print(len(tagging)) #5363353633#빈도수 높은 탑 10단어 추출#형태소 분석 및 품사 태깅tokens = [ take2 for take1 in data2['token_item'] for take2 in take1]text = nltk.Text(tokens, name='NMSC')print(text.vocab().most_common(10)) #상위10print(text.vocab().most_common()[:-20:-1]) #하위 10[('제프', 1888), ('배송', 1876), ('무료', 1863), ('파이썬', 1860), ('상세', 1714), ('페이지', 1714), ('참조', 1714), ('상품', 1578), ('할인점', 1352), ('2021', 570)][('85', 1), ('거북이', 1), ('그로', 1), ('얌얌', 1), ('36766', 1), ('인디', 1), ('발톱깎이', 1), ('개시', 1), ('더펫', 1), ('마루', 1), ('6835', 1), ('색견출', 1), ('플래그', 1), ('먹물', 1), ('대명', 1), ('지속', 1), ('8시간', 1), ('자극', 1), ('쑥갓', 1)]tokens = [ take2 for take1 in data2['token_item'] for take2 in take1]len(tokens)53633#입력한 키워드와 같이 나온 토큰을 보여줌 fL:연관 검색어text = nltk.Text(tokens, name='NMSC')text.concordance('무료')Displaying 25 of 1863 matches:파티 하는 산타 다이얼 식 비밀번호 식 열쇠 003 단 소 현모양처 무료 배송 하오츠 백탕 훠궈 소스 마라 탕 샹궈 재료 중국 식품 상세 페세 페이지 참조 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 아동 성인 남녀 공용 어색 1321 엘리펀트 그레이 대 용량 식 자재 반찬 소시지 사조 1 무료 배송 상세 페이지 참조 범퍼 케이스 그립 톡 아이폰 글라스 12 미참조 범퍼 케이스 그립 톡 아이폰 글라스 12 미러 하트 스마트 톡 무료 배송 단일 상품 실버 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호단일 상품 실버 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 마향 마라 탕용 소스 1디자인 에트 로 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 간편한 시공 주방 욕실 이 오염 방지 방수 테이프 곰팡이 방수 테이프 오염 방지 욕실 틈새 무료 배송 00 단 품 실버 소품 10 집게 형 걸이 고리 걸이 형 봉  배송 00 단 품 실버 소품 10 집게 형 걸이 고리 걸이 형 봉 무료 배송 상세 페이지 참조 상세 페이지 참조 92 핑코앤 루리 캐릭터 이지 참조 상세 페이지 참조 92 핑코앤 루리 캐릭터 케이스 920 무료 배송 03 하트 패턴 스마 토 별 비트 소켓 무료 배송 073 8 터 케이스 920 무료 배송 03 하트 패턴 스마 토 별 비트 소켓 무료 배송 073 8 45 설치 가 간단한 빨래 줄 15 갤럭시 핏 2  빨래 줄 15 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 나비 다이어리 갤럭시 3 상품 3 풀 커버 필름 2 블랙 나비 다이어리 갤럭시 31 315 무료 배송 단일 상품 01 블랙 갤럭시 21 쉬움 우레 탄 풀 커버 필름랙 갤럭시 21 쉬움 우레 탄 풀 커버 필름 우레 탄 2 매 217 무료 배송 단일 상품 00 통합 범퍼 케이스 그립 톡 아이폰 글라스 12통합 범퍼 케이스 그립 톡 아이폰 글라스 12 미러 하트 스마트 톡 무료 배송 단일 상품 실버 갤럭시 31 3 강화 풀 커버 컬러풀 하드 케방한 양말 검정 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 마음 담아 크리스마스 귀음 078 산타 마을 크리스마스 33 인테리어 용 루돌프 사슴 장식 무료 배송 상세 페이지 참조 마음 담아 크리스마스 귀여운 산타 루돌프 눈종 모음 056 크리스마스트리 알뜰 형 보풀 먼지 제거 용 롤링 기 무료 배송 01 리필 2 마음 담아 크리스마스 귀여운 산타 루돌프 눈사람프린터 후 가공 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 마음 담아 크리스마스 귀 산타 해피 바스 그린 콜라겐 바디 워시 200 자스민 베르가 못향 무료 배송 상세 페이지 참조 핸드 레일 부속 형 원형 35 골드 일제 무료 배송 상세 페이지 참조 핸드 레일 부속 형 원형 35 골드 일제 무료 배송 상세 페이지 참조 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보세 페이지 참조 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 갤럭시 핏 2 2 3 곡 필름 2 블랙 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 마음 담아 크리스마스 귀스티커 9 종 모음 045 싱글벙글 산타 014 제주 삼다수 500 무료 배송 상세 페이지 참조 우레 탄 튜브 유공 압 호스 공 압 호스 우 튜브 유공 압 호스 공 압 호스 우레 탄 호스 관 에어 호스 튜브 무료 배송 투명 1 마음 담아 크리스마스 귀여운 산타 루돌프 눈사람 핸드 크리스마스트리 갤럭시 핏 2 2 3 곡면 엣지 풀 커버 보호 필름 무료 배송 단일 상품 3 풀 커버 필름 2 블랙 크리스마스 메리 산타모 # 라이브러리 다시 불러오기 from collections import Counterimport matplotlibfrom matplotlib import font_manager,rcmatplotlib.rcParams['axes.unicode_minus'] = False#그래프에서 마이너스 기호가 표시되도록 하는 설정def showGraph(wordInfo):        font_location = \"C:\\Windows\\Fonts\\H2GTRE.TTF\"    font_name = font_manager.FontProperties(fname=font_location).get_name()    rc('font',family=font_name)        plt.xlabel('주요 단어')    plt.ylabel('빈도수')    plt.grid(True)            Sorted_Dict_Values = sorted(wordInfo.values(),reverse=True)    Sorted_Dict_Keys = sorted(wordInfo,key=wordInfo.get,reverse=True)        plt.bar(range(len(wordInfo)),Sorted_Dict_Values, align='center')    plt.xticks(range(len(wordInfo)), list(Sorted_Dict_Keys), rotation='70')            plt.show()      noun_text = [ take2 for take1 in data2['Noun'] for take2 in take1]text = nltk.Text(noun_text, name='NMSC')count = Counter(text.vocab())wordInfo = dict()for tags, counts in text.vocab().most_common(30):    if (len(str(tags)) &gt; 1):        wordInfo[tags] = counts        print (\"%s : %d\" % (tags, counts))            showGraph(wordInfo)제프 : 1888배송 : 1876무료 : 1863파이썬 : 1860상세 : 1714페이지 : 1714참조 : 1714상품 : 1578할인점 : 1352산타 : 440크리스마스 : 348루돌프 : 339스티커 : 280눈사람 : 258핸드 : 251모음 : 237마음 : 235메이드 : 230블랙 : 211세트 : 172밴드 : 159커버 : 154걸이 : 145갤럭시 : 143케이스 : 142필름 : 137보호 : 119#'stopwords' is not defined 해결방안 - 밑에 2번줄 실행하기from nltk.corpus import stopwordsdata = text.vocab().most_common(100)wordcloud = WordCloud(    font_path= 'C:\\Windows\\Fonts\\H2GTRE.TTF',    relative_scaling=0.4,    stopwords = stopwords,    background_color='white',).generate_from_frequencies( dict(data) )plt.figure( figsize=(12, 6) )plt.imshow(wordcloud)plt.axis(\"off\")plt.show()",
        "url": "/python-basic"
    }
    
    
    };
</script>
<script src="assets/js/lunr.js"></script>
<script src="assets/js/search.js"></script>
            </section>

        </article>

    </div>
</main>

<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->
<script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>



        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://SEONGJAE-YOO.github.io/">Big Data</a> &copy; 2021</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
    <div id="subscribe" class="subscribe-overlay">
        <a class="subscribe-overlay-close" href="#"></a>
        <div class="subscribe-overlay-content">
            
            <h1 class="subscribe-overlay-title">Search Big Data</h1>
            <p class="subscribe-overlay-description">
                lunr.js를 이용한 posts 검색 </p>
            <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()"
               id="searchtext" type="text" name="searchtext"
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
        </div>
    </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-xxxxxxxx-x', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
